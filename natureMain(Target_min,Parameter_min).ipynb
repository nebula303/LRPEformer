{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 引入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "# 加载torch也是需要时间的，算在里面。\n",
    "start = time.time()\n",
    "import pandas as pd\n",
    "import torch\n",
    "# from exp.exp_informer import Exp_Informer\n",
    "from utils.visualization import *\n",
    "from utils.initialize_random_seed import *\n",
    "from utils.metrics import *\n",
    "from utils.multi_lag_processor import *\n",
    "from pyecharts.globals import CurrentConfig, OnlineHostType\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from utils.tools import StandardScaler\n",
    "from utils.timefeatures import time_features\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# np.set_printoptions(precision=2)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)   #显示完整的列\n",
    "pd.set_option('display.max_rows', None)  #显示完整的行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据的时候用到,制作train、vali、test数据集\n",
    "class Dataset_Custom(Dataset):\n",
    "    # 在exp_informer.py中传值进来，覆盖掉这些默认参数\n",
    "    # start，end是后来加的，用于描述该数据从几号索引取到几号索引（0-1600，1600为最长电池长度，不会超过他）\n",
    "    def __init__(self, root_path, data_path, flag='train', size=None, \n",
    "                 features='S',timeenc=0,args=None):\n",
    "        # size： [seq_len, label_len, pred_len]\n",
    "        \n",
    "        # 分别为输入encoder的序列长度、输入decoder中原属数据长度，预测长度\n",
    "        self.seq_len = size[0]\n",
    "        self.label_len = size[1]\n",
    "        self.pred_len = size[2]\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.flag=flag\n",
    "        \n",
    "        rawdataη = pd.read_excel(os.path.join(args.root_path,\n",
    "                                          '最小值(70)2019train.xlsx'))\n",
    "        rawdataη=rawdataη.iloc[:1500].values[:,:].astype(float)\n",
    "        \n",
    "        \n",
    "        # init\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train':0, 'val':1, 'test':2}\n",
    "        # 0，表示train\n",
    "        self.set_type = type_map[flag]\n",
    "        \n",
    "        # features为 S，表示单值预测\n",
    "        self.features = features\n",
    "       \n",
    "        # 时间特征编码  args.embed, help='时间特征编码，选项：[timeF, fixed, learned]' ，默认为timeF\n",
    "        #  这是注释   timeenc = 0 if args.embed!='timeF' else 1，默认为 1\n",
    "        self.timeenc = timeenc\n",
    "        # 时间特征编码的频率，就是进行特征工程的时候时间粒度选取多少，\n",
    "        # '选项（options）:[s:secondly, t:minutely, h:hourly, d:daily, b:工作日（business days）, w:weekly, m:monthly], '\n",
    "        \n",
    "        \n",
    "        self.args = args\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 获取表格中所有列名（训练数据的）\n",
    "        self.dataTrain = pd.read_excel((os.path.join(self.root_path,\n",
    "                                          '最小值(70)2019train.xlsx')))\n",
    "        \n",
    "        self.dataTrain=self.dataTrain.iloc[:1500]\n",
    "        # self.scalerData 与 self.scalerI   为了把归一化的步骤传到外面\n",
    "        self.encoderList, self.decoderList, self.scalerDataη, self.lenListSum = self.__getsamples(rawdataη)\n",
    "\n",
    "    \n",
    "    def __getsamples(self, rawdataη):       \n",
    "        lenList=[]\n",
    "        lenListSum=0\n",
    "        ηFlatten=[]\n",
    "        for j,col in enumerate(self.dataTrain.columns):\n",
    "            # 每列的长度\n",
    "            len=(np.array(self.dataTrain.iloc[:,j].dropna())).shape[0]\n",
    "            lenList.append(len)\n",
    "            lenListSum=lenListSum+len\n",
    "            for i in range(len):\n",
    "                ηFlatten.append(rawdataη[i,j])\n",
    "       \n",
    "        # 变成归一化接受的形式\n",
    "        ηFlatten=np.array(ηFlatten).reshape(-1,1)\n",
    "        \n",
    "        # 归一化      \n",
    "        self.scalerDataη = MinMaxScaler()\n",
    "        self.scalerDataη = self.scalerDataη.fit(ηFlatten) \n",
    "        rawdataη = self.scalerDataη.transform(ηFlatten)\n",
    "            \n",
    "        # 还原成原来的格式  \n",
    "        ηNew=[]\n",
    "        lenTemp=0\n",
    "        # for j,col in enumerate(self.dataTrain.columns):\n",
    "        # 执行训练数据中电池的个数次，即列数\n",
    "        for i in range(self.dataTrain.shape[1]):\n",
    "            # print(i)\n",
    "            ηNewTemp=[]\n",
    "          \n",
    "            for j in range(lenList[i]):\n",
    "                ηNewTemp.append(rawdataη[j+lenTemp][0])  \n",
    "            lenTemp=lenTemp+lenList[i]\n",
    "            ηNewTemp=np.array(ηNewTemp)\n",
    "            \n",
    "            ηNew.append(ηNewTemp)   \n",
    "         \n",
    "        ηNew=np.array(ηNew) \n",
    "\n",
    "        XAll=[]\n",
    "        YAll=[]\n",
    "        for j,col in enumerate(self.dataTrain.columns):\n",
    "            sample_num=lenList[j] - self.seq_len - self.pred_len + 1\n",
    "            # X是encoder的输入,args.enc_in是encoder的输入维度，即几个特征\n",
    "            XPre = torch.zeros((sample_num, self.seq_len,args.enc_in))\n",
    "            # Y是decoder的输入，args.dec_in是decoder的输入维度，即几个特征\n",
    "            YPre = torch.zeros((sample_num, self.label_len + self.pred_len, args.dec_in))\n",
    "            \n",
    "            \n",
    "            for i in range(sample_num):\n",
    "                # encoder的输入开始\n",
    "                s_begin = i\n",
    "                # encoder的输入结束\n",
    "                s_end = s_begin + self.seq_len\n",
    "                # decoder的输入开始\n",
    "                r_begin = s_end - self.label_len\n",
    "                # decoder的输入结束\n",
    "                r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "                # 获取输入序列x\n",
    "                # seq_x = self.data_x[s_begin:s_end]\n",
    "                startX = i\n",
    "                # end从10到200\n",
    "                endX = i + self.seq_len\n",
    "                # result=zip(QDNew[j][start:end], MinNew[j][start:end], VarNew[j][start:end])\n",
    "                # j是第几列，start和end是起始以及终止的行数\n",
    "                result_x=np.vstack((ηNew[j][s_begin:s_end].reshape((self.seq_len,1))))\n",
    "                result_y=np.vstack((ηNew[j][r_begin:r_end].reshape((self.label_len+self.pred_len,1))))\n",
    "                # print(result_x.shape)\n",
    "                # 第一个参数 1 表示channel为 1 \n",
    "                # XPre的shape为(sample_num,1,1,seq_len)\n",
    "                XPre[i, :, :] = torch.from_numpy(np.array(list(result_x)))\n",
    "                # YPre的shape为(sampe_num,1,1,label_len+pred_len)\n",
    "                YPre[i, :, :] = torch.from_numpy(np.array(list(result_y)))\n",
    "                \n",
    "            XAll.append(XPre)\n",
    "            YAll.append(YPre)\n",
    "     \n",
    "     \n",
    "        # XAll.shape为（sample_num,seq_len,1）\n",
    "        XAll=torch.cat(XAll,dim=0).reshape(-1,self.seq_len,args.enc_in).double()\n",
    "        YAll=torch.cat(YAll,dim=0).reshape(-1,self.label_len+self.pred_len,args.dec_in).double()\n",
    "       \n",
    "        sample_sum=lenListSum- self.dataTrain.shape[1]*(self.seq_len + self.pred_len - 1)\n",
    "        train_num=int(0.8*sample_sum)\n",
    "        test_num=int(0.1*sample_sum)\n",
    "        val_num=sample_sum-train_num-test_num\n",
    "        \n",
    "        \n",
    "         # 以同样方法打乱两个矩阵的函数\n",
    "        def shuffle_two_matrix(a, b):\n",
    "            # 以a的行数为基准，打乱a和b\n",
    "            p = np.random.permutation(a.shape[0])\n",
    "            return a[p], b[p]\n",
    "        \n",
    "        # 确保每次打乱得一样\n",
    "        seed=args.seed\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic =True\n",
    "        # 确保每次打乱的一样\n",
    "        XAll,YAll=shuffle_two_matrix(XAll, YAll)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if(self.flag==\"train\"):\n",
    "            XAll=XAll\n",
    "            YAll=YAll\n",
    "        if(self.flag==\"test\"):\n",
    "            XAll=XAll[train_num:train_num+test_num]\n",
    "            YAll=YAll[train_num:train_num+test_num]\n",
    "        if(self.flag==\"val\"):\n",
    "            XAll=XAll[train_num+test_num:]\n",
    "            YAll=YAll[train_num+test_num:]\n",
    "        \n",
    "        return (XAll, YAll, self.scalerDataη, lenListSum) \n",
    "    \n",
    "   \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.encoderList.shape[0]\n",
    "    \n",
    "     # 外部使用【idx】来获取，idx的max值即上面的__len__\n",
    "    def __getitem__(self, idx):\n",
    "        seq_x=self.encoderList[idx, :, :]\n",
    "        seq_y=self.decoderList[idx, :, :]\n",
    "        # 获取带有掩码的输入序列x\n",
    "        seq_x_mark = torch.zeros(1)\n",
    "        # 获取带有掩码的输入序列x\n",
    "        seq_y_mark = torch.zeros(1)      \n",
    "        \n",
    "        return seq_x, seq_y,seq_x_mark, seq_y_mark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. exp_LRPEformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载器\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "# 在自定义的data模块中\n",
    "import pandas as pd\n",
    "\n",
    "# from data.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Pred\n",
    "#\n",
    "from exp.exp_basic import Exp_Basic\n",
    "# 导入模型\n",
    "from models.model import Informer, InformerStack\n",
    "\n",
    "# 提前停止策略、修正学习率\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate\n",
    "# 评价指标\n",
    "from utils.metrics import metric\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 继承Exp_Basic类\n",
    "class Exp_Informer(Exp_Basic):\n",
    "    def __init__(self, args):\n",
    "        super(Exp_Informer, self).__init__(args)\n",
    "\n",
    "    # 构造模型\n",
    "    def _build_model(self):\n",
    "        model_dict = {\n",
    "            'informer':Informer,\n",
    "            'informerstack':InformerStack,\n",
    "        }\n",
    "        if self.args.model=='informer' or self.args.model=='informerstack':\n",
    "            e_layers = self.args.e_layers if self.args.model=='informer' else self.args.s_layers\n",
    "            # 如果self.args.model是informer，那么model_dict[self.args.model]就是Informer类\n",
    "            model = model_dict[self.args.model](\n",
    "                self.args.enc_in,\n",
    "                self.args.dec_in, \n",
    "                self.args.c_out, \n",
    "                self.args.lstm_hidden_size, \n",
    "                self.args.lstm_num_layers, \n",
    "                self.args.seq_len, \n",
    "                self.args.label_len,\n",
    "                self.args.pred_len, \n",
    "                self.args.factor,\n",
    "                self.args.d_model, \n",
    "                self.args.n_heads, \n",
    "                e_layers, # self.args.e_layers,\n",
    "                self.args.d_layers, \n",
    "                self.args.d_ff,\n",
    "                self.args.dropout, \n",
    "                self.args.attn,\n",
    "                self.args.embed,\n",
    "                self.args.freq,\n",
    "                self.args.activation,\n",
    "                self.args.output_attention,\n",
    "                self.args.distil,\n",
    "                self.args.mix,\n",
    "                self.device\n",
    "            ).float()\n",
    "        \n",
    "        if self.args.use_multi_gpu and self.args.use_gpu:\n",
    "            model = nn.DataParallel(model, device_ids=self.args.device_ids)\n",
    "        return model\n",
    "\n",
    "    # 获取数据并进行处理，返回符合输入格式的数据\n",
    "    def _get_data(self, flag):\n",
    "        args = self.args\n",
    "        data_dict = {\n",
    "            'WTH':Dataset_Custom,\n",
    "            'ECL':Dataset_Custom,\n",
    "            'Solar':Dataset_Custom,\n",
    "            # 自定义的数据传到这边\n",
    "            '{}'.format(self.args.data):Dataset_Custom,\n",
    "            'custom':Dataset_Custom,\n",
    "        }\n",
    "        # 下面这个Data，此时是一个Dataset_Custom。\n",
    "        # self.args.data：chicken（我做的此处是rose）;    Data是Dataset_Custom对象\n",
    "        Data = data_dict[self.args.data]\n",
    "        # 时间特征编码  embed',args.embed, help='时间特征编码，选项：[timeF, fixed, learned]' \n",
    "        timeenc = 0 if args.embed!='timeF' else 1\n",
    "\n",
    "        # flag:设置任务类型\n",
    "        # 根据flag设置训练设置和数据操作设置\n",
    "        # 做测试的时候\n",
    "        if flag == 'test':\n",
    "            shuffle_flag = False; drop_last = True; batch_size = 30; freq=args.freq\n",
    "        # 做预测的时候\n",
    "        elif flag=='pred':\n",
    "            # 如果是预测未来的任务\n",
    "            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n",
    "            # 因为是预测任务，所以Data被赋值为Dataset_Pred对象\n",
    "            Data = Dataset_Pred\n",
    "       \n",
    "        elif flag == 'val':\n",
    "            shuffle_flag = False; drop_last = True; batch_size = 30; freq=args.freq\n",
    "        # train的时候:打乱数据\n",
    "        else:\n",
    "            shuffle_flag =True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n",
    "        # 使用Dataset_Custom进行读取数据集，并转换为数组.:\n",
    "        # 实例化Dataset_Custom对象\n",
    "        # print('args.data_path:',args.data_path)\n",
    "        # 下面这个Data，此时是一个Dataset_Custom。\n",
    "        data_set = Data(\n",
    "            root_path=args.root_path,\n",
    "            data_path=args.data_path,\n",
    "            flag=flag,\n",
    "            # informer原论文中，这三个分别为96，48，24，分别是输入encoder的序列长度、\n",
    "            # （48+24）为输入decoder的序列长度，24为预测长度\n",
    "            size=[args.seq_len, args.label_len, args.pred_len],\n",
    "            # M、S、MS，表示多变量预测、单变量预测、多变量预测单变量\n",
    "            features=args.features,\n",
    "            # target=args.target,\n",
    "            # inverse=args.inverse,\n",
    "            timeenc=timeenc,\n",
    "            # freq=freq,\n",
    "            # scale=args.scale,\n",
    "            # cols=args.cols,\n",
    "            args=args\n",
    "        )\n",
    "\n",
    "        \"\"\"\n",
    "        (96, 1)\n",
    "        (72, 1)\n",
    "        (96, 3)\n",
    "        (72, 3)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        返回读取的数据且是一个iterable，可迭代对象。这个可迭代对象里面是4个数组，对应了\n",
    "        \"\"\"\n",
    "        # sys.exit()\n",
    "        # print(flag,\":\\t\", len(data_set))\n",
    "        # 对data_set使用DataLoader，这里的shuffle决定了是否把数据打乱\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last)\n",
    "        \"\"\"\n",
    "        drop_last代表将不足一个batch_size的数据是否保留，即假如有4条数据，batch_size的值为3，将取出一个batch_size之后剩余的1条数据是否仍然作为训练数据，即是否丢掉这条数据。\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        torch.Size([32, 96, 1])\n",
    "        torch.Size([32, 72, 1])\n",
    "        torch.Size([32, 96, 3])\n",
    "        torch.Size([32, 72, 3])\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        DataLoader就是将数据data_set组装起来成input的格式，且是一个iterable，可迭代对象。这个输入格式是序列的输入格式，[批次大小batch_size，输入序列长度seq_len，特征(有多少列)数量]。\n",
    "        其中，输入序列长度seq_len相当于是滑动窗口的大小。\n",
    "        \"\"\"\n",
    "        return data_set, data_loader\n",
    "\n",
    "    # 选择模型优化器（这里是adam）\n",
    "    def _select_optimizer(self):\n",
    "        model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "\n",
    "    # 选择损失标准(损失函数)\n",
    "    def _select_criterion(self):\n",
    "        # 默认是mse\n",
    "        criterion = nn.MSELoss()\n",
    "        if self.args.loss == 'mse':\n",
    "            criterion = nn.MSELoss()\n",
    "        if self.args.loss == 'L1loss':\n",
    "            criterion = nn.L1Loss()\n",
    "        if self.args.loss == 'huberloss':\n",
    "            criterion = nn.SmoothL1Loss()\n",
    "        return criterion\n",
    "\n",
    "     # 验证集的验证，val的loss是总 loss，train的 loss是50轮的平均 loss\n",
    "    def vali(self,vali_data,vali_loader,criterion,args):\n",
    "        self.model.eval()\n",
    "        with  torch.no_grad():\n",
    "            total_loss = []\n",
    "            dataset = Dataset_Custom(\n",
    "                        root_path=args.root_path,\n",
    "                        data_path=args.data_path,\n",
    "                        # 此处这个flag无影响\n",
    "                        flag='test',\n",
    "                        # informer原论文中，这三个分别为96，48，24，分别是输入encoder的序列长度、\n",
    "                        # （48+24）为输入decoder的序列长度，24为预测长度\n",
    "                        size=[args.seq_len, args.label_len, args.pred_len],\n",
    "                        # M、S、MS，表示多变量预测、单变量预测、多变量预测单变量\n",
    "                        features=args.features,\n",
    "                        timeenc=0,\n",
    "                        args=args\n",
    "                    )\n",
    "            scalerDataη1=dataset.scalerDataη\n",
    "            # 命名的时候带All表示所有的数据，只是用来看每一列的长度的，但此处实际上每列长度固定为500了\n",
    "            dataAll=pd.read_excel((os.path.join(args.root_path,\n",
    "                                                    '最小值(70)2019train.xlsx')))\n",
    "        \n",
    "            dataAll=dataAll.iloc[:1500]\n",
    "            lenList=[]\n",
    "            lenListSum=0\n",
    "            colListAll=[]\n",
    "\n",
    "            # 每列的长度，实际此处数据每列固定为500，但可以处理每列数据不一样的情况\n",
    "            for j,col in enumerate(dataAll.columns):\n",
    "                # 每列的长度\n",
    "                len=(np.array(dataAll.iloc[:,j].dropna())).shape[0]\n",
    "                lenList.append(len)\n",
    "                lenListSum=lenListSum+len\n",
    "                # 表的列名，用于给图片命名，表明电池编号\n",
    "                colListAll.append(col)\n",
    "\n",
    "            \n",
    "            excelHead=['参数']\n",
    "            excelMse=['lhs_'+str(args.lstm_hidden_size)+'，lnl_'+str(args.lstm_num_layers)+'，dM_'+str(args.d_model)+'，dFF_'+str(args.d_ff)]\n",
    "            YTruthAll=[]\n",
    "            YPredAll=[]\n",
    "            # i是训练集的每一列（每一个电池），跑完就是一个参数下所有电池跑完\n",
    "            for i in range(dataAll.shape[1]):\n",
    "                if(i>-1):\n",
    "                    rawdataNewη1 = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                    '最小值(70)2019train.xlsx')))\n",
    "                    # 这一列的全部真实值\n",
    "                    rawdataNewη1=rawdataNewη1.iloc[:lenList[i]].values[:,i].reshape(-1, 1)\n",
    "                    \n",
    "                    # 归一化后输入模型\n",
    "                    rawdataNewη1 = scalerDataη1.transform(rawdataNewη1)\n",
    "                    \n",
    "                    result1=np.vstack((rawdataNewη1))\n",
    "                    res_list1_encoder1 = torch.from_numpy(result1[:args.seq_len])\n",
    "                    \n",
    "                    start = 0\n",
    "                    # 一直预测到200\n",
    "                    # resItemList用于记录所有的预测值(450个)\n",
    "                    resItemList1=[]\n",
    "                    rawdata = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                    '最小值(70)2019train.xlsx')))\n",
    "                    # 该列电池真实值（不做归一化）\n",
    "                    rawdata=rawdata.iloc[:lenList[i]].values[:,i]\n",
    "                    # 下面几个参数是一个电池所共有的\n",
    "                    mseCell=0\n",
    "                    # 下面两个是为了方便计算R平方等值用的\n",
    "                    predictCell=[]\n",
    "                    realCell=[]\n",
    "                    \n",
    "                    # 循环结束是一个电池的预测结束\n",
    "                    while(start<((lenList[i]-args.seq_len)//args.pred_len)+1):\n",
    "                        window_encoder= torch.tensor(res_list1_encoder1[start*args.pred_len: start*args.pred_len+args.seq_len])\n",
    "                        # 注意，这边还是从encoder中取\n",
    "                        window_decoder= torch.tensor(res_list1_encoder1[start*args.pred_len+args.seq_len- args.label_len: start*args.pred_len+args.seq_len])\n",
    "                        seq_x_mark = torch.zeros(1)\n",
    "                        # 获取带有掩码的输入序列x\n",
    "                        seq_y_mark = torch.zeros(1)\n",
    "                        \n",
    "                        \n",
    "                        if args.use_gpu:\n",
    "                            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) if not args.use_multi_gpu else self.args.devices\n",
    "                            device = torch.device('cuda:{}'.format(args.gpu))\n",
    "                            # print('Use GPU: cuda:{}'.format(args.gpu))\n",
    "                        else:\n",
    "                            device = torch.device('cpu')\n",
    "                        global dec_inp\n",
    "                        batch_x = window_encoder.float()\n",
    "                        batch_y = window_decoder.float()\n",
    "\n",
    "                        batch_x_mark = seq_x_mark.float()\n",
    "                        batch_y_mark = seq_y_mark.float()\n",
    "                        batch_x=batch_x.unsqueeze(0)\n",
    "                        batch_y=batch_y.unsqueeze(0)\n",
    "                        batch_x_mark=batch_x_mark.unsqueeze(0)\n",
    "                        batch_y_mark=batch_y_mark.unsqueeze(0)\n",
    "                        # decoder input\n",
    "                        if args.padding==0:\n",
    "                            dec_inp = torch.zeros([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "                        elif args.padding==1:\n",
    "                            dec_inp = torch.ones([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "                        # 在给定维度上对输入的张量序列seq 进行连接操作。\n",
    "                        \"\"\"\n",
    "                        outputs = torch.cat(inputs, dim=0) → Tensor\n",
    "                        \n",
    "                        inputs : 待连接的张量序列，可以是任意相同Tensor类型的python 序列，可以是列表或者元组。\n",
    "                        dim : 选择的扩维, 必须在0到len(inputs[0])之间，沿着此维连接张量序列。\n",
    "                        \"\"\"\n",
    "                        dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float()\n",
    "                        # encoder - decoder（编码器-解码器）\n",
    "                        # 假如使用自动混合精度训练，这个true是假的，下面用直接读取excel的方法取得\n",
    "                        pred, trueFake = self._process_one_batch(\n",
    "                                vali_data, batch_x, batch_y, batch_x_mark, batch_y_mark,args)\n",
    "                        f_dim = -1 if args.features=='MS' else 0\n",
    "                        # 如果是MS。那么只留有一列输出\n",
    "                        # outputs = outputs[:, :, 1:] if args.features == 'MS' else outputs\n",
    "                        # 对y进行解码\n",
    "                        # 取出pred\n",
    "                        batch_y = batch_y[:,-args.pred_len:,f_dim:]\n",
    "\n",
    "                        # 如果是M任务，那么进行打平再输出去计算梯度\n",
    "                        # output作为预测值，batch_y(取出pred部分，也就是长度40)作为真实值\n",
    "                        # return outputs, batch_y\n",
    "                        \n",
    "                        # outputs(1,50,1)\n",
    "                                \n",
    "                        outputs=pred.to('cpu')\n",
    "                        # print('res_list1_encoder1',res_list1_encoder1.device)\n",
    "                        # print('outputs',outputs.device)\n",
    "                        # 存的是真实值以及预测值的拼接\n",
    "                        res_list1_encoder1=torch.cat([res_list1_encoder1,outputs.squeeze(0)],dim=0)\n",
    "                        \n",
    "                        # 算mse\n",
    "                        # 逆归一化\n",
    "                        res_listnew=scalerDataη1.inverse_transform(outputs.squeeze(0).reshape(-1,1)).ravel()  \n",
    "                        \n",
    "                        for element in res_listnew:\n",
    "                            predictCell.append(element)\n",
    "                        \n",
    "                        \n",
    "                        start = start + 1\n",
    "                        \n",
    "                    \n",
    "                    # resItemList1\n",
    "                    # 逆归一化,还原成预测的充电电容(150个)\n",
    "                    res_listnew2=scalerDataη1.inverse_transform(res_list1_encoder1[:,-1].reshape(-1,1)).ravel()  \n",
    "                    res_listnew2=res_listnew2[0:lenList[i]]\n",
    "                    # print(\"ahh\",res_listnew)\n",
    "                    \n",
    "                    # print('每个电池迭代次数',lenList[i]-args.seq_len-args.pred_len+1)\n",
    "                    # print('start',start)\n",
    "                    # 除以'每个电池迭代次数'，得到一个电池的最终mse\n",
    "                    # mseCell=mseCell/((lenList[i]-args.seq_len-args.pred_len)//args.pred_len+1)\n",
    "                \n",
    "                    # print('predictCell', len(predictCell))\n",
    "                    \n",
    "                    # 一套参数下所有电池的mse相加\n",
    "                    # mseAll = mseAll+mseCell\n",
    "\n",
    "\n",
    "\n",
    "                    # testIndex = 0\n",
    "\n",
    "                    # # print('res_listnew',res_listnew[-1])\n",
    "                    # # 一开始用的是1A的数据,用的是初始数据\n",
    "                    rawdata = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                        '最小值(70)2019train.xlsx')))\n",
    "                    rawdata=rawdata.iloc[:lenList[i]].values[:,i]\n",
    "                    \n",
    "                    # 纵坐标真实值\n",
    "                    y = rawdata[0:]\n",
    "                    # 纵坐标预测值     # 还原成原样\n",
    "                    # y2 = np.array(res_listnew[:]).tolist()\n",
    "                    # print(type(y))\n",
    "                    # print(type(predictCell))\n",
    "                    y2 = y[0:args.seq_len].tolist()+predictCell\n",
    "                    y2 = y2[:lenList[i]]\n",
    "                    YTruthAll=np.concatenate((YTruthAll, y[-lenList[i]+args.seq_len:]))\n",
    "                    YPredAll=np.concatenate((YPredAll, y2[-lenList[i]+args.seq_len:]))\n",
    "                    \n",
    "                    \n",
    "                    # 电池\n",
    "                    realCellAll=pd.read_excel((os.path.join(args.root_path,\n",
    "                                                    '最小值(70)2019train.xlsx')))\n",
    "                    # 这一列的全部真实值\n",
    "                    realCellAll=realCellAll.iloc[:lenList[i]].values[:,i].reshape(-1, 1)\n",
    "                    # 最终得到的realCell是与predict的shape一样的，可以用于计算mse，r平方之类\n",
    "                    # for idx in range(lenList[i]-args.seq_len-args.pred_len+1):\n",
    "                    #     for element in realCellAll[idx+args.seq_len : idx+args.seq_len+args.pred_len]:\n",
    "                    #         realCell.append(element)\n",
    "                    # mean_squared_error(realCell,predictCell)与上面计算的mseCell一样\n",
    "                    realCell=y[-lenList[i]+args.seq_len:]\n",
    "                    # print('mse新',mean_squared_error(realCell,predictCell))\n",
    "                    # print('mse新xin',mean_squared_error(realCell,res_listnew2[100:]))\n",
    "                    # print('mseCell',mseCell)\n",
    "                    # 可以计算r平方\n",
    "                    # print('r',r2_score(realCell,predictCell))\n",
    "                    \n",
    "                    \n",
    "            loss = criterion(torch.from_numpy(YTruthAll.flatten()).detach().cpu(), torch.from_numpy(YPredAll.flatten()).detach().cpu())\n",
    "            total_loss.append(loss)\n",
    "            total_loss = np.average(total_loss)\n",
    "            self.model.train()\n",
    "            return total_loss\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    # 训练集的训练\n",
    "    def train(self,setting,info_dict,run_name_dir_ckp,run_ex_dir,args):\n",
    "        # 做训练的时候这里面已经测试集评估功能 和 验证集的验证功能了,args.save_model_choos\n",
    "        global scaler\n",
    "        train_data, train_loader = self._get_data(flag = 'train')\n",
    "        vali_data, vali_loader = self._get_data(flag = 'val')\n",
    "        test_data, test_loader = self._get_data(flag = 'test')\n",
    "        # 存储模型的位置\n",
    "        path = os.path.join(run_name_dir_ckp, setting)\n",
    "        # path = os.path.join(run_ex_dir, setting)#将模型和可视化文件存储在一起\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        time_now = time.time()\n",
    "        # 训练步数(举例有100个sample，batch_size为20，则训练步数为 100/20==5，即一个epoch里面分了五个batch)\n",
    "        # 不用管他\n",
    "        train_steps = len(train_loader)\n",
    "        # 实例化 提前停止（保存模型的代码在里面）\n",
    "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True,save_model_choos=args.save_model_choos)\n",
    "        # 模型优化器\n",
    "        model_optim = self._select_optimizer()\n",
    "        # 损失函数,此处是mse\n",
    "        criterion =  self._select_criterion()\n",
    "        if self.args.use_amp:\n",
    "            # autocast + GradScaler 可以达到自动混合精度训练的目的；\n",
    "            # GradScaler是梯度\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "        # 训练的时候记录每个epoch产生的损失，包括训练集损失、验证集损失、测试集(评估集)损失\n",
    "        all_epoch_train_loss = []\n",
    "        all_epoch_vali_loss = []\n",
    "        all_epoch_test_loss = []\n",
    "        # 训练args.train_epochs个epoch，每一个epoch循环一遍整个数据集\n",
    "        epoch_count = 0\n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            epoch_count += 1\n",
    "            iter_count = 0\n",
    "            # 存储当前epoch下的每个迭代步的训练损失\n",
    "            train_loss = []\n",
    "            \"\"\"\n",
    "            模型中有BN层(Batch Normalization）和Dropout，需要在训练时添加model.train()，在测试时添加model.eval()。\n",
    "            \n",
    "            其中model.train()是保证BN层用每一批数据的均值和方差，而model.eval()是保证BN用全部训练数据的均值和方差；\n",
    "            而对于Dropout，model.train()是随机取一部分网络连接来训练更新参数，而model.eval()是利用到了所有网络连接。\n",
    "            \"\"\"\n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            # 在每个epoch里面迭代数据训练模型：遍历一遍数据\n",
    "            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n",
    "                # 累计迭代次数\n",
    "                iter_count += 1\n",
    "                # 把模型的参数梯度设置为0:\n",
    "                model_optim.zero_grad()\n",
    "                # 训练集的预测值和真实值 : 这里的真实值是输入数据-滑动窗口，预测值是滑动川口里面的对应预测值。[批次,预测长度,1]\n",
    "                pred, true = self._process_one_batch(train_data, batch_x, batch_y, batch_x_mark, batch_y_mark,args)\n",
    "                # 对于多变量，把数组打平，【然后归一化】，然后再计算损失。\n",
    "                pred = pred[:, :, -1:] if args.features == 'MS' else pred\n",
    "                \"\"\"\n",
    "                true:    <class 'torch.Tensor'> torch.float32\n",
    "                pred:    <class 'torch.Tensor'> torch.float16\n",
    "                \"\"\"\n",
    "                loss = criterion(pred.float(), true.float())\n",
    "                train_loss.append(loss.item())\n",
    "                # 每迭代一百个样本就打印一次\n",
    "                # if (i+1) % 100==0:\n",
    "                if (i+1) % 120==0:\n",
    "                    # 查看迭代100个样本所花费的时间，和这100个样本的训练损失值，还有当前所在epoch\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time()-time_now)/iter_count\n",
    "                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n",
    "                    # 查看处理速度\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "                if self.args.use_amp:\n",
    "                    # 达到自动混合精度训练的目的\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "            # 打印遍历一遍整个训练集 所需要的时间，也就是此次epoch所需要的时间\n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n",
    "            # 对训练集损失求均值\n",
    "            train_loss = np.average(train_loss)\n",
    "            # 验证集验证\n",
    "            vali_loss = self.vali(vali_data, vali_loader, criterion,args)\n",
    "            # 测试集进行评估模型，其实这里也是达到验证的作用\n",
    "            test_loss = self.vali(test_data, test_loader, criterion,args)\n",
    "            # 添加到列表中留存\n",
    "            all_epoch_train_loss.append(float(round(train_loss,1)))\n",
    "            all_epoch_vali_loss.append(float(round(vali_loss,1)))\n",
    "            all_epoch_test_loss.append(float(round(test_loss,1)))\n",
    "            # 完成每个epoch的训练就打印一次\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            # 判断是否提前停止，并且存最好的模型，保存模型 torch.save\n",
    "            early_stopping(vali_loss, self.model, path,args.save_model_choos)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "            # 更新学习率\n",
    "            adjust_learning_rate(model_optim, epoch+1, self.args)\n",
    "            # if(epoch%5==0):\n",
    "                # torch.save(self.model, \"./model/batterySD/Δη/informer/单特征/informer_e\" + str(epoch) + \"_b\" + str(args.batch_size) + \"_dModel\" + str(args.d_model) + \"_dFF\" + str(args.d_ff)+ \"_s\" + str(args.seq_len) + \"_l\" + str(args.label_len) + \"_p\" + str(args.pred_len)+ \".pkl\")\n",
    "        # 存储该次实验的更新迭代中的最优模型\n",
    "        if args.save_model_choos==True:\n",
    "            best_model_path = path+'/'+'checkpoint.pth'\n",
    "            # 下面是加载模型，（这个模型最终在预测完之后要删除，因为占用内存大）\n",
    "            self.model.load_state_dict(torch.load(best_model_path))\n",
    "        # 实验记录\n",
    "        info_dict[\"【训练】本次实验训练的train平均损失\"] = round(float(np.mean(all_epoch_train_loss)),1)\n",
    "        info_dict[\"【验证】本次实验训练的vali平均损失\"]  = round(float(np.mean(all_epoch_vali_loss)),1)\n",
    "        info_dict[\"【验证】本次实验训练的test平均损失\"]  = round(float(np.mean(all_epoch_test_loss)),1)\n",
    "        info_dict[\"----实际训练的epoch-------\"] = epoch_count\n",
    "\n",
    "        return self.model,info_dict,all_epoch_train_loss,all_epoch_vali_loss,all_epoch_test_loss,epoch_count\n",
    "\n",
    "    # 测试集测试\n",
    "    def test(self,setting,info_dict,run_ex_dir,args):\n",
    "        test_data, test_loader = self._get_data(flag='test')#做测试的时候\n",
    "        # 不启用 BatchNormalization 和 Dropout，因为不是训练模式\n",
    "        self.model.eval()\n",
    "        preds = []\n",
    "        trues = []\n",
    "        # batch_x是输入的一个批次的x数据，\n",
    "        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(test_loader):\n",
    "            # print(batch_x.shape, batch_y.shape, batch_x_mark.shape, batch_y_mark.shape)\n",
    "            # print(batch_x, batch_y)\n",
    "            # 返回的是数组,注意：loader里面已经把数据打乱了\n",
    "            pred, true = self._process_one_batch(\n",
    "                test_data, batch_x, batch_y, batch_x_mark, batch_y_mark,args)\n",
    "            pred = pred[:, :, -1:] if args.features == 'MS' else pred\n",
    "            # print(type(pred),pred.shape)\n",
    "            # print(pred)\n",
    "            # print(type(true),true.shape)\n",
    "            # print(true)\n",
    "            # print(\"-----------\"*4)\n",
    "            # sys.exit()\n",
    "            # 把数组添加到列表\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "            trues.append(true.detach().cpu().numpy())\n",
    "            # if args.inverse == False:\n",
    "            #     inverse_true = Standardization.inverse_transform(true)\n",
    "            #     inverse_pred = Standardization.inverse_transform(pred)\n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "        \"\"\"\n",
    "        test shape: (29, 32, 24, 1) (29, 32, 24, 1)\n",
    "        test shape: (928, 24, 1) (928, 24, 1)\n",
    "        \"\"\"\n",
    "        # result save\n",
    "        folder_path = run_ex_dir+'/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        if args.features == 'M':\n",
    "            # 取到最后一个值，因为那个才是要预测的。\n",
    "            trues = trues[:,-1:,:]\n",
    "            preds = preds[:,-1:,:]\n",
    "            trues = trues.reshape(len(trues),trues.shape[-1])\n",
    "            preds = preds.reshape(len(preds),preds.shape[-1])\n",
    "            # print(trues)\n",
    "            # sys.exit()\n",
    "            trues = np.around(trues,decimals=1)\n",
    "            preds = np.around(preds,decimals=1)\n",
    "            trues = trues.tolist()\n",
    "            preds = preds.tolist()\n",
    "            preds = np.array(preds)\n",
    "            trues = np.array(trues)\n",
    "\n",
    "        if args.features != 'M':\n",
    "            trues = trues[:, -1:, :]\n",
    "            preds = preds[:, -1:, :]\n",
    "            trues = trues.flatten()\n",
    "            preds = preds.flatten()\n",
    "            trues = np.around(trues, decimals=1)\n",
    "            preds = np.around(preds, decimals=1)\n",
    "            trues = trues.tolist()\n",
    "            preds = preds.tolist()\n",
    "            preds = [round(i, 1) for i in preds]\n",
    "            trues = [round(i, 1) for i in trues]\n",
    "            preds = np.array(preds)\n",
    "            trues = np.array(trues)\n",
    "\n",
    "        # 评估指标：测试集评估模型\n",
    "        mae,rmse,smape,r2,ad_r2 = metric(preds, trues)\n",
    "        mae, rmse, smape, r2, ad_r2 = round(float(mae),1),round(float(rmse),1),round(float(smape),1),round(float(r2),1),round(float(ad_r2),1)\n",
    "        print('测试集评估结果：\\t平均绝对误差 MAE:{}，均方根误差RMSE:{}，对称平均绝对百分比误差SMAPE:{}，决定系数R²：{}，校正R²:{} \\n'.format(mae,rmse,smape,r2,ad_r2))\n",
    "        # 存储评估指标\n",
    "        info_dict[\"【评估】本次实验的test集平均绝对误差MAE\"] = mae\n",
    "        info_dict[\"【评估】本次实验的test集均方根误差RMSE\"] = rmse\n",
    "        info_dict[\"【评估】本次实验的test集对称平均绝对百分比误差SMAPE\"] = smape\n",
    "        info_dict[\"【评估】本次实验的test集决定系数R²\"] = r2\n",
    "        info_dict[\"【评估】本次实验的test集校正决定系数Ad_R²\"] = ad_r2\n",
    "        # 存储评估指标和向量\n",
    "        np.save(folder_path+'metrics.npy', np.array([mae,rmse,smape,r2,ad_r2]))\n",
    "        np.save(folder_path+'pred.npy', preds)\n",
    "        np.save(folder_path+'true.npy', trues)\n",
    "        if args.inverse == False:\n",
    "            pass\n",
    "        return info_dict,preds,trues\n",
    "\n",
    "    # 预测未来\n",
    "    def predict(self, setting,run_name_dir_ckp, run_ex_dir,args,load=False):\n",
    "        # 从_get_data获取数据\n",
    "        pred_data, pred_loader = self._get_data(flag='pred')\n",
    "        pred_date = pred_data.pred_date\n",
    "        if args.freq[-1] == \"t\" or args.freq[-1] == 'h' or args.freq[-1] == 's':\n",
    "            pred_date = [str(p) for p in pred_date[1:]]\n",
    "        else:\n",
    "            pred_date = [str(p).split(\" \")[0] for p in pred_date[1:]]\n",
    "        print(\"本次实验预测未来的时间范围：\",pred_date)\n",
    "        # 加载模型\n",
    "        if load:\n",
    "            path = os.path.join(run_name_dir_ckp ,setting)\n",
    "            # path = os.path.join(run_ex_dir ,setting)\n",
    "            best_model_path = path+'/'+'checkpoint.pth'\n",
    "            self.model.load_state_dict(torch.load(best_model_path))\n",
    "        # 清楚缓存\n",
    "        self.model.eval()\n",
    "        preds = []\n",
    "        \n",
    "        for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n",
    "            # print(batch_x.shape,batch_y.shape,batch_x_mark.shape,batch_y_mark.shape)\n",
    "            # torch.Size([1, 96, 1]) torch.Size([1, 48, 1]) torch.Size([1, 96, 3]) torch.Size([1, 72, 3])\n",
    "            \"\"\"\n",
    "            [1, 96, 1]是输入的一个批次的X数据，可以认为是滑动窗口为96的X。\n",
    "            [1, 48, 1]是输入的一个批次的Y数据，可以认为是滑动窗口为96的X的标签数据，48是inform解码器的开始令牌长度label_len，多步预测的展现。\n",
    "            \n",
    "            [1, 96, 3]是输入的X数据的Q、K、V向量的数组。\n",
    "            [1, 72, 3]是输入的Y数据的Q、K、V向量的数组,其中，72=48+24，48是label_len，24是预测序列长度pred_len，也就是说24是被预测的，这里是作为已知输入的。\n",
    "            \"\"\"\n",
    "            # print(batch_x.shape, batch_y.shape, batch_x_mark.shape, batch_y_mark.shape)\n",
    "            # sys.exit()\n",
    "            pred, true = self._process_one_batch(pred_data, batch_x, batch_y, batch_x_mark, batch_y_mark,args)\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        preds = preds[:, :, -1:] if args.features == 'MS' else preds\n",
    "        # print(preds)\n",
    "        # print(type(preds),len(preds),preds.shape,preds)\n",
    "        # sys.exit()\n",
    "        # result save\n",
    "        folder_path = run_ex_dir+'/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        if args.features == 'M':\n",
    "            preds = preds[0]\n",
    "            print(\"本次实验预测未来的结果：\", preds)\n",
    "            # 存储未来的预测结果到npy文件\n",
    "            np.save(folder_path + 'real_prediction.npy', preds)\n",
    "            assert len(preds) == len(pred_date)\n",
    "            return preds, pred_date\n",
    "        if args.features != 'M':\n",
    "            preds = preds.flatten().tolist()\n",
    "            preds = [round(i, 1) for i in preds]\n",
    "            print(\"本次实验预测未来的结果：\",preds)\n",
    "            # 存储未来的预测结果到npy文件\n",
    "            np.save(folder_path+'real_prediction.npy', preds)\n",
    "            assert len(preds) == len(pred_date)\n",
    "            return preds, pred_date\n",
    "        return preds,pred_date\n",
    "\n",
    "    # 对一个batch进行的编码解码操作，就是训练模型\n",
    "    def _process_one_batch(self, dataset_object, batch_x, batch_y, batch_x_mark, batch_y_mark,args):\n",
    "        global dec_inp\n",
    "        batch_x = batch_x.float().to(self.device)\n",
    "        batch_y = batch_y.float()\n",
    "\n",
    "        batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "        # decoder input\n",
    "        if self.args.padding==0:\n",
    "            # 返回一个形状为为size，size是一个list，代表了数组的shape,类型为torch.dtype，里面的每一个值都是0的tensor\n",
    "            # batch_y.shape[0]是self.lbel_len + self.pred_len\n",
    "            # batch_y.shape[-1]是特征数,单特征预测单特征的情况下，这里是1\n",
    "            dec_inp = torch.zeros([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        elif self.args.padding==1:\n",
    "            dec_inp = torch.ones([batch_y.shape[0], self.args.pred_len, batch_y.shape[-1]]).float()\n",
    "        # 在给定维度上对输入的张量序列seq 进行连接操作。\n",
    "        \"\"\"\n",
    "        outputs = torch.cat(inputs, dim=0) → Tensor\n",
    "        \n",
    "        inputs : 待连接的张量序列，可以是任意相同Tensor类型的python 序列，可以是列表或者元组。\n",
    "        dim : 选择的扩维, 必须在0到len(inputs[0])之间，沿着此维连接张量序列。\n",
    "        \"\"\"\n",
    "        dec_inp = torch.cat([batch_y[:,:self.args.label_len,:], dec_inp], dim=1).float().to(self.device)\n",
    "        # encoder - decoder（编码器-解码器）\n",
    "        # 假如使用自动混合精度训练\n",
    "        if self.args.use_amp:\n",
    "            # pytorch 使用autocast半精度进行加速训练\n",
    "            with torch.cuda.amp.autocast():\n",
    "                # 假如在编码器中输出注意力\n",
    "                if self.args.output_attention:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        # 假如不使用自动混合精度训练\n",
    "        else:\n",
    "            if self.args.output_attention:\n",
    "                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        # 逆标准化输出数据\n",
    "        # if self.args.inverse:\n",
    "        #     outputs = dataset_object.inverse_transform(outputs)\n",
    "        f_dim = -1 if self.args.features=='MS' else 0\n",
    "        # 如果是MS。那么只留有一列输出\n",
    "        # outputs = outputs[:, :, 1:] if args.features == 'MS' else outputs\n",
    "        # 对y进行解码\n",
    "        # 取出pred\n",
    "        batch_y = batch_y[:,-self.args.pred_len:,f_dim:].to(self.device)\n",
    "\n",
    "        # 如果是M任务，那么进行打平再输出去计算梯度\n",
    "        # output作为预测值，batch_y(取出pred部分，也就是长度40)作为真实值\n",
    "        return outputs, batch_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 定义参数集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameter():\n",
    "    parser = argparse.ArgumentParser(description='[Informer] Long Sequences Forecasting')\n",
    "    parser.add_argument('--root_path', type=str, default='./data/batteryNature/', help='（训练）数据文件的根路径（root path of the data file）')\n",
    "    parser.add_argument('--target', type=str, default='price', help='S或MS任务中的目标特征列名（target feature in S or MS task）')\n",
    "  \n",
    "    parser.add_argument('--freq', type=str, default='w', help='时间特征编码的频率（freq for time features encoding）, '\n",
    "                                                              '选项（options）:[s:secondly, t:minutely, h:hourly, d:daily, b:工作日（business days）, w:weekly, m:monthly], '\n",
    "                                                              '你也可以使用更详细的频率，比如15分钟或3小时（you can also use more detailed freq like 15min or 3h）')\n",
    "    # 存储模型位置的地方\n",
    "    parser.add_argument('--checkpoints', type=str, default='./checkpoints/',\n",
    "                        help='模型检查点的位置（location of model checkpoints）')\n",
    "    # Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "    # 指的应该是channel的个数\n",
    "    parser.add_argument('--lstm_hidden_size', type=int, default=2, help='LSTM的隐藏层维度')\n",
    "    parser.add_argument('--lstm_num_layers', type=int, default=2, help='LSTM的层数')\n",
    "    parser.add_argument('--enc_in', type=int, default=1, help='编码器输入大小（encoder input size）')\n",
    "    parser.add_argument('--dec_in', type=int, default=1, help='解码器输入大小（decoder input size）')\n",
    "    parser.add_argument('--c_out', type=int, default=1, help='输出尺寸（output size）')\n",
    "    parser.add_argument('--d_model', type=int, default=16, help='模型维数（dimension of model）默认是512-------------------------模型维数')\n",
    "    parser.add_argument('--n_heads', type=int, default=8, help='（num of heads）multi-head self-attention的head数')\n",
    "    parser.add_argument('--e_layers', type=int, default=2, help='编码器层数（num of encoder layers）-------------------编码器层数')\n",
    "    parser.add_argument('--d_layers', type=int, default=1, help='解码器层数（num of decoder layers）---------------------解码器层数')\n",
    "    # 源代码也是设置的这些值，可以先不改\n",
    "    parser.add_argument('--s_layers', type=str, default='3,2,1', help='堆栈编码器层数（num of stack encoder layers）---------------堆栈编码器层数')\n",
    "    parser.add_argument('--d_ff', type=int, default=32, help='fcn维度（dimension of fcn），默认是2048--------------------FCN维度')\n",
    "    \"\"\"\n",
    "    预测未来短期时间1~3个月的时候，d_model和d_ff进行设置的小，如16、32或者16,16；\n",
    "    预测未来短期时间4个月及以上的时候，d_model和d_ff进行设置的稍微大一点点，如16、64或者32,64；32,128。\n",
    "    \"\"\"\n",
    "    # 源代码也是5，可以先不改\n",
    "    parser.add_argument('--factor', type=int, default=5, help='probsparse attn factor')\n",
    "    parser.add_argument('--padding', type=int, default=0, help='padding type')\n",
    "    # 即是否使用下采样，使用该参数表示不进行下采样\n",
    "    parser.add_argument('--distil', action='store_false', help='是否在编码器中不使用知识蒸馏，使用此参数意味着不使用蒸馏'\n",
    "                                                               '（whether to use distilling in encoder, using this argument means not using distilling）',\n",
    "                        default=True)\n",
    "    # prob是informer提出的一个创新点\n",
    "    parser.add_argument('--attn', type=str, default='prob', help='用于编码器的注意力机制，选项：[prob, full]'\n",
    "                                                                 '（attention used in encoder, options:[prob, full]）')\n",
    "\n",
    "    parser.add_argument('--embed', type=str, default='timeF', help='时间特征编码，选项：[timeF, fixed, learned]'\n",
    "                                                                   '（time features encoding, options:[timeF, fixed, learned]）')\n",
    "    parser.add_argument('--activation', type=str, default='gelu', help='activation')\n",
    "    parser.add_argument('--output_attention', action='store_true',default=True, help='是否在编码器中输出注意力'\n",
    "                                                                        '（whether to output attention in ecoder）')\n",
    "\n",
    "    parser.add_argument('--do_predict', action='store_true', default=True, help='是否预测看不见的未来数据'\n",
    "                                                                                '（whether to predict unseen future data）')\n",
    "    parser.add_argument('--mix', action='store_true', help='在生成解码器中使用混合注意力'\n",
    "                                                            '（use mix attention in generative decoder）', default=True)\n",
    "    # nargs=‘+’：表示参数可设置一个或多个\n",
    "    parser.add_argument('--cols', type=str, nargs='+', help='将数据文件中的某些cols作为输入特性'\n",
    "                                                            '（certain cols from the data files as the input features）')\n",
    "    parser.add_argument('--num_workers', type=int, default=0, help='工作的数据加载器数量 data loader num workers')\n",
    "\n",
    "    parser.add_argument('--train_epochs', type=int, default=60, help='train epochs')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help='训练输入数据的批大小 batch size of train input data--------------------批次大小，原文用的32')\n",
    "    parser.add_argument('--patience', type=int, default=15, help='提前停止的连续轮数 early stopping patience')\n",
    "    parser.add_argument('--des', type=str, default='forecasting', help='实验描述 exp description')\n",
    "\n",
    "    parser.add_argument('--loss', type=str, default='mse', help='损失函数选项：loss function【mse、huberloss、L1loss】--------------------损失函数')\n",
    "\n",
    "    parser.add_argument('--lradj', type=str, default='type1', help='校正的学习率adjust learning rate----------------------学习率更新算法')\n",
    "    parser.add_argument('--use_amp', action='store_true', help='使用自动混合精度训练 use automatic mixed precision training--------',\n",
    "                        default=True)\n",
    "    parser.add_argument('--output', type=str, default='./output', help='输出路径')\n",
    "    # 想要获得最终预测的话这里应该设置为True；否则将是获得一个标准化的预测。即进行了 逆标准化\n",
    "    parser.add_argument('--inverse', action='store_true', help='逆标准化输出数据 inverse output data', default=True)\n",
    "    parser.add_argument('--scale', action='store_true', help='是否进行标准化，默认是True', default=True)\n",
    "    parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
    "    parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
    "    parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
    "    parser.add_argument('--devices', type=str, default='0,1,2,3', help='device ids of multile gpus')\n",
    "\n",
    "    parser.add_argument('--itr', type=int, default=1, help='实验次数 experiments times----------------------------------多少次实验')\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.01, help='optimizer learning rate-----------------------------初始学习率')\n",
    "\n",
    "    parser.add_argument('--save_model_choos', type=bool, default=True, help='是否保存模型，不保存的话不占用IO')\n",
    "    parser.add_argument('--is_show_label', type=bool, default=True, help='是否显示图例数值')\n",
    "    # seq_len其实就是n个滑动窗口的大小，pred_len就是一个滑动窗口的大小\n",
    "    # 这个文件中用的是12个预测8个\n",
    "\n",
    "    parser.add_argument('--seq_len', type=int, default=200,\n",
    "                        help='Informer编码器的输入序列长度（input sequence length of Informer encoder）原始默认为96------------------------编码器输入序列长度seq_len')\n",
    "    # label_len 和 pred_len 加起来是 decoder 的输入长度\n",
    "    parser.add_argument('--label_len', type=int, default=100,\n",
    "                        help='inform解码器的开始令牌长度（start token length of Informer decoder），原始默认为48-------------------------解码器的开始令牌起始位置label_len')\n",
    "    # pred_len就是要预测的序列长度（要预测未来多少个时刻的数据），也就是Decoder中置零的那部分的长度\n",
    "    parser.add_argument('--pred_len', type=int, default=100 ,help='预测序列长度（prediction sequence length）原始默认为24------------------预测序列长度pred_len')\n",
    "    \n",
    "    parser.add_argument('--dropout', type=float, default=0.1,\n",
    "                        help='dropout，长序列预测用0.5，短期预测用0.05~0.2(一般是0.05)，如果shuffle_flag的训练部分为True，那么该值直接设置为0;模型参数多设置为0.5，要在0.5范围内；视情况而定。----')\n",
    "\n",
    "    # 这两个应该用不到 \n",
    "    parser.add_argument('--train_proportion', type=float, default=0.8, help='训练集比例')\n",
    "    parser.add_argument('--test_proportion', type=float, default=0.1, help='测试集比例')\n",
    "\n",
    "    parser.add_argument('--seed', type=int, default=12345, help='random seed 随机数种子')\n",
    "    parser.add_argument('--random_choos', type=bool, default=False, help='random seed 随机数种子，是否随机，为True一般用于多次实验')\n",
    "    # 存在output文件夹下\n",
    "    parser.add_argument('--sub_them', type=str, default='2变量多对一', help='单次运行的存储文件夹字后面的内容--------------------存储数据父文件夹名字')\n",
    "    # parser.add_argument('--sub_them', type=str, default='月度', help='单次运行的存储文件夹的月字后面的内容--------------------存储数据父文件夹名字')\n",
    "    parser.add_argument('--true_sheetname', type=str, default='Sheet1', help='真实值的月份名称,execl文件的sheetname--------------------------真实值的月份数值')\n",
    "    # parser.add_argument('--true_price', type=str, default='7月第二第三周', help='真实值的月份名称,execl文件的sheetname--------------------------真实值的月份数值')\n",
    "    # parser.add_argument('--true_price', type=str, default='1-6月', help='真实值的月份名称,execl文件的sheetname--------------------------真实值的月份数值')\n",
    "    parser.add_argument('--model', type=str, required=False, default='informer',\n",
    "                        help='model of experiment, options: [informer, informerstack]')\n",
    "   \n",
    "    parser.add_argument('--data', type=str, required=False, default='batteryNature', help='data them，取决了在data parse中寻找的是哪个数据文件的配置,很重要')\n",
    "    # parser.add_argument('--data', type=str, required=False, default='chicken_MS',help='data them，取决了在data parse中寻找的是哪个数据文件的配置,很重要')\n",
    "\n",
    "    # parser.add_argument('--true_file', type=str, required=False, default='./TrueValue/2020年真实值.xls', help='真实值数据的文件名')\n",
    "    # parser.add_argument('--true_file', type=str, required=False, default='./TrueValue/周粒度实验的真实价格.xls', help='真实值数据的文件名')\n",
    "    # parser.add_argument('--true_file', type=str, required=False, default='./TrueValue/月粒度实验的真实价格.xls', help='真实值数据的文件名')\n",
    "    # parser.add_argument('--true_file', type=str, required=False, default='./TrueValue/日粒度实验的真实价格.xls', help='真实值数据的文件名')\n",
    "    # parser.add_argument('--true_file', type=str, required=False, default='./TrueValue/日粒度与月粒度对比实验的真实价格.xls', help='真实值数据的文件名')\n",
    "    parser.add_argument('--true_file', type=str, required=False, default='./TrueValue/周-预测的rose真实价格.xls', help='真实值数据的文件名')\n",
    "\n",
    "    # parser.add_argument('--data_path', type=str, default='周粒度-多特征数据汇总.csv', help='data file')\n",
    "    # 训练数据\n",
    "    # 不用管，内部写死了\n",
    "    parser.add_argument('--data_path', type=str, default='电池循环汇总(训练数据).xlsx', help='data file')\n",
    "\n",
    "    # 不用管，内部写死\n",
    "    parser.add_argument('--columns', type=list, required=False, default=[\"date\",'price'], help='存储预测数据的时候的列名，多对多M')\n",
    "    # parser.add_argument('--columns', type=list, required=False, default=[\"time\", 'GZ_maize_prince','CD_maize_price','CD_SBM_price','ZJ_SBM_prince','price'], help='存储预测数据的时候的列名，多对一MS、一对一S任务')\n",
    "    # parser.add_argument('--shuffle_flag_train', type=str, required=False, default=True, help='训练的时候是否打乱数据[未完成该定义]')\n",
    "  \n",
    "    parser.add_argument('--features', type=str, default='S', help='预测任务选项（forecasting task, options）:[M, S, MS]; '\n",
    "                                                                   'M:多变量预测多元（multivariate predict multivariate）, '\n",
    "                                                                   'S:单变量预测单变量（univariate predict univariate）, '\n",
    "                                                                   'MS:多变量预测单变量（multivariate predict univariate）')\n",
    "    #----------------S任务下:下面的配置项不用修改,如果需要再进行修改-------------------\n",
    "    parser.add_argument('--lag_sign', type=bool,required=False, default=False, help=\"是否进行滞后性处理，只需要进行一次即可。开启此选项进行一次处理后修改回为False，才有效。-------\")\n",
    "    parser.add_argument('--lag', type=int, default=0, help=\"滞后性处理的数值，代表滞后了多少，仅仅用于M或者MS模式----------\")\n",
    "    parser.add_argument('--original_multi_path', type=str, default='./Time_data/Uncleaned_data/价格-供求数据.xls',\n",
    "                        help=\"供求价格的excel文件所在的路径\")\n",
    "    parser.add_argument('--output_multi_originalPath', type=str, default=\"./Time_data/Uncleaned_data/未进行滞后处理-价格-供求数据.csv\",\n",
    "                        help=\"生成供求价格的csv文件路径\")\n",
    "    parser.add_argument('--single_path', type=str, default=\"./Time_data/价格.csv\", help=\"完整月均价数据的所在路径\")\n",
    "    parser.add_argument('--laged_multi_path', type=str, default=\"./data/Time_data/供求-价格.csv\", help=\"经过滞后处理后的价格-供求数据\")\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "\n",
    "\"\"\"\n",
    "enc_in: informer的encoder的输入维度\n",
    "dec_in: informer的decoder的输入维度\n",
    "c_out: informer的decoder的输出维度\n",
    "d_model: informer中self-attention的输入和输出向量维度\n",
    "n_heads: multi-head self-attention的head数\n",
    "e_layers: informer的encoder的层数\n",
    "d_layers: informer的decoder的层数\n",
    "d_ff: self-attention后面的FFN的中间向量表征维度\n",
    "factor: probsparse attention中设置的因子系数\n",
    "padding: decoder的输入中，作为占位的x_token是填0还是填1\n",
    "distil: informer的encoder是否使用注意力蒸馏\n",
    "attn: informer的encoder和decoder中使用的自注意力机制\n",
    "embed: 输入数据的时序编码方式\n",
    "activation: informer的encoder和decoder中的大部分激活函数\n",
    "output_attention: 是否选择让informer的encoder输出attention以便进行分析\n",
    "\n",
    "小数据集的预测可以先使用默认参数或适当减小d_model和d_ff的大小\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 主函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 前期准备以及训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_hidden_size_vlaues=[1,4,8,16,32]\n",
    "lstm_num_layers_vlaues=[1,2,3]\n",
    "d_model_values=[32]\n",
    "d_ff_values=[128,256]\n",
    "# lstm_hidden_size_vlaues=[4]\n",
    "# lstm_num_layers_vlaues=[2]\n",
    "# d_model_values=[32]\n",
    "# d_ff_values=[256]\n",
    "seed_values=[12345,54321,42]\n",
    "for lstm_hidden_size in lstm_hidden_size_vlaues:\n",
    "    for lstm_num_layers in lstm_num_layers_vlaues:\n",
    "        for d_model in d_model_values:\n",
    "            for d_ff in d_ff_values:\n",
    "                for seeds in seed_values:\n",
    "                    if d_ff >= d_model:\n",
    "        \n",
    "                        # 进行parser的变量初始化，获取实例。\n",
    "                        args = initialize_parameter()\n",
    "                        args.lstm_hidden_size=lstm_hidden_size\n",
    "                        args.lstm_num_layers=lstm_num_layers\n",
    "                        args.d_model=d_model\n",
    "                        args.d_ff=d_ff\n",
    "                        args.seed=seeds\n",
    "                        # print(\"model：\\t\",args.model)\n",
    "                        # 默认为false，暂时不用管\n",
    "                        if args.lag_sign:\n",
    "                            lag_processor_main(args.original_multi_path, args.output_multi_originalPath, args.single_path, args.lag, args.laged_multi_path)\n",
    "                            print(\"已经处理完 滞后性数值进程---回退args.lag_sign参数为False并且建议定制好实验才可继续往下进行~\")\n",
    "                            sys.exit()\n",
    "                        # 判断GPU是否能够使用，并获取标识\n",
    "                        args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "                        # 判断是否使用多块GPU，默认不使用多块GPU\n",
    "                        if args.use_gpu and args.use_multi_gpu:\n",
    "                            # 获取显卡列表，type：str\n",
    "                            args.devices = args.devices.replace(' ', '')\n",
    "                            # 拆分显卡获取列表，type：list\n",
    "                            device_ids = args.devices.split(',')\n",
    "                            # 转换显卡id的数据类型\n",
    "                            args.device_ids = [int(id_) for id_ in device_ids]\n",
    "                            print(\"显卡设备id：\", args.device_ids)\n",
    "                            # 获取第一块显卡\n",
    "                            args.gpu = args.device_ids[0]\n",
    "                        args.gpu='1'    \n",
    "                            \n",
    "                            \n",
    "                        # 初始化数据解析器，用于定义训练模式、预测模式、数据粒度的初始化选项。\n",
    "                        \"\"\"\n",
    "                        字典格式：{数据主题：{data：数据路径，'T':目标字段列名,'M'：，'S'：，'MS':}}\n",
    "\n",
    "                        'M:多变量预测多元（multivariate predict multivariate）'，\n",
    "                        'S:单变量预测单变量（univariate predict univariate）'，\n",
    "                        'MS:多变量预测单变量（multivariate predict univariate）'。\n",
    "                        \"\"\"\n",
    "                        # 直接在data_parser中就可以设定args.enc_in, args.dec_in, args.c_out\n",
    "                        data_parser = {\n",
    "                            \n",
    "                            'rose': {'data': 'data.csv', 'T': 'price', 'M': [2, 2, 2], 'S': [1, 1, 1], 'MS': [2, 2, 1]},\n",
    "                            'chicken_MS': {'data': '周粒度-多特征数据汇总.csv', 'T': 'price', 'M': [2, 2, 2], 'S': [1, 1, 1], 'MS': [5, 5, 1]},\n",
    "                            'Time_data': {'data': 'most_samll_test_1个变量.csv', 'T': 'X4', 'M': [3, 3, 3], 'S': [1, 1, 1], 'MS': [3, 3, 1]},\n",
    "                            # T不用管，我内部写死，实际上只看 'S': [1, 1, 1]，这个是单变量预测单变量\n",
    "                            'min': {'data': 'min2019.xlsx', 'T': 'price', 'MS': [2, 2, 2], 'S': [1, 1, 1], 'MS': [2, 2, 1]},\n",
    "                            # T不用管，文件地址也不用管，我内部写死，实际上只看 'S': [1, 1, 1]，这个是单变量预测单变量\n",
    "                            'batteryNature': {'data': '电池', 'T': 'price', 'M': [2, 2, 2], 'S': [1, 1, 1], 'MS': [2, 2, 1]},\n",
    "                        }\n",
    "                        # 判断在parser中定义的数据主题是否在解析器中\n",
    "                        if args.data in data_parser.keys():  \n",
    "                            # 根据args里面定义的数据主题，获取对应的初始化数据解析器info信息，type：dict\n",
    "                            # 此处data_info就是获取到的 data_parse中的 rose的数据\n",
    "                            data_info = data_parser[args.data]\n",
    "                            # 获取该数据主题的数据文件的路径（相对路径），父目录在上面定义过了\n",
    "                            args.data_path = data_info['data']\n",
    "                            # 从数据解析器中获取 S或 MS任务中的目标特征列名。\n",
    "                            # 此处target没有用，内部写死了\n",
    "                            args.target = data_info['T']\n",
    "                            # 从数据解析器中 根据变量features的初始化信息 获取 编码器输入大小，解码器输入大小，输出尺寸\n",
    "                            # args.features取值为S、M、MS，即单变量以及多变量\n",
    "                            # rose是S，所以取的是1，1，1，分别描述了encoder输入特征种类数、decoder输入特征种类数以及模型输出特征种类数，那是不是对于rose来说，M与MS字段没有作用\n",
    "                            args.enc_in, args.dec_in, args.c_out = data_info[args.features]\n",
    "                        # 堆栈编码器层数，type：list，可以先不管\n",
    "                        args.s_layers = [int(s_l) for s_l in args.s_layers.replace(' ', '').split(',')]\n",
    "                        # 时间特征编码的频率，就是进行特征工程的时候时间粒度选取多少\n",
    "                        # 不用管，内部写死了\n",
    "                        args.detail_freq = args.freq\n",
    "                        args.freq = args.freq[-1:]\n",
    "                        # print('Args in experiment:')\n",
    "                        # print(args)\n",
    "                        now_time = datetime.datetime.now().strftime('%mM_%dD %HH:%Mm:%Ss').replace(\" \", \"_\").replace(\":\", \"_\")\n",
    "                        # 获取模型实例\n",
    "                        Exp = Exp_Informer\n",
    "                        # 获取page实例\n",
    "                        # args.itr表示试验次数，page相当于与就是几号实验\n",
    "                        # 用于可视化\n",
    "                        # page_loss = get_page_loss(args.itr)\n",
    "                        # page_predict_true = get_page_value(args.itr)\n",
    "                        # page_predict = get_page_noTrue(args.itr)\n",
    "                        # page_test = get_page_Test(args.itr)\n",
    "\n",
    "                        \"\"\"\n",
    "                        存储数据的字典，为了将预测和均值和真实值存储到本地,(若是没有真实值，那么不存储真实值)\n",
    "                        存储未来预测值的真实数据，为了做可视化和评估未来\n",
    "                        存储模型信息的json文件\n",
    "                        存储预测未来的时候生成的时间\n",
    "                        \"\"\"\n",
    "\n",
    "                        # info_dict存储的是模型信息\n",
    "                        info_dict = dict()\n",
    "\n",
    "                        # sys.exit()\n",
    "                        # 构建单次运行的存储路径：informer_e50_b1024_dModel32_dFF128_s80_l40_p_40_min\n",
    "                        run_name_dir_old = args.model + \"_e\" + str(args.train_epochs) + \"_b\" + str(args.batch_size) + \"_lhs\" + str(args.lstm_hidden_size) + \"_lnl\" + str(args.lstm_num_layers) + \"_dModel\" + str(args.d_model) + \"_dFF\" + str(args.d_ff)+ \"_s\" + str(args.seq_len) + \"_l\" + str(args.label_len) + \"_p\" + str(args.pred_len)+ \"_\" + args.data\n",
    "                        # 右侧的args.output表示output文件夹 \n",
    "                        # output\\rose_1变量一对一_w\n",
    "                        args.output = os.path.join(args.output,args.data+\"_\" + args.sub_them)\n",
    "\n",
    "\n",
    "                        # 输出的文件夹位置：output\\min_1变量一对一\\informer_e50_b1024_dModel32_dFF128_s80_l40_p_40_min\n",
    "                        run_name_dir = os.path.join(args.output, run_name_dir_old)\n",
    "                        if not os.path.exists(run_name_dir):\n",
    "                            os.makedirs(run_name_dir)\n",
    "                        # 单次运行的n个实验的模型存储的路径：需要判断是否存在，训练的时候已经判断了\n",
    "                        # ./checkpoints/batterySD\n",
    "                        run_name_dir_ckp_main = os.path.join(args.checkpoints, args.data)\n",
    "                        # './checkpoints/batterySD\\\\TwoFeatures(Δη,QD)\\\\informer_e50_b32_dModel32_dFF128_s100_l50_p50_batterySD'   \n",
    "                        run_name_dir_ckp = os.path.join(run_name_dir_ckp_main,'minNew/informerLSTM(pretreatment,ResNet,XL)' ,run_name_dir_old)\n",
    "\n",
    "                        # 要进行多少次实验，一次实验就是完成一个模型的训练-测试-预测 过程。默认2次，rose用了5次\n",
    "                        for ii in range(args.itr):\n",
    "                            print(\"-------------.....第{}次实验.....------------\".format(ii+1))\n",
    "                            # 存到output文件夹下了\n",
    "                            run_ex_dir = os.path.join(run_name_dir, \"第_{}_次实验记录\".format(ii + 1))\n",
    "                            if args.random_choos == True:\n",
    "                                pass\n",
    "                            else:\n",
    "                                # 固定随机性\n",
    "                                # setup_seed(args.seed)\n",
    "                                seed=args.seed\n",
    "                                random.seed(seed)\n",
    "                                os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "                                np.random.seed(seed)\n",
    "                                torch.manual_seed(seed)\n",
    "                                torch.cuda.manual_seed(seed)\n",
    "                                torch.cuda.manual_seed_all(seed)\n",
    "                                torch.backends.cudnn.deterministic =True\n",
    "                            if not os.path.exists(run_ex_dir):\n",
    "                                os.makedirs(run_ex_dir)\n",
    "                            # 添加实验info，存到 json文件中\n",
    "                            info_dict[\"实验序号\"] = ii+1\n",
    "                            info_dict[\"model\"] = args.model\n",
    "                            info_dict[\"data_them\"] = args.data\n",
    "                            info_dict[\"编码器的输入序列长度 seq_len【滑动窗口大小】\"] = args.seq_len\n",
    "                            info_dict[\"解码器的开始解码令牌起始位置 label_len\"] = args.label_len\n",
    "                            info_dict[\"预测未来序列长度 pred_len\"] = args.pred_len\n",
    "                            info_dict[\"时间特征编码的频率【数据粒度】freq\"] = args.freq\n",
    "                            info_dict[\"dorpout\"] = args.dropout\n",
    "                            info_dict[\"批次大小 batch_size\"] = args.batch_size\n",
    "                            info_dict[\"提前停止的连续轮数 patience\"] = args.patience\n",
    "                            info_dict[\"随机种子seed\"] = args.seed\n",
    "                            info_dict[\"损失函数loss\"] = args.loss\n",
    "                            info_dict[\"是否随机实验 random_choos\"] = args.random_choos\n",
    "                            info_dict[\"滞后数值 lag\"] = args.lag\n",
    "                            info_dict[\"编码器输入大小 enc_in\"] = args.enc_in\n",
    "                            info_dict[\"解码器输入大小 dec_in\"] = args.dec_in\n",
    "                            info_dict[\"输出尺寸 c_out\"] = args.c_out\n",
    "                            info_dict[\"模型维数 d_model\"] = args.d_model\n",
    "                            info_dict[\"多头部注意力机制的头部个数 n_heads\"] = args.n_heads\n",
    "                            info_dict[\"编码器层数 e_layers\"] = args.e_layers\n",
    "                            info_dict[\"解码器层数 d_layers\"] = args.d_layers\n",
    "                            info_dict[\"堆栈编码器层数 s_layers\"] = str(args.s_layers)\n",
    "                            info_dict[\"self-attention后面的FFN的中间向量表征维度 d_ff\"] = args.d_ff\n",
    "                            info_dict[\"probsparse attn factor\"] = args.factor\n",
    "                            info_dict[\"是否在编码器中不使用知识蒸馏 distil\"] = args.distil\n",
    "                            info_dict[\"编码器的注意力机制 attn\"] = args.attn\n",
    "                            info_dict[\"填充的值 padding\"] = args.padding\n",
    "                            info_dict[\"时间特征编码 embed\"] = args.embed\n",
    "                            info_dict[\"激活函数 activation\"] = args.activation\n",
    "                            info_dict[\"是否在编码器中输出注意力 output_attention\"] = args.output_attention\n",
    "                            info_dict[\"是否预测看不见的未来数据 do_predict\"] = args.do_predict\n",
    "                            info_dict[\"在生成解码器中使用混合注意力 mix\"] = args.mix\n",
    "                            info_dict[\"实验次数 itr\"] = args.itr\n",
    "                            info_dict[\"校正的学习率 lradj\"] = args.lradj\n",
    "                            info_dict[\"使用自动混合精度训练 use_amp\"] = args.use_amp\n",
    "                            info_dict[\"逆标准化输出数据 inverse\"] = args.inverse\n",
    "                            info_dict[\"优化器初始学习率 learning_rate\"] = args.learning_rate\n",
    "\n",
    "                            \n",
    "                            # 实验设置记录要点，方便打印，同时也作为文件名字传入参数，setting record of experiments\n",
    "                            # args.model = 'informer'，args.data = 'min'，args.features = 'ETTh1'，最后一个不用管，内部写死了\n",
    "                            setting = '{}_{}_{}_{}'.format(ii + 1, args.model, args.data, args.features)\n",
    "                            # 设置实验，将数据参数和模型变量传入实例\n",
    "                            exp = Exp(args)  # set experiments\n",
    "\n",
    "                        \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "\n",
    "                            # # 模型测试：存在问题：无法取到时间，boder不确定\n",
    "                            # print('>>>>>>>testing :  {}  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "                            # # test： 返回的是数组\n",
    "                            # # sys.exit()\n",
    "                            # info_dict, test_pred, test_true = exp.test(setting, info_dict, run_ex_dir,args)\n",
    "\n",
    "                            # future_pred, pred_date = 0, 0\n",
    "                            # # 做预测\n",
    "                            # if args.do_predict:\n",
    "                            #     print('>>>>>>>predicting :  {}  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "                            #     # 模型预测未来\n",
    "                            #     future_pred, pred_date = exp.predict(setting, run_name_dir_ckp, run_ex_dir,args, load=args.save_model_choos)\n",
    "                            #     pred_dates = pred_date\n",
    "                            #     # assert pred_dates == pred_dates2\n",
    "\n",
    "                            print('--------------------------------------------------------------------------------------')\n",
    "                            print('--------------------------------------------------------------------------------------')\n",
    "                            print('--------------------------------------------------------------------------------------')\n",
    "                            print('>>>>>>>start training :  {}  >>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "                            \n",
    "                            print('lstm_hidden_size=', args.lstm_hidden_size)\n",
    "                            print('lstm_num_layers=', args.lstm_num_layers)\n",
    "                            print('d_model=', args.d_model)\n",
    "                            print('d_ff=', args.d_ff)\n",
    "                            print('batch=', args.batch_size)\n",
    "                            print('seeds=',args.seed)\n",
    "                            model, info_dict, all_epoch_train_loss, all_epoch_vali_loss, all_epoch_test_loss, epoch_count = exp.train(\n",
    "                                setting, info_dict, run_name_dir_ckp, run_ex_dir,args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2模型训练好后执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_hidden_size_vlaues=[1,4,8,16,32]\n",
    "lstm_num_layers_vlaues=[1,2,3]\n",
    "d_model_values=[32]\n",
    "d_ff_values=[128,256]\n",
    "# lstm_hidden_size_vlaues=[4]\n",
    "# lstm_num_layers_vlaues=[2]\n",
    "# d_model_values=[32]\n",
    "# d_ff_values=[256]\n",
    "seed_values=[12345]\n",
    "for lstm_hidden_size in lstm_hidden_size_vlaues:\n",
    "    for lstm_num_layers in lstm_num_layers_vlaues:\n",
    "        for d_model in d_model_values:\n",
    "            for d_ff in d_ff_values:\n",
    "                for seeds in seed_values:\n",
    "                    if d_ff >= d_model:\n",
    "            \n",
    "                        # 进行parser的变量初始化，获取实例。\n",
    "                        args = initialize_parameter()\n",
    "                        args.lstm_hidden_size=lstm_hidden_size\n",
    "                        args.lstm_num_layers=lstm_num_layers\n",
    "                        args.d_model=d_model\n",
    "                        args.d_ff=d_ff\n",
    "                        args.seed=seeds\n",
    "\n",
    "                        # print(\"model：\\t\",args.model)\n",
    "                        # 默认为false，暂时不用管\n",
    "                        if args.lag_sign:\n",
    "                            lag_processor_main(args.original_multi_path, args.output_multi_originalPath, args.single_path, args.lag, args.laged_multi_path)\n",
    "                            print(\"已经处理完 滞后性数值进程---回退args.lag_sign参数为False并且建议定制好实验才可继续往下进行~\")\n",
    "                            sys.exit()\n",
    "                        # 判断GPU是否能够使用，并获取标识\n",
    "                        args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "                        # 判断是否使用多块GPU，默认不使用多块GPU\n",
    "                        if args.use_gpu and args.use_multi_gpu:\n",
    "                            # 获取显卡列表，type：str\n",
    "                            args.devices = args.devices.replace(' ', '')\n",
    "                            # 拆分显卡获取列表，type：list\n",
    "                            device_ids = args.devices.split(',')\n",
    "                            # 转换显卡id的数据类型\n",
    "                            args.device_ids = [int(id_) for id_ in device_ids]\n",
    "                            print(\"显卡设备id：\", args.device_ids)\n",
    "                            # 获取第一块显卡\n",
    "                            args.gpu = args.device_ids[0]\n",
    "                        args.gpu='1'    \n",
    "                            \n",
    "                            \n",
    "                        # 初始化数据解析器，用于定义训练模式、预测模式、数据粒度的初始化选项。\n",
    "                        \"\"\"\n",
    "                        字典格式：{数据主题：{data：数据路径，'T':目标字段列名,'M'：，'S'：，'MS':}}\n",
    "\n",
    "                        'M:多变量预测多元（multivariate predict multivariate）'，\n",
    "                        'S:单变量预测单变量（univariate predict univariate）'，\n",
    "                        'MS:多变量预测单变量（multivariate predict univariate）'。\n",
    "                        \"\"\"\n",
    "                        # 直接在data_parser中就可以设定args.enc_in, args.dec_in, args.c_out\n",
    "                        data_parser = {\n",
    "                            \n",
    "                            'rose': {'data': 'data.csv', 'T': 'price', 'M': [2, 2, 2], 'S': [1, 1, 1], 'MS': [2, 2, 1]},\n",
    "                            'chicken_MS': {'data': '周粒度-多特征数据汇总.csv', 'T': 'price', 'M': [2, 2, 2], 'S': [1, 1, 1], 'MS': [5, 5, 1]},\n",
    "                            'Time_data': {'data': 'most_samll_test_1个变量.csv', 'T': 'X4', 'M': [3, 3, 3], 'S': [1, 1, 1], 'MS': [3, 3, 1]},\n",
    "                            # T不用管，我内部写死，实际上只看 'S': [1, 1, 1]，这个是单变量预测单变量\n",
    "                            'min': {'data': 'min2019.xlsx', 'T': 'price', 'MS': [2, 2, 2], 'S': [1, 1, 1], 'MS': [2, 2, 1]},\n",
    "                            # T不用管，文件地址也不用管，我内部写死，实际上只看 'S': [1, 1, 1]，这个是单变量预测单变量\n",
    "                            'batteryNature': {'data': '电池', 'T': 'price', 'M': [2, 2, 2], 'S': [1, 1, 1], 'MS': [2, 2, 1]},\n",
    "                        }\n",
    "                        # 判断在parser中定义的数据主题是否在解析器中\n",
    "                        if args.data in data_parser.keys():  \n",
    "                            # 根据args里面定义的数据主题，获取对应的初始化数据解析器info信息，type：dict\n",
    "                            # 此处data_info就是获取到的 data_parse中的 rose的数据\n",
    "                            data_info = data_parser[args.data]\n",
    "                            # 获取该数据主题的数据文件的路径（相对路径），父目录在上面定义过了\n",
    "                            args.data_path = data_info['data']\n",
    "                            # 从数据解析器中获取 S或 MS任务中的目标特征列名。\n",
    "                            # 此处target没有用，内部写死了\n",
    "                            args.target = data_info['T']\n",
    "                            # 从数据解析器中 根据变量features的初始化信息 获取 编码器输入大小，解码器输入大小，输出尺寸\n",
    "                            # args.features取值为S、M、MS，即单变量以及多变量\n",
    "                            # rose是S，所以取的是1，1，1，分别描述了encoder输入特征种类数、decoder输入特征种类数以及模型输出特征种类数，那是不是对于rose来说，M与MS字段没有作用\n",
    "                            args.enc_in, args.dec_in, args.c_out = data_info[args.features]\n",
    "                        # 堆栈编码器层数，type：list，可以先不管\n",
    "                        args.s_layers = [int(s_l) for s_l in args.s_layers.replace(' ', '').split(',')]\n",
    "                        # 时间特征编码的频率，就是进行特征工程的时候时间粒度选取多少\n",
    "                        # 不用管，内部写死了\n",
    "                        args.detail_freq = args.freq\n",
    "                        args.freq = args.freq[-1:]\n",
    "                        # print('Args in experiment:')\n",
    "                        # print(args)\n",
    "                        now_time = datetime.datetime.now().strftime('%mM_%dD %HH:%Mm:%Ss').replace(\" \", \"_\").replace(\":\", \"_\")\n",
    "                        # 获取模型实例\n",
    "                        Exp = Exp_Informer\n",
    "                        # 获取page实例\n",
    "                        # args.itr表示试验次数，page相当于与就是几号实验\n",
    "                        # 用于可视化\n",
    "                        # page_loss = get_page_loss(args.itr)\n",
    "                        # page_predict_true = get_page_value(args.itr)\n",
    "                        # page_predict = get_page_noTrue(args.itr)\n",
    "                        # page_test = get_page_Test(args.itr)\n",
    "\n",
    "                        \"\"\"\n",
    "                        存储数据的字典，为了将预测和均值和真实值存储到本地,(若是没有真实值，那么不存储真实值)\n",
    "                        存储未来预测值的真实数据，为了做可视化和评估未来\n",
    "                        存储模型信息的json文件\n",
    "                        存储预测未来的时候生成的时间\n",
    "                        \"\"\"\n",
    "\n",
    "                        # info_dict存储的是模型信息\n",
    "                        info_dict = dict()\n",
    "\n",
    "                        # sys.exit()\n",
    "                        # 构建单次运行的存储路径：informer_e50_b1024_dModel32_dFF128_s80_l40_p_40_min\n",
    "                        run_name_dir_old = args.model + \"_e\" + str(args.train_epochs) + \"_b\" + str(args.batch_size) + \"_lhs\" + str(args.lstm_hidden_size) + \"_lnl\" + str(args.lstm_num_layers) + \"_dModel\" + str(args.d_model) + \"_dFF\" + str(args.d_ff)+ \"_s\" + str(args.seq_len) + \"_l\" + str(args.label_len) + \"_p\" + str(args.pred_len)+ \"_\" + args.data\n",
    "                        # 右侧的args.output表示output文件夹 \n",
    "                        # output\\rose_1变量一对一_w\n",
    "                        args.output = os.path.join(args.output,args.data+\"_\" + args.sub_them)\n",
    "\n",
    "\n",
    "                        # 输出的文件夹位置：output\\min_1变量一对一\\informer_e50_b1024_dModel32_dFF128_s80_l40_p_40_min\n",
    "                        run_name_dir = os.path.join(args.output, run_name_dir_old)\n",
    "                        if not os.path.exists(run_name_dir):\n",
    "                            os.makedirs(run_name_dir)\n",
    "                        # 单次运行的n个实验的模型存储的路径：需要判断是否存在，训练的时候已经判断了\n",
    "                        # ./checkpoints/batterySD\n",
    "                        run_name_dir_ckp_main = os.path.join(args.checkpoints, args.data)\n",
    "                        # './checkpoints/batterySD\\\\TwoFeatures(Δη,QD)\\\\informer_e50_b32_dModel32_dFF128_s100_l50_p50_batterySD'   \n",
    "                        run_name_dir_ckp = os.path.join(run_name_dir_ckp_main,'minNew/informerLSTM(pretreatment,ResNet,XL)' ,run_name_dir_old)\n",
    "\n",
    "                        # 要进行多少次实验，一次实验就是完成一个模型的训练-测试-预测 过程。默认2次，rose用了5次\n",
    "                        for ii in range(args.itr):\n",
    "                            print(\"-------------.....第{}次实验.....------------\".format(ii+1))\n",
    "                            # 存到output文件夹下了\n",
    "                            run_ex_dir = os.path.join(run_name_dir, \"第_{}_次实验记录\".format(ii + 1))\n",
    "                            if args.random_choos == True:\n",
    "                                pass\n",
    "                            else:\n",
    "                                # 固定随机性\n",
    "                                # setup_seed(args.seed)\n",
    "                                seed=args.seed\n",
    "                                random.seed(seed)\n",
    "                                os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "                                np.random.seed(seed)\n",
    "                                torch.manual_seed(seed)\n",
    "                                torch.cuda.manual_seed(seed)\n",
    "                                torch.cuda.manual_seed_all(seed)\n",
    "                                torch.backends.cudnn.deterministic =True\n",
    "                            if not os.path.exists(run_ex_dir):\n",
    "                                os.makedirs(run_ex_dir)\n",
    "                            # 添加实验info，存到 json文件中\n",
    "                            info_dict[\"实验序号\"] = ii+1\n",
    "                            info_dict[\"model\"] = args.model\n",
    "                            info_dict[\"data_them\"] = args.data\n",
    "                            info_dict[\"编码器的输入序列长度 seq_len【滑动窗口大小】\"] = args.seq_len\n",
    "                            info_dict[\"解码器的开始解码令牌起始位置 label_len\"] = args.label_len\n",
    "                            info_dict[\"预测未来序列长度 pred_len\"] = args.pred_len\n",
    "                            info_dict[\"时间特征编码的频率【数据粒度】freq\"] = args.freq\n",
    "                            info_dict[\"dorpout\"] = args.dropout\n",
    "                            info_dict[\"批次大小 batch_size\"] = args.batch_size\n",
    "                            info_dict[\"提前停止的连续轮数 patience\"] = args.patience\n",
    "                            info_dict[\"随机种子seed\"] = args.seed\n",
    "                            info_dict[\"损失函数loss\"] = args.loss\n",
    "                            info_dict[\"是否随机实验 random_choos\"] = args.random_choos\n",
    "                            info_dict[\"滞后数值 lag\"] = args.lag\n",
    "                            info_dict[\"编码器输入大小 enc_in\"] = args.enc_in\n",
    "                            info_dict[\"解码器输入大小 dec_in\"] = args.dec_in\n",
    "                            info_dict[\"输出尺寸 c_out\"] = args.c_out\n",
    "                            info_dict[\"模型维数 d_model\"] = args.d_model\n",
    "                            info_dict[\"多头部注意力机制的头部个数 n_heads\"] = args.n_heads\n",
    "                            info_dict[\"编码器层数 e_layers\"] = args.e_layers\n",
    "                            info_dict[\"解码器层数 d_layers\"] = args.d_layers\n",
    "                            info_dict[\"堆栈编码器层数 s_layers\"] = str(args.s_layers)\n",
    "                            info_dict[\"self-attention后面的FFN的中间向量表征维度 d_ff\"] = args.d_ff\n",
    "                            info_dict[\"probsparse attn factor\"] = args.factor\n",
    "                            info_dict[\"是否在编码器中不使用知识蒸馏 distil\"] = args.distil\n",
    "                            info_dict[\"编码器的注意力机制 attn\"] = args.attn\n",
    "                            info_dict[\"填充的值 padding\"] = args.padding\n",
    "                            info_dict[\"时间特征编码 embed\"] = args.embed\n",
    "                            info_dict[\"激活函数 activation\"] = args.activation\n",
    "                            info_dict[\"是否在编码器中输出注意力 output_attention\"] = args.output_attention\n",
    "                            info_dict[\"是否预测看不见的未来数据 do_predict\"] = args.do_predict\n",
    "                            info_dict[\"在生成解码器中使用混合注意力 mix\"] = args.mix\n",
    "                            info_dict[\"实验次数 itr\"] = args.itr\n",
    "                            info_dict[\"校正的学习率 lradj\"] = args.lradj\n",
    "                            info_dict[\"使用自动混合精度训练 use_amp\"] = args.use_amp\n",
    "                            info_dict[\"逆标准化输出数据 inverse\"] = args.inverse\n",
    "                            info_dict[\"优化器初始学习率 learning_rate\"] = args.learning_rate\n",
    "\n",
    "                            \n",
    "                            # 实验设置记录要点，方便打印，同时也作为文件名字传入参数，setting record of experiments\n",
    "                            # args.model = 'informer'，args.data = 'min'，args.features = 'ETTh1'，最后一个不用管，内部写死了\n",
    "                            setting = '{}_{}_{}_{}'.format(ii + 1, args.model, args.data, args.features)\n",
    "                            # 设置实验，将数据参数和模型变量传入实例\n",
    "                            exp = Exp(args)  # set experiments\n",
    "\n",
    "                        \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "\n",
    "                            # # 模型测试：存在问题：无法取到时间，boder不确定\n",
    "                            # print('>>>>>>>testing :  {}  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "                            # # test： 返回的是数组\n",
    "                            # # sys.exit()\n",
    "                            # info_dict, test_pred, test_true = exp.test(setting, info_dict, run_ex_dir,args)\n",
    "\n",
    "                            # future_pred, pred_date = 0, 0\n",
    "                            # # 做预测\n",
    "                            # if args.do_predict:\n",
    "                            #     print('>>>>>>>predicting :  {}  <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "                            #     # 模型预测未来\n",
    "                            #     future_pred, pred_date = exp.predict(setting, run_name_dir_ckp, run_ex_dir,args, load=args.save_model_choos)\n",
    "                            #     pred_dates = pred_date\n",
    "                            #     # assert pred_dates == pred_dates2\n",
    "\n",
    "                            print('>>>>>>>start training :  {}  >>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "                            print('lstm_hidden_size=', args.lstm_hidden_size)\n",
    "                            print('lstm_num_layers=', args.lstm_num_layers)\n",
    "                            print('d_model=', args.d_model)\n",
    "                            print('d_ff=', args.d_ff)\n",
    "                            print('batch=', args.batch_size)\n",
    "                            print('seed=',args.seed)\n",
    "                            # model, info_dict, all_epoch_train_loss, all_epoch_vali_loss, all_epoch_test_loss, epoch_count = exp.train(\n",
    "                            #     setting, info_dict, run_name_dir_ckp, run_ex_dir,args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3验证集上选取合适的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "try:\n",
    "    from sklearn.metrics import mean_squared_error # 均方误差\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    excelOutPath = 'NatureLRPEformerMinChooseModel.xlsx'\n",
    "    # 输出的所有excel数据\n",
    "    excelDataAll=[]\n",
    "    lstm_hidden_size_vlaues=[1,4,8,16,32]\n",
    "    lstm_num_layers_vlaues=[1,2,3]\n",
    "    d_model_values=[32]\n",
    "    d_ff_values=[128,256]\n",
    "    # d_model_values=[32]\n",
    "    # d_ff_values=[128]\n",
    "\n",
    "    for lstm_hidden_size in lstm_hidden_size_vlaues:\n",
    "        for lstm_num_layers in lstm_num_layers_vlaues:\n",
    "            for d_model in d_model_values:\n",
    "                for d_ff in d_ff_values:\n",
    "                    if d_ff >= d_model:\n",
    "            \n",
    "                        # 进行parser的变量初始化，获取实例。\n",
    "                        args = initialize_parameter()\n",
    "                        args.lstm_hidden_size=lstm_hidden_size\n",
    "                        args.lstm_num_layers=lstm_num_layers\n",
    "                        args.d_model=d_model\n",
    "                        args.d_ff=d_ff\n",
    "                \n",
    "                        seed=args.seed\n",
    "                        random.seed(seed)\n",
    "                        os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "                        np.random.seed(seed)\n",
    "                        torch.manual_seed(seed)\n",
    "                        torch.cuda.manual_seed(seed)\n",
    "                        torch.cuda.manual_seed_all(seed)\n",
    "                        torch.backends.cudnn.deterministic =True\n",
    "                        # 获取运行文件的路径  \n",
    "                        run_name_dir_old = args.model + \"_e\" + str(args.train_epochs) + \"_b\" + str(args.batch_size) + \"_lhs\" + str(args.lstm_hidden_size) + \"_lnl\" + str(args.lstm_num_layers) + \"_dModel\" + str(args.d_model) + \"_dFF\" + str(args.d_ff)+ \"_s\" + str(args.seq_len) + \"_l\" + str(args.label_len) + \"_p\" + str(args.pred_len)+ \"_\" + args.data\n",
    "                        # 右侧的args.output表示output文件夹 \n",
    "                        # output\\rose_1变量一对一_w\n",
    "                        args.output = os.path.join(args.output,args.data+\"_\" + args.sub_them)\n",
    "                        # 输出的文件夹位置：output\\min_1变量一对一\\informer_e50_b1024_dModel32_dFF128_s80_l40_p_40_min\n",
    "                        run_name_dir = os.path.join(args.output, run_name_dir_old)\n",
    "                        # 单次运行的n个实验的模型存储的路径：需要判断是否存在，训练的时候已经判断了\n",
    "                        # ./checkpoints/batterySD\n",
    "                        run_name_dir_ckp_main = os.path.join(args.checkpoints, args.data)\n",
    "                        # './checkpoints/batterySD\\\\TwoFeatures(Δη,QD)\\\\informer_e50_b32_dModel32_dFF128_s100_l50_p50_batterySD'   \n",
    "                        run_name_dir_ckp = os.path.join(run_name_dir_ckp_main,'minNew/informerLSTM(pretreatment,ResNet,XL)' ,run_name_dir_old)\n",
    "\n",
    "\n",
    "                        # 为了不经过训练，导入模型\n",
    "                        dataset = Dataset_Custom(\n",
    "                                    root_path=args.root_path,\n",
    "                                    data_path=args.data_path,\n",
    "                                    # 此处这个flag无影响\n",
    "                                    flag='test',\n",
    "                                    # informer原论文中，这三个分别为96，48，24，分别是输入encoder的序列长度、\n",
    "                                    # （48+24）为输入decoder的序列长度，24为预测长度\n",
    "                                    size=[args.seq_len, args.label_len, args.pred_len],\n",
    "                                    # M、S、MS，表示多变量预测、单变量预测、多变量预测单变量\n",
    "                                    features=args.features,\n",
    "                                    # target=args.target,\n",
    "                                    # inverse=args.inverse,\n",
    "                                    # 不用管，内部写死了\n",
    "                                    timeenc=0,\n",
    "                                    # freq=freq,\n",
    "                                    # scale=args.scale,\n",
    "                                    # cols=args.cols,\n",
    "                                    args=args\n",
    "                                )\n",
    "                        scalerDataη1=dataset.scalerDataη\n",
    "                        if args.use_gpu:\n",
    "                            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) if not args.use_multi_gpu else self.args.devices\n",
    "                            device = torch.device('cuda:{}'.format(args.gpu))\n",
    "                            # print('Use GPU: cuda:{}'.format(args.gpu))\n",
    "                        else:\n",
    "                            device = torch.device('cpu')\n",
    "                        model_dict = {\n",
    "                                    'informer':Informer,\n",
    "                                    'informerstack':InformerStack,\n",
    "                                }\n",
    "                        e_layers = args.e_layers if args.model=='informer' else args.s_layers\n",
    "                        # 如果args.model是informer，那么model_dict[args.model]就是Informer类\n",
    "                        model = model_dict[args.model](\n",
    "                            args.enc_in,\n",
    "                            args.dec_in, \n",
    "                            args.c_out, \n",
    "                            args.lstm_hidden_size,\n",
    "                            args.lstm_num_layers,\n",
    "                            args.seq_len, \n",
    "                            args.label_len,\n",
    "                            args.pred_len, \n",
    "                            args.factor,\n",
    "                            args.d_model, \n",
    "                            args.n_heads, \n",
    "                            e_layers, # args.e_layers,\n",
    "                            args.d_layers, \n",
    "                            args.d_ff,\n",
    "                            args.dropout, \n",
    "                            args.attn,\n",
    "                            args.embed,\n",
    "                            args.freq,\n",
    "                            args.activation,\n",
    "                            args.output_attention,\n",
    "                            args.distil,\n",
    "                            args.mix,\n",
    "                            device\n",
    "                        ).float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        # 清除缓存                \n",
    "                        # 没有BN层与DropOut层时，new_model.eval()可以不加\n",
    "                        with  torch.no_grad():\n",
    "                            path = os.path.join(run_name_dir_ckp ,setting)\n",
    "                            best_model_path = path+'/'+'checkpoint.pth'\n",
    "                        \n",
    "                            print(best_model_path)\n",
    "                            model.load_state_dict(torch.load(best_model_path))\n",
    "                            model.eval()\n",
    "                            model.to('cpu')\n",
    "\n",
    "                            \n",
    "\n",
    "                            # 命名的时候带All表示所有的数据，只是用来看每一列的长度的，但此处实际上每列长度固定为500了\n",
    "                            dataAll=pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                    '最小值(70)2019train.xlsx')))\n",
    "                        \n",
    "                            dataAll=dataAll.iloc[:1500]\n",
    "                            lenList=[]\n",
    "                            lenListSum=0\n",
    "                            colListAll=[]\n",
    "\n",
    "                            # 每列的长度，实际此处数据每列固定为500，但可以处理每列数据不一样的情况\n",
    "                            for j,col in enumerate(dataAll.columns):\n",
    "                                # 每列的长度\n",
    "                                len=(np.array(dataAll.iloc[:,j].dropna())).shape[0]\n",
    "                                lenList.append(len)\n",
    "                                lenListSum=lenListSum+len\n",
    "                                # 表的列名，用于给图片命名，表明电池编号\n",
    "                                colListAll.append(col)\n",
    "\n",
    "                            # print('lenList',lenList)    \n",
    "                            # mseAll是一个参数下的，被一个参数下的所有电池所共有，而对于不同的参数，mseAll不同\n",
    "                            mseAll=0\n",
    "                            excelHead=['参数']\n",
    "                            excelMse=['lhs_'+str(args.lstm_hidden_size)+'，lnl_'+str(args.lstm_num_layers)+'，dM_'+str(args.d_model)+'，dFF_'+str(args.d_ff)]\n",
    "                            YTruthAll=[]\n",
    "                            YPredAll=[]\n",
    "                            # excelR2=['R\\u00B2']\n",
    "                            # i是训练集的每一列（每一个电池），跑完就是一个参数下所有电池跑完\n",
    "                            for i in range(dataAll.shape[1]):\n",
    "                                # if(i==28 or i==29):\n",
    "                                if(i>-1):\n",
    "                                # if(i<2):\n",
    "                                \n",
    "                                    lenList[i]\n",
    "\n",
    "                                    # rawdataNewQD1 = pd.read_excel(filepathQD)\n",
    "                                    # rawdataNewQD1=rawdataNewQD1.drop(rawdataNewQD1.columns[2], axis=1).values[0:lenList[i],i].reshape(-1, 1)\n",
    "                                    # rawdataNewQD1 = pd.read_excel((os.path.join(args.root_path,\n",
    "                                    #                                 'QD(test).xlsx')))\n",
    "                                    # rawdataNewQD1=rawdataNewQD1.iloc[:500].values[:,i].reshape(-1, 1)\n",
    "                                    # print('rawdataNewQD1',rawdataNewQD1)\n",
    "                                    \n",
    "                                    rawdataNewη1 = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                    '最小值(70)2019train.xlsx')))\n",
    "                                    # 这一列的全部真实值\n",
    "                                    rawdataNewη1=rawdataNewη1.iloc[:lenList[i]].values[:,i].reshape(-1, 1)\n",
    "                                    # print('rawdataNew',rawdataNewη1)\n",
    "                                \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    # rawdataNewVar1 = pd.read_excel(filepathVar)\n",
    "                                    # rawdataNewVar1=rawdataNewVar1.drop(rawdataNewVar1.columns[2], axis=1).values[0:lenList[i],i].reshape(-1, 1)\n",
    "                                    # print('rawdataNew1',rawdataNew1)\n",
    "                                    # rawdataNewQD1 = scalerDataQD1.transform(rawdataNewQD1)\n",
    "                                    # rawdataNewQD1 = scalerDataQD1.transform(rawdataNewQD1)\n",
    "                                    # 归一化后输入模型\n",
    "                                    rawdataNewη1 = scalerDataη1.transform(rawdataNewη1)\n",
    "                                    # rawdataNewη1 = rawdataNewη1\n",
    "                                \n",
    "                                    # rawdataNewVar1 = scalerDataVar1.transform(rawdataNewVar1)\n",
    "                                    # print('rawdataNewQD1',rawdataNewQD1)\n",
    "                                    # print('rawdataNew',rawdataNewη1)\n",
    "\n",
    "\n",
    "\n",
    "                                    # rawdataNew1 = pd.read_excel(filepath).values[0:200,18].reshape(-1, 1)\n",
    "                                    # reshape(1,1,-1)的第一个 1 表示 channel为1\n",
    "                                    # result1=rawdataNewMin1\n",
    "                                    # result1=zip(rawdataNewQD1[:,0],rawdataNewη1[:,0])\n",
    "                                    result1=np.vstack((rawdataNewη1))\n",
    "                                        \n",
    "                                    # print(result1.shape)\n",
    "                                    # print(result1)\n",
    "                                \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    # rawdataNew1聚集了3个特征\n",
    "                                    # rawdataNew1=np.array(list(result1))\n",
    "\n",
    "                                    res_list1_encoder1 = torch.from_numpy(result1[:args.seq_len])\n",
    "                                    # res_list1_decoder1 = torch.from_numpy(result1[args.seq_len-args.label_len:args.seq_len])\n",
    "                                    # print('res_list1_encoder1',res_list1_encoder1)\n",
    "                                    # print('res_list1_decoder1',res_list1_decoder1.shape)\n",
    "                                    # print('res_list',type(res_list1))\n",
    "\n",
    "                                    # print(rawdataNew1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                    # print('np.array([IAll[j]])',np.array([IAll[j]]))\n",
    "\n",
    "                                    start = 0\n",
    "                                    # 一直预测到200\n",
    "                                    # resItemList用于记录所有的预测值(450个)\n",
    "                                    resItemList1=[]\n",
    "                                    rawdata = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                    '最小值(70)2019train.xlsx')))\n",
    "                                    # 该列电池真实值（不做归一化）\n",
    "                                    rawdata=rawdata.iloc[:lenList[i]].values[:,i]\n",
    "                                    # 下面几个参数是一个电池所共有的\n",
    "                                    mseCell=0\n",
    "                                    # 下面两个是为了方便计算R平方等值用的\n",
    "                                    predictCell=[]\n",
    "                                    realCell=[]\n",
    "                                    # lenList[i]-args.seq_len)//args.pred_len+1是执行次数，也即扔到model的次数\n",
    "                                    # while(start<(lenList[i]-args.seq_len)//args.pred_len):\n",
    "                                    # 循环结束是一个电池的预测结束\n",
    "                                    while(start<((lenList[i]-args.seq_len)//args.pred_len)+1):\n",
    "                                        window_encoder= torch.tensor(res_list1_encoder1[start*args.pred_len: start*args.pred_len+args.seq_len])\n",
    "                                        # 注意，这边还是从encoder中取\n",
    "                                        # print('window_encoder',window_encoder)\n",
    "                                        # print('window_encoder',window_encoder.shape)\n",
    "                                        # break\n",
    "                                        window_decoder= torch.tensor(res_list1_encoder1[start*args.pred_len+args.seq_len- args.label_len: start*args.pred_len+args.seq_len])\n",
    "                                        # print('window_decoder',window_decoder)\n",
    "                                        # print('window_decoder',window_decoder.shape)\n",
    "                                        # 不用管，内部写死了，获取带有掩码的输入序列x\n",
    "                                        seq_x_mark = torch.zeros(1)\n",
    "                                        # 获取带有掩码的输入序列x\n",
    "                                        seq_y_mark = torch.zeros(1)\n",
    "                                        \n",
    "                                        \n",
    "                                        if args.use_gpu:\n",
    "                                            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) if not args.use_multi_gpu else self.args.devices\n",
    "                                            device = torch.device('cuda:{}'.format(args.gpu))\n",
    "                                            # print('Use GPU: cuda:{}'.format(args.gpu))\n",
    "                                        else:\n",
    "                                            device = torch.device('cpu')\n",
    "                                        global dec_inp\n",
    "                                        batch_x = window_encoder.float()\n",
    "                                        batch_y = window_decoder.float()\n",
    "\n",
    "                                        batch_x_mark = seq_x_mark.float()\n",
    "                                        batch_y_mark = seq_y_mark.float()\n",
    "                                        batch_x=batch_x.unsqueeze(0)\n",
    "                                        batch_y=batch_y.unsqueeze(0)\n",
    "                                        batch_x_mark=batch_x_mark.unsqueeze(0)\n",
    "                                        batch_y_mark=batch_y_mark.unsqueeze(0)\n",
    "                                        # decoder input\n",
    "                                        if args.padding==0:\n",
    "                                            # 返回一个形状为为size，size是一个list，代表了数组的shape,类型为torch.dtype，里面的每一个值都是0的tensor\n",
    "                                            # batch_y.shape[0]是self.lbel_len + self.pred_len\n",
    "                                            # batch_y.shape[-1]是特征数,单特征预测单特征的情况下，这里是1\n",
    "                                            dec_inp = torch.zeros([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "                                        elif args.padding==1:\n",
    "                                            dec_inp = torch.ones([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "                                        # 在给定维度上对输入的张量序列seq 进行连接操作。\n",
    "                                        \"\"\"\n",
    "                                        outputs = torch.cat(inputs, dim=0) → Tensor\n",
    "                                        \n",
    "                                        inputs : 待连接的张量序列，可以是任意相同Tensor类型的python 序列，可以是列表或者元组。\n",
    "                                        dim : 选择的扩维, 必须在0到len(inputs[0])之间，沿着此维连接张量序列。\n",
    "                                        \"\"\"\n",
    "                                        dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float()\n",
    "                                        # encoder - decoder（编码器-解码器）\n",
    "                                        # 假如使用自动混合精度训练\n",
    "                                        if args.use_amp:\n",
    "                                            # pytorch 使用autocast半精度进行加速训练\n",
    "                                            with torch.cuda.amp.autocast():\n",
    "                                                # 假如在编码器中输出注意力\n",
    "                                                if args.output_attention:\n",
    "                                                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                                                else:\n",
    "                                                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                                        # 假如不使用自动混合精度训练\n",
    "                                        else:\n",
    "                                            if args.output_attention:\n",
    "                                                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                                            else:\n",
    "                                                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                                        # print(outputs.shape)\n",
    "                                        # print(outputs)\n",
    "                                        # 逆标准化输出数据\n",
    "                                        # 暂时不管他\n",
    "                                        # if self.args.inverse:\n",
    "                                        #     outputs = dataset_object.inverse_transform(outputs)\n",
    "                                        f_dim = -1 if args.features=='MS' else 0\n",
    "                                        # 如果是MS。那么只留有一列输出\n",
    "                                        # outputs = outputs[:, :, 1:] if args.features == 'MS' else outputs\n",
    "                                        # 对y进行解码\n",
    "                                        # 取出pred\n",
    "                                        batch_y = batch_y[:,-args.pred_len:,f_dim:]\n",
    "\n",
    "                                        # 如果是M任务，那么进行打平再输出去计算梯度\n",
    "                                        # output作为预测值，batch_y(取出pred部分，也就是长度40)作为真实值\n",
    "                                        # return outputs, batch_y\n",
    "                                        \n",
    "                                        # outputs(1,50,1)\n",
    "                                        # resultTemp=torch.tensor(np.vstack((outputs.squeeze(0))))\n",
    "                                        # # print('resultTemp',resultTemp)\n",
    "                                        # # 存的是真实值以及预测值的拼接,outputs(1,50,1)\n",
    "                                        # res_list1_encoder1=torch.cat([res_list1_encoder1,resultTemp],dim=0)\n",
    "                                        # print('res_list1_encoder1',res_list1_encoder1[:,-1])                \n",
    "                                        \n",
    "                                        # 存的是真实值以及预测值的拼接\n",
    "                                        res_list1_encoder1=torch.cat([res_list1_encoder1,outputs.squeeze(0)],dim=0)\n",
    "                                        \n",
    "                                        # 算mse\n",
    "                                        # 逆归一化\n",
    "                                        res_listnew=scalerDataη1.inverse_transform(outputs.squeeze(0).reshape(-1,1)).ravel()  \n",
    "                                        # res_listnew=res_listnew[0:lenList[i]]\n",
    "                                        # 真实值和预测值的mse    \n",
    "                                        # rawdata为未归一化时的真实值\n",
    "                                        # 一个电池中的所有mse相加                    \n",
    "                                        # print('start=',start)\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len])\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len].shape)\n",
    "                                        # print('res_listnew',res_listnew.shape)\n",
    "                                        # print('ahh',)[start*args.pred_len: start*args.pred_len+args.seq_len])\n",
    "                                        # mseCell=mseCell+mean_squared_error(rawdata[start*args.pred_len+args.seq_len : start*args.pred_len+args.seq_len+args.pred_len],res_listnew)\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len])\n",
    "                                        # 存入predicetCell\n",
    "                                        # predictCell里面存的是逆归一化之后的预测值\n",
    "                                        for element in res_listnew:\n",
    "                                            predictCell.append(element)\n",
    "                                        \n",
    "                                        \n",
    "                                        start = start + 1\n",
    "                                        # 这边改成全用真实值\n",
    "                                        # res_list1_encoder1=torch.from_numpy(result1[start*args.pred_len : start*args.pred_len+args.seq_len])\n",
    "                                        # print('ahh',res_list1_encoder1)\n",
    "                                        \n",
    "                                        \n",
    "                                    \n",
    "                                        # resItemList1.append(outputs)\n",
    "                                        # 将循环号归一化后合并\n",
    "                                        # reshape(1,1,1) 的第一个参数 1 表示 channel为 1\n",
    "                                        # result=np.array([res.item()]).reshape(1,1,1)\n",
    "                                        # print(result)\n",
    "                                        # print(result.shape)\n",
    "                                        # res_list1=np.concatenate((res_list1,result),axis=2)\n",
    "                                        # print(res_list1)\n",
    "                                        # print(res_list1.shape)\n",
    "                                        \n",
    "\n",
    "                                    \n",
    "                                    # resItemList1\n",
    "                                    # 逆归一化,还原成预测的充电电容(150个)\n",
    "                                    res_listnew2=scalerDataη1.inverse_transform(res_list1_encoder1[:,-1].reshape(-1,1)).ravel()  \n",
    "                                    res_listnew2=res_listnew2[0:lenList[i]]\n",
    "                                    # print(\"ahh\",res_listnew)\n",
    "                                    \n",
    "                                    # print('每个电池迭代次数',lenList[i]-args.seq_len-args.pred_len+1)\n",
    "                                    # print('start',start)\n",
    "                                    # 除以'每个电池迭代次数'，得到一个电池的最终mse\n",
    "                                    # mseCell=mseCell/((lenList[i]-args.seq_len-args.pred_len)//args.pred_len+1)\n",
    "                                \n",
    "                                    # print('predictCell', len(predictCell))\n",
    "                                    \n",
    "                                    # 一套参数下所有电池的mse相加\n",
    "                                    mseAll = mseAll+mseCell\n",
    "\n",
    "\n",
    "\n",
    "                                    # testIndex = 0\n",
    "\n",
    "                                    # # print('res_listnew',res_listnew[-1])\n",
    "                                    # # 一开始用的是1A的数据,用的是初始数据\n",
    "                                    rawdata = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                     '最小值(70)2019train.xlsx')))\n",
    "                                    rawdata=rawdata.iloc[:lenList[i]].values[:,i]\n",
    "                                    \n",
    "                                    # 横坐标\n",
    "                                    x = range(1,lenList[i]+1)\n",
    "                                    # 纵坐标真实值\n",
    "                                    y = rawdata[0:]\n",
    "                                    # 纵坐标预测值     # 还原成原样\n",
    "                                    # y2 = np.array(res_listnew[:]).tolist()\n",
    "                                    # print(type(y))\n",
    "                                    # print(type(predictCell))\n",
    "                                    y2 = y[0:args.seq_len].tolist()+predictCell\n",
    "                                    y2 = y2[:lenList[i]]\n",
    "                                    YTruthAll=np.concatenate((YTruthAll, y[-lenList[i]+args.seq_len:]))\n",
    "                                    YPredAll=np.concatenate((YPredAll, y2[-lenList[i]+args.seq_len:]))\n",
    "                                    # print('predictCell',predictCell)\n",
    "                                    # print('res_listnew2',res_listnew2[50:])\n",
    "                                    # 此处写上最好的一两种参数，进行画图\n",
    "                                    if(args.lstm_hidden_size==312 and args.lstm_num_layers==2 and args.d_model==32 and args.d_ff==128):\n",
    "                                    \n",
    "                                    # print(len(y2))\n",
    "                                        print('lstm_hidden_size=', args.lstm_hidden_size)\n",
    "                                        print('lstm_num_layers=', args.lstm_num_layers)\n",
    "                                        print('d_model=', args.d_model)\n",
    "                                        print('d_ff=', args.d_ff)\n",
    "                                        print('batch=', args.batch_size)\n",
    "                                        \n",
    "                                    \n",
    "                                        plt.figure()\n",
    "                                        # plt.title(colListAll[i]+'_Model 2——'+str(testIndex)+'——'+str(num_epochs))\n",
    "                                        plt.title(colListAll[i]+'_lHS'+str(args.lstm_hidden_size)+'_lNL'+str(args.lstm_num_layers)+'_dModel'+str(args.d_model)+'_dFF'+str(args.d_ff))\n",
    "                                    \n",
    "                                        plt.xlabel('circle')\n",
    "                                        plt.ylabel('min')\n",
    "                                        plt.plot(x,y, label='True')\n",
    "                                        \n",
    "                                        plt.plot(x,y2, label='prediction', linestyle='--')\n",
    "                                        # plt.ylim(0.1,1.1)\n",
    "                                        # plt.annotate(f'{round(y[-1],4)}', (500, y[-1]))\n",
    "                                        # plt.annotate(f'{round(y2[-1],4)}', (500, y2[-1]))\n",
    "\n",
    "                                        plt.legend(loc='upper left')\n",
    "                                        # 添加虚线\n",
    "                                        # plt.axhline(y=0.88,linestyle=\"--\",c=\"black\")\n",
    "                                        plt.axvline(x=args.seq_len,ls=\"--\",c=\"black\")\n",
    "                                        for idx in range((int(plt.axis()[1])-args.seq_len)//args.pred_len):plt.axvline(x=args.seq_len+idx*args.pred_len,ls=\"--\",c=\"grey\")\n",
    "                                        # plt.axvline(y=0.88,ls=\"--\",c=\"black\")\n",
    "                                        \n",
    "                                        plt.ylim(-2.5,0.1)\n",
    "                                        # 解决中文显示问题\n",
    "                                        plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "                                        plt.rcParams['axes.unicode_minus'] = False  \n",
    "                                        # -x[-1]*0.06,min(y[-1],y2[-1])- (y[0]-y[-1])*0.3  这些是用于指定文字的坐标的\n",
    "                                        plt.text(-x[-1]*0.06,-2.85, \"真实值：\"+str(y[-1]), ha='left', fontsize=12)\n",
    "                                        plt.text(-x[-1]*0.06, -3, \"预测值：\"+str(y2[-1]), ha='left', fontsize=12)\n",
    "                                        # plt.text(-x[-1]*0.06, -0.30, \"MSE:    \"+str(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:])), ha='left', fontsize=12)\n",
    "                                        \n",
    "                                        plt.text(-x[-1]*0.06, -3.15, \"MSE:    \"+str(\"{:.2e}\".format(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:]))), ha='left', fontsize=12)\n",
    "                                        # plt.savefig('./img(min)/'+colListAll[i]+'模型1-h64-testIndex='+str(testIndex)+'-epoch='+str(num_epochs)+'.jpg', format='jpg', dpi=200)\n",
    "                                        # print(plt.axis()[2])\n",
    "                                        plt.show()\n",
    "                                        print('真实值：',y[-1])\n",
    "                                        print('预测值：',y2[-1])\n",
    "                                        print('MSE：',mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:]))\n",
    "                                    \n",
    "                                    # 电池\n",
    "                                    realCellAll=pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                   '最小值(70)2019train.xlsx')))\n",
    "                                    # 这一列的全部真实值\n",
    "                                    realCellAll=realCellAll.iloc[:lenList[i]].values[:,i].reshape(-1, 1)\n",
    "                                    # 最终得到的realCell是与predict的shape一样的，可以用于计算mse，r平方之类\n",
    "                                    # for idx in range(lenList[i]-args.seq_len-args.pred_len+1):\n",
    "                                    #     for element in realCellAll[idx+args.seq_len : idx+args.seq_len+args.pred_len]:\n",
    "                                    #         realCell.append(element)\n",
    "                                    # mean_squared_error(realCell,predictCell)与上面计算的mseCell一样\n",
    "                                    realCell=y[-lenList[i]+args.seq_len:]\n",
    "                                    # print('mse新',mean_squared_error(realCell,predictCell))\n",
    "                                    # print('mse新xin',mean_squared_error(realCell,res_listnew2[100:]))\n",
    "                                    # print('mseCell',mseCell)\n",
    "                                    # 可以计算r平方\n",
    "                                    # print('r',r2_score(realCell,predictCell))\n",
    "                                    \n",
    "                                    # excelHead.append(colListAll[i])\n",
    "                                    # excelMse.append(\"{:.2e}\".format(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:])))\n",
    "                                    \n",
    "                                    # 暂时先不要R2\n",
    "                                    # excelR2.append(r2_score(realCell,predictCell))\n",
    "                                    \n",
    "                            # print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "                            # print('d_model=', args.d_model)\n",
    "                            # print('d_ff=', args.d_ff) \n",
    "                            # print('电池个数',dataAll.shape[1])\n",
    "                            # 是一个参数下所有电池的  \n",
    "                            # print('mseAll',mseAll/dataAll.shape[1])\n",
    "                            excelHead.append('总MSE')\n",
    "                            excelMse.append(\"{:.2e}\".format(mean_squared_error(np.array(YTruthAll).flatten(),np.array(YPredAll).flatten())))\n",
    "                            excelHead.append('总R2')\n",
    "                            excelMse.append(\"{:.2e}\".format(r2_score(np.array(YTruthAll).flatten(),np.array(YPredAll).flatten())))\n",
    "                            # 电池编号（第一行）未加入，就加一次\n",
    "                            if excelDataAll ==[]: excelDataAll.append(excelHead)\n",
    "                            excelDataAll.append(excelMse)\n",
    "                            # data = [\n",
    "                            #     excelHead,\n",
    "                            #     excelMse,\n",
    "                            #     # excelR2\n",
    "                            # ]\n",
    "\n",
    "                            # 创建数据框\n",
    "    df = pd.DataFrame(excelDataAll)\n",
    "    # 保存为 Excel 文件\n",
    "    file_path = excelOutPath\n",
    "    # 创建 Styler 对象并设置单元格样式\n",
    "    styler = df.style.set_properties(**{'text-align': 'center'})\n",
    "    # df.to_excel(file_path, index=False, header=False)\n",
    "    styler.to_excel(file_path, index=False, header=False)\n",
    "    print('数据已保存为 Excel 文件.')\n",
    "\n",
    "except Exception as e:\n",
    "    print(traceback.print_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 预测及画图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测值，每次窗口移动50，画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "try:\n",
    "    from sklearn.metrics import mean_squared_error # 均方误差\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    excelOutPath = 'NatureLRPEformerMin.xlsx'\n",
    "    # 输出的所有excel数据\n",
    "    excelDataAll=[]\n",
    "    lstm_hidden_size_vlaues=[1,4,8,16,32]\n",
    "    lstm_num_layers_vlaues=[1,2,3]\n",
    "    d_model_values=[32]\n",
    "    d_ff_values=[128,256]\n",
    "    lstm_hidden_size_vlaues=[4]\n",
    "    lstm_num_layers_vlaues=[2]\n",
    "    d_model_values=[32]\n",
    "    d_ff_values=[256]\n",
    "    seed_values=[12345]\n",
    "\n",
    "    for lstm_hidden_size in lstm_hidden_size_vlaues:\n",
    "        for lstm_num_layers in lstm_num_layers_vlaues:\n",
    "            for d_model in d_model_values:\n",
    "                for d_ff in d_ff_values:\n",
    "                    for seeds in seed_values:\n",
    "                    # if d_ff >= d_model:\n",
    "            \n",
    "                        # 进行parser的变量初始化，获取实例。\n",
    "                        args = initialize_parameter()\n",
    "                        args.lstm_hidden_size=lstm_hidden_size\n",
    "                        args.lstm_num_layers=lstm_num_layers\n",
    "                        args.d_model=d_model\n",
    "                        args.d_ff=d_ff\n",
    "                        args.seed=seeds\n",
    "                \n",
    "                        seed=args.seed\n",
    "                        random.seed(seed)\n",
    "                        os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "                        np.random.seed(seed)\n",
    "                        torch.manual_seed(seed)\n",
    "                        torch.cuda.manual_seed(seed)\n",
    "                        torch.cuda.manual_seed_all(seed)\n",
    "                        torch.backends.cudnn.deterministic =True\n",
    "                        # 获取运行文件的路径  \n",
    "                        run_name_dir_old = args.model + \"_e\" + str(args.train_epochs) + \"_b\" + str(args.batch_size) + \"_lhs\" + str(args.lstm_hidden_size) + \"_lnl\" + str(args.lstm_num_layers) + \"_dModel\" + str(args.d_model) + \"_dFF\" + str(args.d_ff)+ \"_s\" + str(args.seq_len) + \"_l\" + str(args.label_len) + \"_p\" + str(args.pred_len)+ \"_\" + args.data\n",
    "                        # 右侧的args.output表示output文件夹 \n",
    "                        # output\\rose_1变量一对一_w\n",
    "                        args.output = os.path.join(args.output,args.data+\"_\" + args.sub_them)\n",
    "                        # 输出的文件夹位置：output\\min_1变量一对一\\informer_e50_b1024_dModel32_dFF128_s80_l40_p_40_min\n",
    "                        run_name_dir = os.path.join(args.output, run_name_dir_old)\n",
    "                        # 单次运行的n个实验的模型存储的路径：需要判断是否存在，训练的时候已经判断了\n",
    "                        # ./checkpoints/batterySD\n",
    "                        run_name_dir_ckp_main = os.path.join(args.checkpoints, args.data)\n",
    "                        # './checkpoints/batterySD\\\\TwoFeatures(Δη,QD)\\\\informer_e50_b32_dModel32_dFF128_s100_l50_p50_batterySD'   \n",
    "                        run_name_dir_ckp = os.path.join(run_name_dir_ckp_main,'minNew/informerLSTM(pretreatment,ResNet,XL)' ,run_name_dir_old)\n",
    "\n",
    "\n",
    "                        # 为了不经过训练，导入模型\n",
    "                        dataset = Dataset_Custom(\n",
    "                                    root_path=args.root_path,\n",
    "                                    data_path=args.data_path,\n",
    "                                    # 此处这个flag无影响\n",
    "                                    flag='test',\n",
    "                                    # informer原论文中，这三个分别为96，48，24，分别是输入encoder的序列长度、\n",
    "                                    # （48+24）为输入decoder的序列长度，24为预测长度\n",
    "                                    size=[args.seq_len, args.label_len, args.pred_len],\n",
    "                                    # M、S、MS，表示多变量预测、单变量预测、多变量预测单变量\n",
    "                                    features=args.features,\n",
    "                                    # target=args.target,\n",
    "                                    # inverse=args.inverse,\n",
    "                                    # 不用管，内部写死了\n",
    "                                    timeenc=0,\n",
    "                                    # freq=freq,\n",
    "                                    # scale=args.scale,\n",
    "                                    # cols=args.cols,\n",
    "                                    args=args\n",
    "                                )\n",
    "                        scalerDataη1=dataset.scalerDataη\n",
    "                        if args.use_gpu:\n",
    "                            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) if not args.use_multi_gpu else self.args.devices\n",
    "                            device = torch.device('cuda:{}'.format(args.gpu))\n",
    "                            # print('Use GPU: cuda:{}'.format(args.gpu))\n",
    "                        else:\n",
    "                            device = torch.device('cpu')\n",
    "                        model_dict = {\n",
    "                                    'informer':Informer,\n",
    "                                    'informerstack':InformerStack,\n",
    "                                }\n",
    "                        e_layers = args.e_layers if args.model=='informer' else args.s_layers\n",
    "                        # 如果args.model是informer，那么model_dict[args.model]就是Informer类\n",
    "                        model = model_dict[args.model](\n",
    "                            args.enc_in,\n",
    "                            args.dec_in, \n",
    "                            args.c_out, \n",
    "                            args.lstm_hidden_size,\n",
    "                            args.lstm_num_layers,\n",
    "                            args.seq_len, \n",
    "                            args.label_len,\n",
    "                            args.pred_len, \n",
    "                            args.factor,\n",
    "                            args.d_model, \n",
    "                            args.n_heads, \n",
    "                            e_layers, # args.e_layers,\n",
    "                            args.d_layers, \n",
    "                            args.d_ff,\n",
    "                            args.dropout, \n",
    "                            args.attn,\n",
    "                            args.embed,\n",
    "                            args.freq,\n",
    "                            args.activation,\n",
    "                            args.output_attention,\n",
    "                            args.distil,\n",
    "                            args.mix,\n",
    "                            device\n",
    "                        ).float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        # 清除缓存                \n",
    "                        # 没有BN层与DropOut层时，new_model.eval()可以不加\n",
    "                        with  torch.no_grad():\n",
    "                            path = os.path.join(run_name_dir_ckp ,setting)\n",
    "                            best_model_path = path+'/'+'checkpoint.pth'\n",
    "                        \n",
    "                            print(best_model_path)\n",
    "                            model.load_state_dict(torch.load(best_model_path))\n",
    "                            model.eval()\n",
    "                            model.to('cpu')\n",
    "\n",
    "                            \n",
    "\n",
    "                            # 命名的时候带All表示所有的数据，只是用来看每一列的长度的，但此处实际上每列长度固定为500了\n",
    "                            dataAll=pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                    '最小值(70)2019test.xlsx')))\n",
    "                        \n",
    "                            dataAll=dataAll.iloc[:1500]\n",
    "                            lenList=[]\n",
    "                            lenListSum=0\n",
    "                            colListAll=[]\n",
    "\n",
    "                            # 每列的长度，实际此处数据每列固定为500，但可以处理每列数据不一样的情况\n",
    "                            for j,col in enumerate(dataAll.columns):\n",
    "                                # 每列的长度\n",
    "                                len=(np.array(dataAll.iloc[:,j].dropna())).shape[0]\n",
    "                                lenList.append(len)\n",
    "                                lenListSum=lenListSum+len\n",
    "                                # 表的列名，用于给图片命名，表明电池编号\n",
    "                                colListAll.append(col)\n",
    "\n",
    "                            # print('lenList',lenList)    \n",
    "                            # mseAll是一个参数下的，被一个参数下的所有电池所共有，而对于不同的参数，mseAll不同\n",
    "                            mseAll=0\n",
    "                            excelHead=['参数']\n",
    "                            excelMse=['lhs_'+str(args.lstm_hidden_size)+'，lnl_'+str(args.lstm_num_layers)+'，dM_'+str(args.d_model)+'，dFF_'+str(args.d_ff)+',seed_'+str(args.seed)]\n",
    "                            YTruthAll=[]\n",
    "                            YPredAll=[]\n",
    "                            # excelR2=['R\\u00B2']\n",
    "                            # i是训练集的每一列（每一个电池），跑完就是一个参数下所有电池跑完\n",
    "                            for i in range(dataAll.shape[1]):\n",
    "                                # if(i==28 or i==29):\n",
    "                                if(i>-1):\n",
    "                                # if(i<2):\n",
    "                                \n",
    "                                    lenList[i]\n",
    "\n",
    "                                    # rawdataNewQD1 = pd.read_excel(filepathQD)\n",
    "                                    # rawdataNewQD1=rawdataNewQD1.drop(rawdataNewQD1.columns[2], axis=1).values[0:lenList[i],i].reshape(-1, 1)\n",
    "                                    # rawdataNewQD1 = pd.read_excel((os.path.join(args.root_path,\n",
    "                                    #                                 'QD(test).xlsx')))\n",
    "                                    # rawdataNewQD1=rawdataNewQD1.iloc[:500].values[:,i].reshape(-1, 1)\n",
    "                                    # print('rawdataNewQD1',rawdataNewQD1)\n",
    "                                    \n",
    "                                    rawdataNewη1 = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                    '最小值(70)2019test.xlsx')))\n",
    "                                    # 这一列的全部真实值\n",
    "                                    rawdataNewη1=rawdataNewη1.iloc[:lenList[i]].values[:,i].reshape(-1, 1)\n",
    "                                    # print('rawdataNew',rawdataNewη1)\n",
    "                                \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    # rawdataNewVar1 = pd.read_excel(filepathVar)\n",
    "                                    # rawdataNewVar1=rawdataNewVar1.drop(rawdataNewVar1.columns[2], axis=1).values[0:lenList[i],i].reshape(-1, 1)\n",
    "                                    # print('rawdataNew1',rawdataNew1)\n",
    "                                    # rawdataNewQD1 = scalerDataQD1.transform(rawdataNewQD1)\n",
    "                                    # rawdataNewQD1 = scalerDataQD1.transform(rawdataNewQD1)\n",
    "                                    # 归一化后输入模型\n",
    "                                    rawdataNewη1 = scalerDataη1.transform(rawdataNewη1)\n",
    "                                    # rawdataNewη1 = rawdataNewη1\n",
    "                                \n",
    "                                    # rawdataNewVar1 = scalerDataVar1.transform(rawdataNewVar1)\n",
    "                                    # print('rawdataNewQD1',rawdataNewQD1)\n",
    "                                    # print('rawdataNew',rawdataNewη1)\n",
    "\n",
    "\n",
    "\n",
    "                                    # rawdataNew1 = pd.read_excel(filepath).values[0:200,18].reshape(-1, 1)\n",
    "                                    # reshape(1,1,-1)的第一个 1 表示 channel为1\n",
    "                                    # result1=rawdataNewMin1\n",
    "                                    # result1=zip(rawdataNewQD1[:,0],rawdataNewη1[:,0])\n",
    "                                    result1=np.vstack((rawdataNewη1))\n",
    "                                        \n",
    "                                    # print(result1.shape)\n",
    "                                    # print(result1)\n",
    "                                \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    # rawdataNew1聚集了3个特征\n",
    "                                    # rawdataNew1=np.array(list(result1))\n",
    "\n",
    "                                    res_list1_encoder1 = torch.from_numpy(result1[:args.seq_len])\n",
    "                                    # res_list1_decoder1 = torch.from_numpy(result1[args.seq_len-args.label_len:args.seq_len])\n",
    "                                    # print('res_list1_encoder1',res_list1_encoder1)\n",
    "                                    # print('res_list1_decoder1',res_list1_decoder1.shape)\n",
    "                                    # print('res_list',type(res_list1))\n",
    "\n",
    "                                    # print(rawdataNew1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                    # print('np.array([IAll[j]])',np.array([IAll[j]]))\n",
    "\n",
    "                                    start = 0\n",
    "                                    # 一直预测到200\n",
    "                                    # resItemList用于记录所有的预测值(450个)\n",
    "                                    resItemList1=[]\n",
    "                                    rawdata = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                    '最小值(70)2019test.xlsx')))\n",
    "                                    # 该列电池真实值（不做归一化）\n",
    "                                    rawdata=rawdata.iloc[:lenList[i]].values[:,i]\n",
    "                                    # 下面几个参数是一个电池所共有的\n",
    "                                    mseCell=0\n",
    "                                    # 下面两个是为了方便计算R平方等值用的\n",
    "                                    predictCell=[]\n",
    "                                    realCell=[]\n",
    "                                    # lenList[i]-args.seq_len)//args.pred_len+1是执行次数，也即扔到model的次数\n",
    "                                    # while(start<(lenList[i]-args.seq_len)//args.pred_len):\n",
    "                                    # 循环结束是一个电池的预测结束\n",
    "                                    while(start<((lenList[i]-args.seq_len)//args.pred_len)+1):\n",
    "                                        window_encoder= torch.tensor(res_list1_encoder1[start*args.pred_len: start*args.pred_len+args.seq_len])\n",
    "                                        # 注意，这边还是从encoder中取\n",
    "                                        # print('window_encoder',window_encoder)\n",
    "                                        # print('window_encoder',window_encoder.shape)\n",
    "                                        # break\n",
    "                                        window_decoder= torch.tensor(res_list1_encoder1[start*args.pred_len+args.seq_len- args.label_len: start*args.pred_len+args.seq_len])\n",
    "                                        # print('window_decoder',window_decoder)\n",
    "                                        # print('window_decoder',window_decoder.shape)\n",
    "                                        # 不用管，内部写死了，获取带有掩码的输入序列x\n",
    "                                        seq_x_mark = torch.zeros(1)\n",
    "                                        # 获取带有掩码的输入序列x\n",
    "                                        seq_y_mark = torch.zeros(1)\n",
    "                                        \n",
    "                                        \n",
    "                                        if args.use_gpu:\n",
    "                                            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) if not args.use_multi_gpu else self.args.devices\n",
    "                                            device = torch.device('cuda:{}'.format(args.gpu))\n",
    "                                            # print('Use GPU: cuda:{}'.format(args.gpu))\n",
    "                                        else:\n",
    "                                            device = torch.device('cpu')\n",
    "                                        global dec_inp\n",
    "                                        batch_x = window_encoder.float()\n",
    "                                        batch_y = window_decoder.float()\n",
    "\n",
    "                                        batch_x_mark = seq_x_mark.float()\n",
    "                                        batch_y_mark = seq_y_mark.float()\n",
    "                                        batch_x=batch_x.unsqueeze(0)\n",
    "                                        batch_y=batch_y.unsqueeze(0)\n",
    "                                        batch_x_mark=batch_x_mark.unsqueeze(0)\n",
    "                                        batch_y_mark=batch_y_mark.unsqueeze(0)\n",
    "                                        # decoder input\n",
    "                                        if args.padding==0:\n",
    "                                            # 返回一个形状为为size，size是一个list，代表了数组的shape,类型为torch.dtype，里面的每一个值都是0的tensor\n",
    "                                            # batch_y.shape[0]是self.lbel_len + self.pred_len\n",
    "                                            # batch_y.shape[-1]是特征数,单特征预测单特征的情况下，这里是1\n",
    "                                            dec_inp = torch.zeros([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "                                        elif args.padding==1:\n",
    "                                            dec_inp = torch.ones([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "                                        # 在给定维度上对输入的张量序列seq 进行连接操作。\n",
    "                                        \"\"\"\n",
    "                                        outputs = torch.cat(inputs, dim=0) → Tensor\n",
    "                                        \n",
    "                                        inputs : 待连接的张量序列，可以是任意相同Tensor类型的python 序列，可以是列表或者元组。\n",
    "                                        dim : 选择的扩维, 必须在0到len(inputs[0])之间，沿着此维连接张量序列。\n",
    "                                        \"\"\"\n",
    "                                        dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float()\n",
    "                                        # encoder - decoder（编码器-解码器）\n",
    "                                        # 假如使用自动混合精度训练\n",
    "                                        if args.use_amp:\n",
    "                                            # pytorch 使用autocast半精度进行加速训练\n",
    "                                            with torch.cuda.amp.autocast():\n",
    "                                                # 假如在编码器中输出注意力\n",
    "                                                if args.output_attention:\n",
    "                                                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                                                else:\n",
    "                                                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                                        # 假如不使用自动混合精度训练\n",
    "                                        else:\n",
    "                                            if args.output_attention:\n",
    "                                                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                                            else:\n",
    "                                                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                                        # print(outputs.shape)\n",
    "                                        # print(outputs)\n",
    "                                        # 逆标准化输出数据\n",
    "                                        # 暂时不管他\n",
    "                                        # if self.args.inverse:\n",
    "                                        #     outputs = dataset_object.inverse_transform(outputs)\n",
    "                                        f_dim = -1 if args.features=='MS' else 0\n",
    "                                        # 如果是MS。那么只留有一列输出\n",
    "                                        # outputs = outputs[:, :, 1:] if args.features == 'MS' else outputs\n",
    "                                        # 对y进行解码\n",
    "                                        # 取出pred\n",
    "                                        batch_y = batch_y[:,-args.pred_len:,f_dim:]\n",
    "\n",
    "                                        # 如果是M任务，那么进行打平再输出去计算梯度\n",
    "                                        # output作为预测值，batch_y(取出pred部分，也就是长度40)作为真实值\n",
    "                                        # return outputs, batch_y\n",
    "                                        \n",
    "                                        # outputs(1,50,1)\n",
    "                                        # resultTemp=torch.tensor(np.vstack((outputs.squeeze(0))))\n",
    "                                        # # print('resultTemp',resultTemp)\n",
    "                                        # # 存的是真实值以及预测值的拼接,outputs(1,50,1)\n",
    "                                        # res_list1_encoder1=torch.cat([res_list1_encoder1,resultTemp],dim=0)\n",
    "                                        # print('res_list1_encoder1',res_list1_encoder1[:,-1])                \n",
    "                                        \n",
    "                                        # 存的是真实值以及预测值的拼接\n",
    "                                        res_list1_encoder1=torch.cat([res_list1_encoder1,outputs.squeeze(0)],dim=0)\n",
    "                                        \n",
    "                                        # 算mse\n",
    "                                        # 逆归一化\n",
    "                                        res_listnew=scalerDataη1.inverse_transform(outputs.squeeze(0).reshape(-1,1)).ravel()  \n",
    "                                        # res_listnew=res_listnew[0:lenList[i]]\n",
    "                                        # 真实值和预测值的mse    \n",
    "                                        # rawdata为未归一化时的真实值\n",
    "                                        # 一个电池中的所有mse相加                    \n",
    "                                        # print('start=',start)\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len])\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len].shape)\n",
    "                                        # print('res_listnew',res_listnew.shape)\n",
    "                                        # print('ahh',)[start*args.pred_len: start*args.pred_len+args.seq_len])\n",
    "                                        # mseCell=mseCell+mean_squared_error(rawdata[start*args.pred_len+args.seq_len : start*args.pred_len+args.seq_len+args.pred_len],res_listnew)\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len])\n",
    "                                        # 存入predicetCell\n",
    "                                        # predictCell里面存的是逆归一化之后的预测值\n",
    "                                        for element in res_listnew:\n",
    "                                            predictCell.append(element)\n",
    "                                        \n",
    "                                        \n",
    "                                        start = start + 1\n",
    "                                        # 这边改成全用真实值\n",
    "                                        # res_list1_encoder1=torch.from_numpy(result1[start*args.pred_len : start*args.pred_len+args.seq_len])\n",
    "                                        # print('ahh',res_list1_encoder1)\n",
    "                                        \n",
    "                                        \n",
    "                                    \n",
    "                                        # resItemList1.append(outputs)\n",
    "                                        # 将循环号归一化后合并\n",
    "                                        # reshape(1,1,1) 的第一个参数 1 表示 channel为 1\n",
    "                                        # result=np.array([res.item()]).reshape(1,1,1)\n",
    "                                        # print(result)\n",
    "                                        # print(result.shape)\n",
    "                                        # res_list1=np.concatenate((res_list1,result),axis=2)\n",
    "                                        # print(res_list1)\n",
    "                                        # print(res_list1.shape)\n",
    "                                        \n",
    "\n",
    "                                    \n",
    "                                    # resItemList1\n",
    "                                    # 逆归一化,还原成预测的充电电容(150个)\n",
    "                                    res_listnew2=scalerDataη1.inverse_transform(res_list1_encoder1[:,-1].reshape(-1,1)).ravel()  \n",
    "                                    res_listnew2=res_listnew2[0:lenList[i]]\n",
    "                                    # print(\"ahh\",res_listnew)\n",
    "                                    \n",
    "                                    # print('每个电池迭代次数',lenList[i]-args.seq_len-args.pred_len+1)\n",
    "                                    # print('start',start)\n",
    "                                    # 除以'每个电池迭代次数'，得到一个电池的最终mse\n",
    "                                    # mseCell=mseCell/((lenList[i]-args.seq_len-args.pred_len)//args.pred_len+1)\n",
    "                                \n",
    "                                    # print('predictCell', len(predictCell))\n",
    "                                    \n",
    "                                    # 一套参数下所有电池的mse相加\n",
    "                                    mseAll = mseAll+mseCell\n",
    "\n",
    "\n",
    "\n",
    "                                    # testIndex = 0\n",
    "\n",
    "                                    # # print('res_listnew',res_listnew[-1])\n",
    "                                    # # 一开始用的是1A的数据,用的是初始数据\n",
    "                                    rawdata = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                     '最小值(70)2019test.xlsx')))\n",
    "                                    rawdata=rawdata.iloc[:lenList[i]].values[:,i]\n",
    "                                    \n",
    "                                    # 横坐标\n",
    "                                    x = range(1,lenList[i]+1)\n",
    "                                    # 纵坐标真实值\n",
    "                                    y = rawdata[0:]\n",
    "                                    # 纵坐标预测值     # 还原成原样\n",
    "                                    # y2 = np.array(res_listnew[:]).tolist()\n",
    "                                    # print(type(y))\n",
    "                                    # print(type(predictCell))\n",
    "                                    y2 = y[0:args.seq_len].tolist()+predictCell\n",
    "                                    y2 = y2[:lenList[i]]\n",
    "                                    YTruthAll=np.concatenate((YTruthAll, y[-lenList[i]+args.seq_len:]))\n",
    "                                    YPredAll=np.concatenate((YPredAll, y2[-lenList[i]+args.seq_len:]))\n",
    "                                    # print('predictCell',predictCell)\n",
    "                                    # print('res_listnew2',res_listnew2[50:])\n",
    "                                    # 此处写上最好的一两种参数，进行画图\n",
    "                                    if(args.lstm_hidden_size==4 and args.lstm_num_layers==2 and args.d_model==32 and args.d_ff==256):\n",
    "                                    \n",
    "                                    # print(len(y2))\n",
    "                                        print('lstm_hidden_size=', args.lstm_hidden_size)\n",
    "                                        print('lstm_num_layers=', args.lstm_num_layers)\n",
    "                                        print('d_model=', args.d_model)\n",
    "                                        print('d_ff=', args.d_ff)\n",
    "                                        print('batch=', args.batch_size)\n",
    "                                        \n",
    "                                    \n",
    "                                        plt.figure()\n",
    "                                        # plt.title(colListAll[i]+'_Model 2——'+str(testIndex)+'——'+str(num_epochs))\n",
    "                                        plt.title(colListAll[i]+'_lHS'+str(args.lstm_hidden_size)+'_lNL'+str(args.lstm_num_layers)+'_dModel'+str(args.d_model)+'_dFF'+str(args.d_ff))\n",
    "                                    \n",
    "                                        plt.xlabel('circle')\n",
    "                                        plt.ylabel('min')\n",
    "                                        plt.plot(x,y, label='True')\n",
    "                                        \n",
    "                                        plt.plot(x,y2, label='prediction', linestyle='--')\n",
    "                                        # plt.ylim(0.1,1.1)\n",
    "                                        # plt.annotate(f'{round(y[-1],4)}', (500, y[-1]))\n",
    "                                        # plt.annotate(f'{round(y2[-1],4)}', (500, y2[-1]))\n",
    "\n",
    "                                        plt.legend(loc='upper left')\n",
    "                                        # 添加虚线\n",
    "                                        # plt.axhline(y=0.88,linestyle=\"--\",c=\"black\")\n",
    "                                        plt.axvline(x=args.seq_len,ls=\"--\",c=\"black\")\n",
    "                                        for idx in range((int(plt.axis()[1])-args.seq_len)//args.pred_len):plt.axvline(x=args.seq_len+idx*args.pred_len,ls=\"--\",c=\"grey\")\n",
    "                                        # plt.axvline(y=0.88,ls=\"--\",c=\"black\")\n",
    "                                        \n",
    "                                        plt.ylim(-2.5,0.1)\n",
    "                                        # 解决中文显示问题\n",
    "                                        plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "                                        plt.rcParams['axes.unicode_minus'] = False  \n",
    "                                        # -x[-1]*0.06,min(y[-1],y2[-1])- (y[0]-y[-1])*0.3  这些是用于指定文字的坐标的\n",
    "                                        plt.text(-x[-1]*0.06,-2.85, \"真实值：\"+str(y[-1]), ha='left', fontsize=12)\n",
    "                                        plt.text(-x[-1]*0.06, -3, \"预测值：\"+str(y2[-1]), ha='left', fontsize=12)\n",
    "                                        # plt.text(-x[-1]*0.06, -0.30, \"MSE:    \"+str(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:])), ha='left', fontsize=12)\n",
    "                                        \n",
    "                                        plt.text(-x[-1]*0.06, -3.15, \"MSE:    \"+str(\"{:.2e}\".format(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:]))), ha='left', fontsize=12)\n",
    "                                        # plt.savefig('./img(min)/'+colListAll[i]+'模型1-h64-testIndex='+str(testIndex)+'-epoch='+str(num_epochs)+'.jpg', format='jpg', dpi=200)\n",
    "                                        # print(plt.axis()[2])\n",
    "                                        plt.show()\n",
    "                                        print('真实值：',y[-1])\n",
    "                                        print('预测值：',y2[-1])\n",
    "                                        print('MSE：',mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:]))\n",
    "                                    \n",
    "                                    # 电池\n",
    "                                    realCellAll=pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                   '最小值(70)2019test.xlsx')))\n",
    "                                    # 这一列的全部真实值\n",
    "                                    realCellAll=realCellAll.iloc[:lenList[i]].values[:,i].reshape(-1, 1)\n",
    "                                    # 最终得到的realCell是与predict的shape一样的，可以用于计算mse，r平方之类\n",
    "                                    # for idx in range(lenList[i]-args.seq_len-args.pred_len+1):\n",
    "                                    #     for element in realCellAll[idx+args.seq_len : idx+args.seq_len+args.pred_len]:\n",
    "                                    #         realCell.append(element)\n",
    "                                    # mean_squared_error(realCell,predictCell)与上面计算的mseCell一样\n",
    "                                    realCell=y[-lenList[i]+args.seq_len:]\n",
    "                                    # print('mse新',mean_squared_error(realCell,predictCell))\n",
    "                                    # print('mse新xin',mean_squared_error(realCell,res_listnew2[100:]))\n",
    "                                    # print('mseCell',mseCell)\n",
    "                                    # 可以计算r平方\n",
    "                                    # print('r',r2_score(realCell,predictCell))\n",
    "                                    \n",
    "                                        # excelHead.append(colListAll[i])\n",
    "                                        # excelMse.append(\"{:.2e}\".format(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:])))\n",
    "                                    \n",
    "                                    # 暂时先不要R2\n",
    "                                    # excelR2.append(r2_score(realCell,predictCell))\n",
    "                                    \n",
    "                            # print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "                            # print('d_model=', args.d_model)\n",
    "                            # print('d_ff=', args.d_ff) \n",
    "                            # print('电池个数',dataAll.shape[1])\n",
    "                            # 是一个参数下所有电池的  \n",
    "                            # print('mseAll',mseAll/dataAll.shape[1])\n",
    "                            excelHead.append('总MSE')\n",
    "                            excelMse.append(\"{:.2e}\".format(mean_squared_error(np.array(YTruthAll).flatten(),np.array(YPredAll).flatten())))\n",
    "                            excelHead.append('总MAE')\n",
    "                            excelMse.append(\"{:.2e}\".format(np.mean(np.abs(np.array(YTruthAll).flatten() - np.array(YPredAll).flatten()))))\n",
    "                            excelHead.append('总MAPE')\n",
    "                            excelMse.append(\"{:.2e}\".format(np.mean(np.abs((np.array(YTruthAll).flatten() - np.array(YPredAll).flatten()) / np.array(YTruthAll).flatten())) * 100 ))\n",
    "                            # excelMse.append('2')\n",
    "                            excelHead.append('总R2')\n",
    "                            excelMse.append(\"{:.2e}\".format(r2_score(np.array(YTruthAll).flatten(),np.array(YPredAll).flatten())))\n",
    "                            # 电池编号（第一行）未加入，就加一次\n",
    "                            if excelDataAll ==[]: excelDataAll.append(excelHead)\n",
    "                            excelDataAll.append(excelMse)\n",
    "                            # data = [\n",
    "                            #     excelHead,\n",
    "                            #     excelMse,\n",
    "                            #     # excelR2\n",
    "                            # ]\n",
    "\n",
    "                            # 创建数据框\n",
    "    column_means = [sum(float(row[i]) for row in excelDataAll[1:]) / excelDataAll[1:].__len__() for i in range(1, excelDataAll[0].__len__())]\n",
    "    excelMean=['均值']\n",
    "    for i in range(column_means.__len__()):\n",
    "        excelMean.append(\"{:.2e}\".format(column_means[i]))\n",
    "    excelDataAll.append(excelMean)\n",
    "    df = pd.DataFrame(excelDataAll)\n",
    "    # 保存为 Excel 文件\n",
    "    file_path = excelOutPath\n",
    "    # 创建 Styler 对象并设置单元格样式\n",
    "    styler = df.style.set_properties(**{'text-align': 'center'})\n",
    "    # df.to_excel(file_path, index=False, header=False)\n",
    "    styler.to_excel(file_path, index=False, header=False)\n",
    "    print('数据已保存为 Excel 文件.')\n",
    "\n",
    "except Exception as e:\n",
    "    print(traceback.print_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测值，生成train的预测结果并存表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "try:\n",
    "    from sklearn.metrics import mean_squared_error # 均方误差\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    excelOutPath = 'Useless.xlsx'\n",
    "    # 输出的所有excel数据\n",
    "    excelDataAll=[]\n",
    "    lstm_hidden_size_vlaues=[4]\n",
    "    lstm_num_layers_vlaues=[2]\n",
    "    d_model_values=[32]\n",
    "    d_ff_values=[256]\n",
    "    seed_values=[12345,54321,42,7,3000]\n",
    "    # d_model_values=[32]\n",
    "    # d_ff_values=[128]\n",
    "\n",
    "    for lstm_hidden_size in lstm_hidden_size_vlaues:\n",
    "        for lstm_num_layers in lstm_num_layers_vlaues:\n",
    "            for d_model in d_model_values:\n",
    "                for d_ff in d_ff_values:\n",
    "                    for seeds in seed_values:\n",
    "                    # if d_ff >= d_model:\n",
    "            \n",
    "                        # 进行parser的变量初始化，获取实例。\n",
    "                        args = initialize_parameter()\n",
    "                        args.lstm_hidden_size=lstm_hidden_size\n",
    "                        args.lstm_num_layers=lstm_num_layers\n",
    "                        args.d_model=d_model\n",
    "                        args.d_ff=d_ff\n",
    "                        args.seed=seeds\n",
    "                \n",
    "                        seed=args.seed\n",
    "                        random.seed(seed)\n",
    "                        os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "                        np.random.seed(seed)\n",
    "                        torch.manual_seed(seed)\n",
    "                        torch.cuda.manual_seed(seed)\n",
    "                        torch.cuda.manual_seed_all(seed)\n",
    "                        torch.backends.cudnn.deterministic =True\n",
    "                        # 获取运行文件的路径  \n",
    "                        run_name_dir_old = args.model + \"_e\" + str(args.train_epochs) + \"_b\" + str(args.batch_size) + \"_lhs\" + str(args.lstm_hidden_size) + \"_lnl\" + str(args.lstm_num_layers) + \"_dModel\" + str(args.d_model) + \"_dFF\" + str(args.d_ff)+ \"_s\" + str(args.seq_len) + \"_l\" + str(args.label_len) + \"_p\" + str(args.pred_len)+ \"_\" + args.data\n",
    "                        # 右侧的args.output表示output文件夹 \n",
    "                        # output\\rose_1变量一对一_w\n",
    "                        args.output = os.path.join(args.output,args.data+\"_\" + args.sub_them)\n",
    "                        # 输出的文件夹位置：output\\min_1变量一对一\\informer_e50_b1024_dModel32_dFF128_s80_l40_p_40_min\n",
    "                        run_name_dir = os.path.join(args.output, run_name_dir_old)\n",
    "                        # 单次运行的n个实验的模型存储的路径：需要判断是否存在，训练的时候已经判断了\n",
    "                        # ./checkpoints/batterySD\n",
    "                        run_name_dir_ckp_main = os.path.join(args.checkpoints, args.data)\n",
    "                        # './checkpoints/batterySD\\\\TwoFeatures(Δη,QD)\\\\informer_e50_b32_dModel32_dFF128_s100_l50_p50_batterySD'   \n",
    "                        run_name_dir_ckp = os.path.join(run_name_dir_ckp_main,'minNew/informerLSTM(pretreatment,ResNet,XL)' ,run_name_dir_old)\n",
    "\n",
    "\n",
    "                        # 为了不经过训练，导入模型\n",
    "                        dataset = Dataset_Custom(\n",
    "                                    root_path=args.root_path,\n",
    "                                    data_path=args.data_path,\n",
    "                                    # 此处这个flag无影响\n",
    "                                    flag='test',\n",
    "                                    # informer原论文中，这三个分别为96，48，24，分别是输入encoder的序列长度、\n",
    "                                    # （48+24）为输入decoder的序列长度，24为预测长度\n",
    "                                    size=[args.seq_len, args.label_len, args.pred_len],\n",
    "                                    # M、S、MS，表示多变量预测、单变量预测、多变量预测单变量\n",
    "                                    features=args.features,\n",
    "                                    # target=args.target,\n",
    "                                    # inverse=args.inverse,\n",
    "                                    # 不用管，内部写死了\n",
    "                                    timeenc=0,\n",
    "                                    # freq=freq,\n",
    "                                    # scale=args.scale,\n",
    "                                    # cols=args.cols,\n",
    "                                    args=args\n",
    "                                )\n",
    "                        scalerDataη1=dataset.scalerDataη\n",
    "                        if args.use_gpu:\n",
    "                            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) if not args.use_multi_gpu else self.args.devices\n",
    "                            device = torch.device('cuda:{}'.format(args.gpu))\n",
    "                            # print('Use GPU: cuda:{}'.format(args.gpu))\n",
    "                        else:\n",
    "                            device = torch.device('cpu')\n",
    "                        model_dict = {\n",
    "                                    'informer':Informer,\n",
    "                                    'informerstack':InformerStack,\n",
    "                                }\n",
    "                        e_layers = args.e_layers if args.model=='informer' else args.s_layers\n",
    "                        # 如果args.model是informer，那么model_dict[args.model]就是Informer类\n",
    "                        model = model_dict[args.model](\n",
    "                            args.enc_in,\n",
    "                            args.dec_in, \n",
    "                            args.c_out, \n",
    "                            args.lstm_hidden_size,\n",
    "                            args.lstm_num_layers,\n",
    "                            args.seq_len, \n",
    "                            args.label_len,\n",
    "                            args.pred_len, \n",
    "                            args.factor,\n",
    "                            args.d_model, \n",
    "                            args.n_heads, \n",
    "                            e_layers, # args.e_layers,\n",
    "                            args.d_layers, \n",
    "                            args.d_ff,\n",
    "                            args.dropout, \n",
    "                            args.attn,\n",
    "                            args.embed,\n",
    "                            args.freq,\n",
    "                            args.activation,\n",
    "                            args.output_attention,\n",
    "                            args.distil,\n",
    "                            args.mix,\n",
    "                            device\n",
    "                        ).float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        # 清除缓存                \n",
    "                        # 没有BN层与DropOut层时，new_model.eval()可以不加\n",
    "                        with  torch.no_grad():\n",
    "                            path = os.path.join(run_name_dir_ckp ,setting)\n",
    "                            best_model_path = path+'/'+'checkpoint.pth'\n",
    "                        \n",
    "                            print(best_model_path)\n",
    "                            model.load_state_dict(torch.load(best_model_path))\n",
    "                            model.eval()\n",
    "                            model.to('cpu')\n",
    "\n",
    "                            \n",
    "\n",
    "                            # 命名的时候带All表示所有的数据，只是用来看每一列的长度的，但此处实际上每列长度固定为500了\n",
    "                            dataAll=pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                    '最小值(70)2019train.xlsx')))\n",
    "                        \n",
    "                            dataAll=dataAll.iloc[:1500]\n",
    "                            lenList=[]\n",
    "                            lenListSum=0\n",
    "                            colListAll=[]\n",
    "\n",
    "                            # 每列的长度，实际此处数据每列固定为500，但可以处理每列数据不一样的情况\n",
    "                            for j,col in enumerate(dataAll.columns):\n",
    "                                # 每列的长度\n",
    "                                len=(np.array(dataAll.iloc[:,j].dropna())).shape[0]\n",
    "                                lenList.append(len)\n",
    "                                lenListSum=lenListSum+len\n",
    "                                # 表的列名，用于给图片命名，表明电池编号\n",
    "                                colListAll.append(col)\n",
    "\n",
    "                            # print('lenList',lenList)    \n",
    "                            # mseAll是一个参数下的，被一个参数下的所有电池所共有，而对于不同的参数，mseAll不同\n",
    "                            mseAll=0\n",
    "                            excelHead=['参数']\n",
    "                            excelMse=['lhs_'+str(args.lstm_hidden_size)+'，lnl_'+str(args.lstm_num_layers)+'，dM_'+str(args.d_model)+'，dFF_'+str(args.d_ff)]\n",
    "                            YTruthAll=[]\n",
    "                            YPredAll=[]\n",
    "                            # excelR2=['R\\u00B2']\n",
    "                            excel_file = \"data/batteryNature/预测结果最小值(70)2019_\"+ str(args.seed) +\"train.xlsx\"\n",
    "\n",
    "                            # 创建一个空的DataFrame\n",
    "                            df = pd.DataFrame(index=range(1500))\n",
    "                            # i是训练集的每一列（每一个电池），跑完就是一个参数下所有电池跑完\n",
    "                            for i in range(dataAll.shape[1]):\n",
    "                                # if(i==28 or i==29):\n",
    "                                if(i>-1):\n",
    "                                # if(i<2):\n",
    "                                \n",
    "                                    lenList[i]\n",
    "\n",
    "                                    # rawdataNewQD1 = pd.read_excel(filepathQD)\n",
    "                                    # rawdataNewQD1=rawdataNewQD1.drop(rawdataNewQD1.columns[2], axis=1).values[0:lenList[i],i].reshape(-1, 1)\n",
    "                                    # rawdataNewQD1 = pd.read_excel((os.path.join(args.root_path,\n",
    "                                    #                                 'QD(test).xlsx')))\n",
    "                                    # rawdataNewQD1=rawdataNewQD1.iloc[:500].values[:,i].reshape(-1, 1)\n",
    "                                    # print('rawdataNewQD1',rawdataNewQD1)\n",
    "                                    \n",
    "                                    rawdataNewη1 = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                            '最小值(70)2019train.xlsx')))\n",
    "                                    # 这一列的全部真实值\n",
    "                                    rawdataNewη1=rawdataNewη1.iloc[:lenList[i]].values[:,i].reshape(-1, 1)\n",
    "                                    # print('rawdataNew',rawdataNewη1)\n",
    "                                \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    # rawdataNewVar1 = pd.read_excel(filepathVar)\n",
    "                                    # rawdataNewVar1=rawdataNewVar1.drop(rawdataNewVar1.columns[2], axis=1).values[0:lenList[i],i].reshape(-1, 1)\n",
    "                                    # print('rawdataNew1',rawdataNew1)\n",
    "                                    # rawdataNewQD1 = scalerDataQD1.transform(rawdataNewQD1)\n",
    "                                    # rawdataNewQD1 = scalerDataQD1.transform(rawdataNewQD1)\n",
    "                                    # 归一化后输入模型\n",
    "                                    rawdataNewη1 = scalerDataη1.transform(rawdataNewη1)\n",
    "                                    # rawdataNewη1 = rawdataNewη1\n",
    "                                \n",
    "                                    # rawdataNewVar1 = scalerDataVar1.transform(rawdataNewVar1)\n",
    "                                    # print('rawdataNewQD1',rawdataNewQD1)\n",
    "                                    # print('rawdataNew',rawdataNewη1)\n",
    "\n",
    "\n",
    "\n",
    "                                    # rawdataNew1 = pd.read_excel(filepath).values[0:200,18].reshape(-1, 1)\n",
    "                                    # reshape(1,1,-1)的第一个 1 表示 channel为1\n",
    "                                    # result1=rawdataNewMin1\n",
    "                                    # result1=zip(rawdataNewQD1[:,0],rawdataNewη1[:,0])\n",
    "                                    result1=np.vstack((rawdataNewη1))\n",
    "                                        \n",
    "                                    # print(result1.shape)\n",
    "                                    # print(result1)\n",
    "                                \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    # rawdataNew1聚集了3个特征\n",
    "                                    # rawdataNew1=np.array(list(result1))\n",
    "\n",
    "                                    res_list1_encoder1 = torch.from_numpy(result1[:args.seq_len])\n",
    "                                    # res_list1_decoder1 = torch.from_numpy(result1[args.seq_len-args.label_len:args.seq_len])\n",
    "                                    # print('res_list1_encoder1',res_list1_encoder1)\n",
    "                                    # print('res_list1_decoder1',res_list1_decoder1.shape)\n",
    "                                    # print('res_list',type(res_list1))\n",
    "\n",
    "                                    # print(rawdataNew1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                    # print('np.array([IAll[j]])',np.array([IAll[j]]))\n",
    "\n",
    "                                    start = 0\n",
    "                                    # 一直预测到200\n",
    "                                    # resItemList用于记录所有的预测值(450个)\n",
    "                                    resItemList1=[]\n",
    "                                    rawdata = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                            '最小值(70)2019train.xlsx')))\n",
    "                                    # 该列电池真实值（不做归一化）\n",
    "                                    rawdata=rawdata.iloc[:lenList[i]].values[:,i]\n",
    "                                    # 下面几个参数是一个电池所共有的\n",
    "                                    mseCell=0\n",
    "                                    # 下面两个是为了方便计算R平方等值用的\n",
    "                                    predictCell=[]\n",
    "                                    realCell=[]\n",
    "                                    # lenList[i]-args.seq_len)//args.pred_len+1是执行次数，也即扔到model的次数\n",
    "                                    # while(start<(lenList[i]-args.seq_len)//args.pred_len):\n",
    "                                    # 循环结束是一个电池的预测结束\n",
    "                                    while(start<((lenList[i]-args.seq_len)//args.pred_len)+1):\n",
    "                                        window_encoder= torch.tensor(res_list1_encoder1[start*args.pred_len: start*args.pred_len+args.seq_len])\n",
    "                                        # 注意，这边还是从encoder中取\n",
    "                                        # print('window_encoder',window_encoder)\n",
    "                                        # print('window_encoder',window_encoder.shape)\n",
    "                                        # break\n",
    "                                        window_decoder= torch.tensor(res_list1_encoder1[start*args.pred_len+args.seq_len- args.label_len: start*args.pred_len+args.seq_len])\n",
    "                                        # print('window_decoder',window_decoder)\n",
    "                                        # print('window_decoder',window_decoder.shape)\n",
    "                                        # 不用管，内部写死了，获取带有掩码的输入序列x\n",
    "                                        seq_x_mark = torch.zeros(1)\n",
    "                                        # 获取带有掩码的输入序列x\n",
    "                                        seq_y_mark = torch.zeros(1)\n",
    "                                        \n",
    "                                        \n",
    "                                        if args.use_gpu:\n",
    "                                            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) if not args.use_multi_gpu else self.args.devices\n",
    "                                            device = torch.device('cuda:{}'.format(args.gpu))\n",
    "                                            # print('Use GPU: cuda:{}'.format(args.gpu))\n",
    "                                        else:\n",
    "                                            device = torch.device('cpu')\n",
    "                                        global dec_inp\n",
    "                                        batch_x = window_encoder.float()\n",
    "                                        batch_y = window_decoder.float()\n",
    "\n",
    "                                        batch_x_mark = seq_x_mark.float()\n",
    "                                        batch_y_mark = seq_y_mark.float()\n",
    "                                        batch_x=batch_x.unsqueeze(0)\n",
    "                                        batch_y=batch_y.unsqueeze(0)\n",
    "                                        batch_x_mark=batch_x_mark.unsqueeze(0)\n",
    "                                        batch_y_mark=batch_y_mark.unsqueeze(0)\n",
    "                                        # decoder input\n",
    "                                        if args.padding==0:\n",
    "                                            # 返回一个形状为为size，size是一个list，代表了数组的shape,类型为torch.dtype，里面的每一个值都是0的tensor\n",
    "                                            # batch_y.shape[0]是self.lbel_len + self.pred_len\n",
    "                                            # batch_y.shape[-1]是特征数,单特征预测单特征的情况下，这里是1\n",
    "                                            dec_inp = torch.zeros([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "                                        elif args.padding==1:\n",
    "                                            dec_inp = torch.ones([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "                                        # 在给定维度上对输入的张量序列seq 进行连接操作。\n",
    "                                        \"\"\"\n",
    "                                        outputs = torch.cat(inputs, dim=0) → Tensor\n",
    "                                        \n",
    "                                        inputs : 待连接的张量序列，可以是任意相同Tensor类型的python 序列，可以是列表或者元组。\n",
    "                                        dim : 选择的扩维, 必须在0到len(inputs[0])之间，沿着此维连接张量序列。\n",
    "                                        \"\"\"\n",
    "                                        dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float()\n",
    "                                        # encoder - decoder（编码器-解码器）\n",
    "                                        # 假如使用自动混合精度训练\n",
    "                                        if args.use_amp:\n",
    "                                            # pytorch 使用autocast半精度进行加速训练\n",
    "                                            with torch.cuda.amp.autocast():\n",
    "                                                # 假如在编码器中输出注意力\n",
    "                                                if args.output_attention:\n",
    "                                                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                                                else:\n",
    "                                                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                                        # 假如不使用自动混合精度训练\n",
    "                                        else:\n",
    "                                            if args.output_attention:\n",
    "                                                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                                            else:\n",
    "                                                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                                        # print(outputs.shape)\n",
    "                                        # print(outputs)\n",
    "                                        # 逆标准化输出数据\n",
    "                                        # 暂时不管他\n",
    "                                        # if self.args.inverse:\n",
    "                                        #     outputs = dataset_object.inverse_transform(outputs)\n",
    "                                        f_dim = -1 if args.features=='MS' else 0\n",
    "                                        # 如果是MS。那么只留有一列输出\n",
    "                                        # outputs = outputs[:, :, 1:] if args.features == 'MS' else outputs\n",
    "                                        # 对y进行解码\n",
    "                                        # 取出pred\n",
    "                                        batch_y = batch_y[:,-args.pred_len:,f_dim:]\n",
    "\n",
    "                                        # 如果是M任务，那么进行打平再输出去计算梯度\n",
    "                                        # output作为预测值，batch_y(取出pred部分，也就是长度40)作为真实值\n",
    "                                        # return outputs, batch_y\n",
    "                                        \n",
    "                                        # outputs(1,50,1)\n",
    "                                        # resultTemp=torch.tensor(np.vstack((outputs.squeeze(0))))\n",
    "                                        # # print('resultTemp',resultTemp)\n",
    "                                        # # 存的是真实值以及预测值的拼接,outputs(1,50,1)\n",
    "                                        # res_list1_encoder1=torch.cat([res_list1_encoder1,resultTemp],dim=0)\n",
    "                                        # print('res_list1_encoder1',res_list1_encoder1[:,-1])                \n",
    "                                        \n",
    "                                        # 存的是真实值以及预测值的拼接\n",
    "                                        res_list1_encoder1=torch.cat([res_list1_encoder1,outputs.squeeze(0)],dim=0)\n",
    "                                        \n",
    "                                        # 算mse\n",
    "                                        # 逆归一化\n",
    "                                        res_listnew=scalerDataη1.inverse_transform(outputs.squeeze(0).reshape(-1,1)).ravel()  \n",
    "                                        # res_listnew=res_listnew[0:lenList[i]]\n",
    "                                        # 真实值和预测值的mse    \n",
    "                                        # rawdata为未归一化时的真实值\n",
    "                                        # 一个电池中的所有mse相加                    \n",
    "                                        # print('start=',start)\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len])\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len].shape)\n",
    "                                        # print('res_listnew',res_listnew.shape)\n",
    "                                        # print('ahh',)[start*args.pred_len: start*args.pred_len+args.seq_len])\n",
    "                                        # mseCell=mseCell+mean_squared_error(rawdata[start*args.pred_len+args.seq_len : start*args.pred_len+args.seq_len+args.pred_len],res_listnew)\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len])\n",
    "                                        # 存入predicetCell\n",
    "                                        # predictCell里面存的是逆归一化之后的预测值\n",
    "                                        for element in res_listnew:\n",
    "                                            predictCell.append(element)\n",
    "                                        \n",
    "                                        \n",
    "                                        start = start + 1\n",
    "                                        # 这边改成全用真实值\n",
    "                                        # res_list1_encoder1=torch.from_numpy(result1[start*args.pred_len : start*args.pred_len+args.seq_len])\n",
    "                                        # print('ahh',res_list1_encoder1)\n",
    "                                        \n",
    "                                        \n",
    "                                    \n",
    "                                        # resItemList1.append(outputs)\n",
    "                                        # 将循环号归一化后合并\n",
    "                                        # reshape(1,1,1) 的第一个参数 1 表示 channel为 1\n",
    "                                        # result=np.array([res.item()]).reshape(1,1,1)\n",
    "                                        # print(result)\n",
    "                                        # print(result.shape)\n",
    "                                        # res_list1=np.concatenate((res_list1,result),axis=2)\n",
    "                                        # print(res_list1)\n",
    "                                        # print(res_list1.shape)\n",
    "                                        \n",
    "\n",
    "                                    \n",
    "                                    # resItemList1\n",
    "                                    # 逆归一化,还原成预测的充电电容(150个)\n",
    "                                    res_listnew2=scalerDataη1.inverse_transform(res_list1_encoder1[:,-1].reshape(-1,1)).ravel()  \n",
    "                                    res_listnew2=res_listnew2[0:lenList[i]]\n",
    "                                    # print(\"ahh\",res_listnew)\n",
    "                                    \n",
    "                                    # print('每个电池迭代次数',lenList[i]-args.seq_len-args.pred_len+1)\n",
    "                                    # print('start',start)\n",
    "                                    # 除以'每个电池迭代次数'，得到一个电池的最终mse\n",
    "                                    # mseCell=mseCell/((lenList[i]-args.seq_len-args.pred_len)//args.pred_len+1)\n",
    "                                \n",
    "                                    # print('predictCell', len(predictCell))\n",
    "                                    \n",
    "                                    # 一套参数下所有电池的mse相加\n",
    "                                    mseAll = mseAll+mseCell\n",
    "        \n",
    "                            \n",
    "\n",
    "\n",
    "                                    # testIndex = 0\n",
    "\n",
    "                                    # # print('res_listnew',res_listnew[-1])\n",
    "                                    # # 一开始用的是1A的数据,用的是初始数据\n",
    "                                    rawdata = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                            '最小值(70)2019train.xlsx')))\n",
    "                                    rawdata=rawdata.iloc[:lenList[i]].values[:,i]\n",
    "                                    \n",
    "                                    # 横坐标\n",
    "                                    x = range(1,lenList[i]+1)\n",
    "                                    # 纵坐标真实值\n",
    "                                    y = rawdata[0:]\n",
    "                                    # 纵坐标预测值     # 还原成原样\n",
    "                                    # y2 = np.array(res_listnew[:]).tolist()\n",
    "                                    # print(type(y))\n",
    "                                    # print(type(predictCell))\n",
    "                                    y2 = y[0:args.seq_len].tolist()+predictCell\n",
    "                                    # y2 = y2[:lenList[i]]\n",
    "                                    col_list = y2\n",
    "                                    col_name = colListAll[i]\n",
    "                                    # 使用assign方法将每个colList添加到DataFrame中\n",
    "                                    df[col_name] = pd.Series(col_list)\n",
    "                                    YTruthAll=np.concatenate((YTruthAll, y[-lenList[i]+args.seq_len:]))\n",
    "                                    YPredAll=np.concatenate((YPredAll, y2[-lenList[i]+args.seq_len:]))\n",
    "                                    # print('predictCell',predictCell)\n",
    "                                    # print('res_listnew2',res_listnew2[50:])\n",
    "                                    # 此处写上最好的一两种参数，进行画图\n",
    "                                    if(args.lstm_hidden_size==32 and args.lstm_num_layers==3 and args.d_model==32 and args.d_ff==128):\n",
    "                                    # print(len(y2))\n",
    "                                        print('d_model=', args.d_model)\n",
    "                                        print('d_ff=', args.d_ff)\n",
    "                                        print('batch=', args.batch_size)\n",
    "                                        \n",
    "                                    \n",
    "                                        plt.figure()\n",
    "                                        # plt.title(colListAll[i]+'_Model 2——'+str(testIndex)+'——'+str(num_epochs))\n",
    "                                        plt.title(colListAll[i]+'_lHS'+str(args.lstm_hidden_size)+'_lNL'+str(args.lstm_num_layers)+'_dModel'+str(args.d_model)+'_dFF'+str(args.d_ff))\n",
    "                                    \n",
    "                                        plt.xlabel('circle')\n",
    "                                        plt.ylabel('min')\n",
    "                                        plt.plot(x,y, label='True')\n",
    "                                        \n",
    "                                        plt.plot(x,y2, label='prediction', linestyle='--')\n",
    "                                        # plt.ylim(0.1,1.1)\n",
    "                                        # plt.annotate(f'{round(y[-1],4)}', (500, y[-1]))\n",
    "                                        # plt.annotate(f'{round(y2[-1],4)}', (500, y2[-1]))\n",
    "\n",
    "                                        plt.legend(loc='upper left')\n",
    "                                        # 添加虚线\n",
    "                                        # plt.axhline(y=0.88,linestyle=\"--\",c=\"black\")\n",
    "                                        plt.axvline(x=args.seq_len,ls=\"--\",c=\"black\")\n",
    "                                        for idx in range((int(plt.axis()[1])-args.seq_len)//args.pred_len):plt.axvline(x=args.seq_len+idx*args.pred_len,ls=\"--\",c=\"grey\")\n",
    "                                        # plt.axvline(y=0.88,ls=\"--\",c=\"black\")\n",
    "                                        \n",
    "                                        plt.ylim(-2.5,0.1)\n",
    "                                        # 解决中文显示问题\n",
    "                                        plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "                                        plt.rcParams['axes.unicode_minus'] = False  \n",
    "                                        # -x[-1]*0.06,min(y[-1],y2[-1])- (y[0]-y[-1])*0.3  这些是用于指定文字的坐标的\n",
    "                                        plt.text(-x[-1]*0.06,-2.85, \"真实值：\"+str(y[-1]), ha='left', fontsize=12)\n",
    "                                        plt.text(-x[-1]*0.06, -3, \"预测值：\"+str(y2[-1]), ha='left', fontsize=12)\n",
    "                                        # plt.text(-x[-1]*0.06, -0.30, \"MSE:    \"+str(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:])), ha='left', fontsize=12)\n",
    "                                        \n",
    "                                        plt.text(-x[-1]*0.06, -3.15, \"MSE:    \"+str(\"{:.2e}\".format(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:]))), ha='left', fontsize=12)\n",
    "                                        # plt.savefig('./img(min)/'+colListAll[i]+'模型1-h64-testIndex='+str(testIndex)+'-epoch='+str(num_epochs)+'.jpg', format='jpg', dpi=200)\n",
    "                                        # print(plt.axis()[2])\n",
    "                                        plt.show()\n",
    "                                        print('真实值：',y[-1])\n",
    "                                        print('预测值：',y2[-1])\n",
    "                                        print('MSE：',mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:]))\n",
    "                                    \n",
    "                                    # 电池\n",
    "                                    realCellAll=pd.read_excel((os.path.join(args.root_path,\n",
    "                                                            '最小值(70)2019train.xlsx')))\n",
    "                                    # 这一列的全部真实值\n",
    "                                    realCellAll=realCellAll.iloc[:lenList[i]].values[:,i].reshape(-1, 1)\n",
    "                                    # 最终得到的realCell是与predict的shape一样的，可以用于计算mse，r平方之类\n",
    "                                    # for idx in range(lenList[i]-args.seq_len-args.pred_len+1):\n",
    "                                    #     for element in realCellAll[idx+args.seq_len : idx+args.seq_len+args.pred_len]:\n",
    "                                    #         realCell.append(element)\n",
    "                                    # mean_squared_error(realCell,predictCell)与上面计算的mseCell一样\n",
    "                                    realCell=y[-lenList[i]+args.seq_len:]\n",
    "                                    # print('mse新',mean_squared_error(realCell,predictCell))\n",
    "                                    # print('mse新xin',mean_squared_error(realCell,res_listnew2[100:]))\n",
    "                                    # print('mseCell',mseCell)\n",
    "                                    # 可以计算r平方\n",
    "                                    # print('r',r2_score(realCell,predictCell))\n",
    "                                    \n",
    "                                    excelHead.append(colListAll[i])\n",
    "                                    excelMse.append(\"{:.2e}\".format(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:])))\n",
    "                                    \n",
    "                                    # 暂时先不要R2\n",
    "                                    # excelR2.append(r2_score(realCell,predictCell))\n",
    "                            # 将DataFrame保存为Excel文件\n",
    "                            df.to_excel(excel_file, index=False)        \n",
    "                            # print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "                            # print('d_model=', args.d_model)\n",
    "                            # print('d_ff=', args.d_ff) \n",
    "                            # print('电池个数',dataAll.shape[1])\n",
    "                            # 是一个参数下所有电池的  \n",
    "                            # print('mseAll',mseAll/dataAll.shape[1])\n",
    "                            excelHead.append('总MSE')\n",
    "                            excelMse.append(\"{:.2e}\".format(mean_squared_error(np.array(YTruthAll).flatten(),np.array(YPredAll).flatten())))\n",
    "                            excelHead.append('总R2')\n",
    "                            excelMse.append(\"{:.2e}\".format(r2_score(np.array(YTruthAll).flatten(),np.array(YPredAll).flatten())))\n",
    "                            # 电池编号（第一行）未加入，就加一次\n",
    "                            if excelDataAll ==[]: excelDataAll.append(excelHead)\n",
    "                            excelDataAll.append(excelMse)\n",
    "                            # data = [\n",
    "                            #     excelHead,\n",
    "                            #     excelMse,\n",
    "                            #     # excelR2\n",
    "                            # ]\n",
    "\n",
    "                            # 创建数据框\n",
    "    # df = pd.DataFrame(excelDataAll)\n",
    "    # # 保存为 Excel 文件\n",
    "    # file_path = excelOutPath\n",
    "    # # 创建 Styler 对象并设置单元格样式\n",
    "    # styler = df.style.set_properties(**{'text-align': 'center'})\n",
    "    # # df.to_excel(file_path, index=False, header=False)\n",
    "    # styler.to_excel(file_path, index=False, header=False)\n",
    "    print('数据已保存为 Excel 文件.')\n",
    "\n",
    "except Exception as e:\n",
    "    print(traceback.print_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测值，生成test的预测结果并存表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "try:\n",
    "    from sklearn.metrics import mean_squared_error # 均方误差\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    excelOutPath = 'Useless.xlsx'\n",
    "    # 输出的所有excel数据\n",
    "    excelDataAll=[]\n",
    "    lstm_hidden_size_vlaues=[4]\n",
    "    lstm_num_layers_vlaues=[2]\n",
    "    d_model_values=[32]\n",
    "    d_ff_values=[256]\n",
    "    seed_values=[12345,54321,42,7,3000]\n",
    "    # d_model_values=[32]\n",
    "    # d_ff_values=[128]\n",
    "\n",
    "    for lstm_hidden_size in lstm_hidden_size_vlaues:\n",
    "        for lstm_num_layers in lstm_num_layers_vlaues:\n",
    "            for d_model in d_model_values:\n",
    "                for d_ff in d_ff_values:\n",
    "                    for seeds in seed_values:\n",
    "                    # if d_ff >= d_model:\n",
    "            \n",
    "                        # 进行parser的变量初始化，获取实例。\n",
    "                        args = initialize_parameter()\n",
    "                        args.lstm_hidden_size=lstm_hidden_size\n",
    "                        args.lstm_num_layers=lstm_num_layers\n",
    "                        args.d_model=d_model\n",
    "                        args.d_ff=d_ff\n",
    "                        args.seed=seeds\n",
    "                \n",
    "                        seed=args.seed\n",
    "                        random.seed(seed)\n",
    "                        os.environ['PYTHONHASHSEED'] =str(seed)\n",
    "                        np.random.seed(seed)\n",
    "                        torch.manual_seed(seed)\n",
    "                        torch.cuda.manual_seed(seed)\n",
    "                        torch.cuda.manual_seed_all(seed)\n",
    "                        torch.backends.cudnn.deterministic =True\n",
    "                        # 获取运行文件的路径  \n",
    "                        run_name_dir_old = args.model + \"_e\" + str(args.train_epochs) + \"_b\" + str(args.batch_size) + \"_lhs\" + str(args.lstm_hidden_size) + \"_lnl\" + str(args.lstm_num_layers) + \"_dModel\" + str(args.d_model) + \"_dFF\" + str(args.d_ff)+ \"_s\" + str(args.seq_len) + \"_l\" + str(args.label_len) + \"_p\" + str(args.pred_len)+ \"_\" + args.data\n",
    "                        # 右侧的args.output表示output文件夹 \n",
    "                        # output\\rose_1变量一对一_w\n",
    "                        args.output = os.path.join(args.output,args.data+\"_\" + args.sub_them)\n",
    "                        # 输出的文件夹位置：output\\min_1变量一对一\\informer_e50_b1024_dModel32_dFF128_s80_l40_p_40_min\n",
    "                        run_name_dir = os.path.join(args.output, run_name_dir_old)\n",
    "                        # 单次运行的n个实验的模型存储的路径：需要判断是否存在，训练的时候已经判断了\n",
    "                        # ./checkpoints/batterySD\n",
    "                        run_name_dir_ckp_main = os.path.join(args.checkpoints, args.data)\n",
    "                        # './checkpoints/batterySD\\\\TwoFeatures(Δη,QD)\\\\informer_e50_b32_dModel32_dFF128_s100_l50_p50_batterySD'   \n",
    "                        run_name_dir_ckp = os.path.join(run_name_dir_ckp_main,'minNew/informerLSTM(pretreatment,ResNet,XL)' ,run_name_dir_old)\n",
    "\n",
    "\n",
    "                        # 为了不经过训练，导入模型\n",
    "                        dataset = Dataset_Custom(\n",
    "                                    root_path=args.root_path,\n",
    "                                    data_path=args.data_path,\n",
    "                                    # 此处这个flag无影响\n",
    "                                    flag='test',\n",
    "                                    # informer原论文中，这三个分别为96，48，24，分别是输入encoder的序列长度、\n",
    "                                    # （48+24）为输入decoder的序列长度，24为预测长度\n",
    "                                    size=[args.seq_len, args.label_len, args.pred_len],\n",
    "                                    # M、S、MS，表示多变量预测、单变量预测、多变量预测单变量\n",
    "                                    features=args.features,\n",
    "                                    # target=args.target,\n",
    "                                    # inverse=args.inverse,\n",
    "                                    # 不用管，内部写死了\n",
    "                                    timeenc=0,\n",
    "                                    # freq=freq,\n",
    "                                    # scale=args.scale,\n",
    "                                    # cols=args.cols,\n",
    "                                    args=args\n",
    "                                )\n",
    "                        scalerDataη1=dataset.scalerDataη\n",
    "                        if args.use_gpu:\n",
    "                            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) if not args.use_multi_gpu else self.args.devices\n",
    "                            device = torch.device('cuda:{}'.format(args.gpu))\n",
    "                            # print('Use GPU: cuda:{}'.format(args.gpu))\n",
    "                        else:\n",
    "                            device = torch.device('cpu')\n",
    "                        model_dict = {\n",
    "                                    'informer':Informer,\n",
    "                                    'informerstack':InformerStack,\n",
    "                                }\n",
    "                        e_layers = args.e_layers if args.model=='informer' else args.s_layers\n",
    "                        # 如果args.model是informer，那么model_dict[args.model]就是Informer类\n",
    "                        model = model_dict[args.model](\n",
    "                            args.enc_in,\n",
    "                            args.dec_in, \n",
    "                            args.c_out, \n",
    "                            args.lstm_hidden_size,\n",
    "                            args.lstm_num_layers,\n",
    "                            args.seq_len, \n",
    "                            args.label_len,\n",
    "                            args.pred_len, \n",
    "                            args.factor,\n",
    "                            args.d_model, \n",
    "                            args.n_heads, \n",
    "                            e_layers, # args.e_layers,\n",
    "                            args.d_layers, \n",
    "                            args.d_ff,\n",
    "                            args.dropout, \n",
    "                            args.attn,\n",
    "                            args.embed,\n",
    "                            args.freq,\n",
    "                            args.activation,\n",
    "                            args.output_attention,\n",
    "                            args.distil,\n",
    "                            args.mix,\n",
    "                            device\n",
    "                        ).float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        # 清除缓存                \n",
    "                        # 没有BN层与DropOut层时，new_model.eval()可以不加\n",
    "                        with  torch.no_grad():\n",
    "                            path = os.path.join(run_name_dir_ckp ,setting)\n",
    "                            best_model_path = path+'/'+'checkpoint.pth'\n",
    "                        \n",
    "                            print(best_model_path)\n",
    "                            model.load_state_dict(torch.load(best_model_path))\n",
    "                            model.eval()\n",
    "                            model.to('cpu')\n",
    "\n",
    "                            \n",
    "\n",
    "                            # 命名的时候带All表示所有的数据，只是用来看每一列的长度的，但此处实际上每列长度固定为500了\n",
    "                            dataAll=pd.read_excel((os.path.join(args.root_path,\n",
    "                                                                    '最小值(70)2019test.xlsx')))\n",
    "                        \n",
    "                            dataAll=dataAll.iloc[:1500]\n",
    "                            lenList=[]\n",
    "                            lenListSum=0\n",
    "                            colListAll=[]\n",
    "\n",
    "                            # 每列的长度，实际此处数据每列固定为500，但可以处理每列数据不一样的情况\n",
    "                            for j,col in enumerate(dataAll.columns):\n",
    "                                # 每列的长度\n",
    "                                len=(np.array(dataAll.iloc[:,j].dropna())).shape[0]\n",
    "                                lenList.append(len)\n",
    "                                lenListSum=lenListSum+len\n",
    "                                # 表的列名，用于给图片命名，表明电池编号\n",
    "                                colListAll.append(col)\n",
    "\n",
    "                            # print('lenList',lenList)    \n",
    "                            # mseAll是一个参数下的，被一个参数下的所有电池所共有，而对于不同的参数，mseAll不同\n",
    "                            mseAll=0\n",
    "                            excelHead=['参数']\n",
    "                            excelMse=['lhs_'+str(args.lstm_hidden_size)+'，lnl_'+str(args.lstm_num_layers)+'，dM_'+str(args.d_model)+'，dFF_'+str(args.d_ff)]\n",
    "                            YTruthAll=[]\n",
    "                            YPredAll=[]\n",
    "                            # excelR2=['R\\u00B2']\n",
    "                            excel_file = \"data/batteryNature/预测结果最小值(70)2019_\"+ str(args.seed) +\"test.xlsx\"\n",
    "\n",
    "                            # 创建一个空的DataFrame\n",
    "                            df = pd.DataFrame(index=range(1500))\n",
    "                            # i是训练集的每一列（每一个电池），跑完就是一个参数下所有电池跑完\n",
    "                            for i in range(dataAll.shape[1]):\n",
    "                                # if(i==28 or i==29):\n",
    "                                if(i>-1):\n",
    "                                # if(i<2):\n",
    "                                \n",
    "                                    lenList[i]\n",
    "\n",
    "                                    # rawdataNewQD1 = pd.read_excel(filepathQD)\n",
    "                                    # rawdataNewQD1=rawdataNewQD1.drop(rawdataNewQD1.columns[2], axis=1).values[0:lenList[i],i].reshape(-1, 1)\n",
    "                                    # rawdataNewQD1 = pd.read_excel((os.path.join(args.root_path,\n",
    "                                    #                                 'QD(test).xlsx')))\n",
    "                                    # rawdataNewQD1=rawdataNewQD1.iloc[:500].values[:,i].reshape(-1, 1)\n",
    "                                    # print('rawdataNewQD1',rawdataNewQD1)\n",
    "                                    \n",
    "                                    rawdataNewη1 = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                            '最小值(70)2019test.xlsx')))\n",
    "                                    # 这一列的全部真实值\n",
    "                                    rawdataNewη1=rawdataNewη1.iloc[:lenList[i]].values[:,i].reshape(-1, 1)\n",
    "                                    # print('rawdataNew',rawdataNewη1)\n",
    "                                \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    # rawdataNewVar1 = pd.read_excel(filepathVar)\n",
    "                                    # rawdataNewVar1=rawdataNewVar1.drop(rawdataNewVar1.columns[2], axis=1).values[0:lenList[i],i].reshape(-1, 1)\n",
    "                                    # print('rawdataNew1',rawdataNew1)\n",
    "                                    # rawdataNewQD1 = scalerDataQD1.transform(rawdataNewQD1)\n",
    "                                    # rawdataNewQD1 = scalerDataQD1.transform(rawdataNewQD1)\n",
    "                                    # 归一化后输入模型\n",
    "                                    rawdataNewη1 = scalerDataη1.transform(rawdataNewη1)\n",
    "                                    # rawdataNewη1 = rawdataNewη1\n",
    "                                \n",
    "                                    # rawdataNewVar1 = scalerDataVar1.transform(rawdataNewVar1)\n",
    "                                    # print('rawdataNewQD1',rawdataNewQD1)\n",
    "                                    # print('rawdataNew',rawdataNewη1)\n",
    "\n",
    "\n",
    "\n",
    "                                    # rawdataNew1 = pd.read_excel(filepath).values[0:200,18].reshape(-1, 1)\n",
    "                                    # reshape(1,1,-1)的第一个 1 表示 channel为1\n",
    "                                    # result1=rawdataNewMin1\n",
    "                                    # result1=zip(rawdataNewQD1[:,0],rawdataNewη1[:,0])\n",
    "                                    result1=np.vstack((rawdataNewη1))\n",
    "                                        \n",
    "                                    # print(result1.shape)\n",
    "                                    # print(result1)\n",
    "                                \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    # rawdataNew1聚集了3个特征\n",
    "                                    # rawdataNew1=np.array(list(result1))\n",
    "\n",
    "                                    res_list1_encoder1 = torch.from_numpy(result1[:args.seq_len])\n",
    "                                    # res_list1_decoder1 = torch.from_numpy(result1[args.seq_len-args.label_len:args.seq_len])\n",
    "                                    # print('res_list1_encoder1',res_list1_encoder1)\n",
    "                                    # print('res_list1_decoder1',res_list1_decoder1.shape)\n",
    "                                    # print('res_list',type(res_list1))\n",
    "\n",
    "                                    # print(rawdataNew1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                    # print('np.array([IAll[j]])',np.array([IAll[j]]))\n",
    "\n",
    "                                    start = 0\n",
    "                                    # 一直预测到200\n",
    "                                    # resItemList用于记录所有的预测值(450个)\n",
    "                                    resItemList1=[]\n",
    "                                    rawdata = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                            '最小值(70)2019test.xlsx')))\n",
    "                                    # 该列电池真实值（不做归一化）\n",
    "                                    rawdata=rawdata.iloc[:lenList[i]].values[:,i]\n",
    "                                    # 下面几个参数是一个电池所共有的\n",
    "                                    mseCell=0\n",
    "                                    # 下面两个是为了方便计算R平方等值用的\n",
    "                                    predictCell=[]\n",
    "                                    realCell=[]\n",
    "                                    # lenList[i]-args.seq_len)//args.pred_len+1是执行次数，也即扔到model的次数\n",
    "                                    # while(start<(lenList[i]-args.seq_len)//args.pred_len):\n",
    "                                    # 循环结束是一个电池的预测结束\n",
    "                                    while(start<((lenList[i]-args.seq_len)//args.pred_len)+1):\n",
    "                                        window_encoder= torch.tensor(res_list1_encoder1[start*args.pred_len: start*args.pred_len+args.seq_len])\n",
    "                                        # 注意，这边还是从encoder中取\n",
    "                                        # print('window_encoder',window_encoder)\n",
    "                                        # print('window_encoder',window_encoder.shape)\n",
    "                                        # break\n",
    "                                        window_decoder= torch.tensor(res_list1_encoder1[start*args.pred_len+args.seq_len- args.label_len: start*args.pred_len+args.seq_len])\n",
    "                                        # print('window_decoder',window_decoder)\n",
    "                                        # print('window_decoder',window_decoder.shape)\n",
    "                                        # 不用管，内部写死了，获取带有掩码的输入序列x\n",
    "                                        seq_x_mark = torch.zeros(1)\n",
    "                                        # 获取带有掩码的输入序列x\n",
    "                                        seq_y_mark = torch.zeros(1)\n",
    "                                        \n",
    "                                        \n",
    "                                        if args.use_gpu:\n",
    "                                            os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu) if not args.use_multi_gpu else self.args.devices\n",
    "                                            device = torch.device('cuda:{}'.format(args.gpu))\n",
    "                                            # print('Use GPU: cuda:{}'.format(args.gpu))\n",
    "                                        else:\n",
    "                                            device = torch.device('cpu')\n",
    "                                        global dec_inp\n",
    "                                        batch_x = window_encoder.float()\n",
    "                                        batch_y = window_decoder.float()\n",
    "\n",
    "                                        batch_x_mark = seq_x_mark.float()\n",
    "                                        batch_y_mark = seq_y_mark.float()\n",
    "                                        batch_x=batch_x.unsqueeze(0)\n",
    "                                        batch_y=batch_y.unsqueeze(0)\n",
    "                                        batch_x_mark=batch_x_mark.unsqueeze(0)\n",
    "                                        batch_y_mark=batch_y_mark.unsqueeze(0)\n",
    "                                        # decoder input\n",
    "                                        if args.padding==0:\n",
    "                                            # 返回一个形状为为size，size是一个list，代表了数组的shape,类型为torch.dtype，里面的每一个值都是0的tensor\n",
    "                                            # batch_y.shape[0]是self.lbel_len + self.pred_len\n",
    "                                            # batch_y.shape[-1]是特征数,单特征预测单特征的情况下，这里是1\n",
    "                                            dec_inp = torch.zeros([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "                                        elif args.padding==1:\n",
    "                                            dec_inp = torch.ones([batch_y.shape[0], args.pred_len, batch_y.shape[-1]]).float()\n",
    "                                        # 在给定维度上对输入的张量序列seq 进行连接操作。\n",
    "                                        \"\"\"\n",
    "                                        outputs = torch.cat(inputs, dim=0) → Tensor\n",
    "                                        \n",
    "                                        inputs : 待连接的张量序列，可以是任意相同Tensor类型的python 序列，可以是列表或者元组。\n",
    "                                        dim : 选择的扩维, 必须在0到len(inputs[0])之间，沿着此维连接张量序列。\n",
    "                                        \"\"\"\n",
    "                                        dec_inp = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float()\n",
    "                                        # encoder - decoder（编码器-解码器）\n",
    "                                        # 假如使用自动混合精度训练\n",
    "                                        if args.use_amp:\n",
    "                                            # pytorch 使用autocast半精度进行加速训练\n",
    "                                            with torch.cuda.amp.autocast():\n",
    "                                                # 假如在编码器中输出注意力\n",
    "                                                if args.output_attention:\n",
    "                                                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                                                else:\n",
    "                                                    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                                        # 假如不使用自动混合精度训练\n",
    "                                        else:\n",
    "                                            if args.output_attention:\n",
    "                                                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                                            else:\n",
    "                                                outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                                        # print(outputs.shape)\n",
    "                                        # print(outputs)\n",
    "                                        # 逆标准化输出数据\n",
    "                                        # 暂时不管他\n",
    "                                        # if self.args.inverse:\n",
    "                                        #     outputs = dataset_object.inverse_transform(outputs)\n",
    "                                        f_dim = -1 if args.features=='MS' else 0\n",
    "                                        # 如果是MS。那么只留有一列输出\n",
    "                                        # outputs = outputs[:, :, 1:] if args.features == 'MS' else outputs\n",
    "                                        # 对y进行解码\n",
    "                                        # 取出pred\n",
    "                                        batch_y = batch_y[:,-args.pred_len:,f_dim:]\n",
    "\n",
    "                                        # 如果是M任务，那么进行打平再输出去计算梯度\n",
    "                                        # output作为预测值，batch_y(取出pred部分，也就是长度40)作为真实值\n",
    "                                        # return outputs, batch_y\n",
    "                                        \n",
    "                                        # outputs(1,50,1)\n",
    "                                        # resultTemp=torch.tensor(np.vstack((outputs.squeeze(0))))\n",
    "                                        # # print('resultTemp',resultTemp)\n",
    "                                        # # 存的是真实值以及预测值的拼接,outputs(1,50,1)\n",
    "                                        # res_list1_encoder1=torch.cat([res_list1_encoder1,resultTemp],dim=0)\n",
    "                                        # print('res_list1_encoder1',res_list1_encoder1[:,-1])                \n",
    "                                        \n",
    "                                        # 存的是真实值以及预测值的拼接\n",
    "                                        res_list1_encoder1=torch.cat([res_list1_encoder1,outputs.squeeze(0)],dim=0)\n",
    "                                        \n",
    "                                        # 算mse\n",
    "                                        # 逆归一化\n",
    "                                        res_listnew=scalerDataη1.inverse_transform(outputs.squeeze(0).reshape(-1,1)).ravel()  \n",
    "                                        # res_listnew=res_listnew[0:lenList[i]]\n",
    "                                        # 真实值和预测值的mse    \n",
    "                                        # rawdata为未归一化时的真实值\n",
    "                                        # 一个电池中的所有mse相加                    \n",
    "                                        # print('start=',start)\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len])\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len].shape)\n",
    "                                        # print('res_listnew',res_listnew.shape)\n",
    "                                        # print('ahh',)[start*args.pred_len: start*args.pred_len+args.seq_len])\n",
    "                                        # mseCell=mseCell+mean_squared_error(rawdata[start*args.pred_len+args.seq_len : start*args.pred_len+args.seq_len+args.pred_len],res_listnew)\n",
    "                                        # print('ahh',rawdata[start+args.seq_len : start+args.seq_len+args.pred_len])\n",
    "                                        # 存入predicetCell\n",
    "                                        # predictCell里面存的是逆归一化之后的预测值\n",
    "                                        for element in res_listnew:\n",
    "                                            predictCell.append(element)\n",
    "                                        \n",
    "                                        \n",
    "                                        start = start + 1\n",
    "                                        # 这边改成全用真实值\n",
    "                                        # res_list1_encoder1=torch.from_numpy(result1[start*args.pred_len : start*args.pred_len+args.seq_len])\n",
    "                                        # print('ahh',res_list1_encoder1)\n",
    "                                        \n",
    "                                        \n",
    "                                    \n",
    "                                        # resItemList1.append(outputs)\n",
    "                                        # 将循环号归一化后合并\n",
    "                                        # reshape(1,1,1) 的第一个参数 1 表示 channel为 1\n",
    "                                        # result=np.array([res.item()]).reshape(1,1,1)\n",
    "                                        # print(result)\n",
    "                                        # print(result.shape)\n",
    "                                        # res_list1=np.concatenate((res_list1,result),axis=2)\n",
    "                                        # print(res_list1)\n",
    "                                        # print(res_list1.shape)\n",
    "                                        \n",
    "\n",
    "                                    \n",
    "                                    # resItemList1\n",
    "                                    # 逆归一化,还原成预测的充电电容(150个)\n",
    "                                    res_listnew2=scalerDataη1.inverse_transform(res_list1_encoder1[:,-1].reshape(-1,1)).ravel()  \n",
    "                                    res_listnew2=res_listnew2[0:lenList[i]]\n",
    "                                    # print(\"ahh\",res_listnew)\n",
    "                                    \n",
    "                                    # print('每个电池迭代次数',lenList[i]-args.seq_len-args.pred_len+1)\n",
    "                                    # print('start',start)\n",
    "                                    # 除以'每个电池迭代次数'，得到一个电池的最终mse\n",
    "                                    # mseCell=mseCell/((lenList[i]-args.seq_len-args.pred_len)//args.pred_len+1)\n",
    "                                \n",
    "                                    # print('predictCell', len(predictCell))\n",
    "                                    \n",
    "                                    # 一套参数下所有电池的mse相加\n",
    "                                    mseAll = mseAll+mseCell\n",
    "        \n",
    "                            \n",
    "\n",
    "\n",
    "                                    # testIndex = 0\n",
    "\n",
    "                                    # # print('res_listnew',res_listnew[-1])\n",
    "                                    # # 一开始用的是1A的数据,用的是初始数据\n",
    "                                    rawdata = pd.read_excel((os.path.join(args.root_path,\n",
    "                                                            '最小值(70)2019test.xlsx')))\n",
    "                                    rawdata=rawdata.iloc[:lenList[i]].values[:,i]\n",
    "                                    \n",
    "                                    # 横坐标\n",
    "                                    x = range(1,lenList[i]+1)\n",
    "                                    # 纵坐标真实值\n",
    "                                    y = rawdata[0:]\n",
    "                                    # 纵坐标预测值     # 还原成原样\n",
    "                                    # y2 = np.array(res_listnew[:]).tolist()\n",
    "                                    # print(type(y))\n",
    "                                    # print(type(predictCell))\n",
    "                                    y2 = y[0:args.seq_len].tolist()+predictCell\n",
    "                                    # y2 = y2[:lenList[i]]\n",
    "                                    col_list = y2\n",
    "                                    col_name = colListAll[i]\n",
    "                                    # 使用assign方法将每个colList添加到DataFrame中\n",
    "                                    df[col_name] = pd.Series(col_list)\n",
    "                                    YTruthAll=np.concatenate((YTruthAll, y[-lenList[i]+args.seq_len:]))\n",
    "                                    YPredAll=np.concatenate((YPredAll, y2[-lenList[i]+args.seq_len:]))\n",
    "                                    # print('predictCell',predictCell)\n",
    "                                    # print('res_listnew2',res_listnew2[50:])\n",
    "                                    # 此处写上最好的一两种参数，进行画图\n",
    "                                    if(args.lstm_hidden_size==32 and args.lstm_num_layers==3 and args.d_model==32 and args.d_ff==128):\n",
    "                                    # print(len(y2))\n",
    "                                        print('d_model=', args.d_model)\n",
    "                                        print('d_ff=', args.d_ff)\n",
    "                                        print('batch=', args.batch_size)\n",
    "                                        \n",
    "                                    \n",
    "                                        plt.figure()\n",
    "                                        # plt.title(colListAll[i]+'_Model 2——'+str(testIndex)+'——'+str(num_epochs))\n",
    "                                        plt.title(colListAll[i]+'_lHS'+str(args.lstm_hidden_size)+'_lNL'+str(args.lstm_num_layers)+'_dModel'+str(args.d_model)+'_dFF'+str(args.d_ff))\n",
    "                                    \n",
    "                                        plt.xlabel('circle')\n",
    "                                        plt.ylabel('min')\n",
    "                                        plt.plot(x,y, label='True')\n",
    "                                        \n",
    "                                        plt.plot(x,y2, label='prediction', linestyle='--')\n",
    "                                        # plt.ylim(0.1,1.1)\n",
    "                                        # plt.annotate(f'{round(y[-1],4)}', (500, y[-1]))\n",
    "                                        # plt.annotate(f'{round(y2[-1],4)}', (500, y2[-1]))\n",
    "\n",
    "                                        plt.legend(loc='upper left')\n",
    "                                        # 添加虚线\n",
    "                                        # plt.axhline(y=0.88,linestyle=\"--\",c=\"black\")\n",
    "                                        plt.axvline(x=args.seq_len,ls=\"--\",c=\"black\")\n",
    "                                        for idx in range((int(plt.axis()[1])-args.seq_len)//args.pred_len):plt.axvline(x=args.seq_len+idx*args.pred_len,ls=\"--\",c=\"grey\")\n",
    "                                        # plt.axvline(y=0.88,ls=\"--\",c=\"black\")\n",
    "                                        \n",
    "                                        plt.ylim(-2.5,0.1)\n",
    "                                        # 解决中文显示问题\n",
    "                                        plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "                                        plt.rcParams['axes.unicode_minus'] = False  \n",
    "                                        # -x[-1]*0.06,min(y[-1],y2[-1])- (y[0]-y[-1])*0.3  这些是用于指定文字的坐标的\n",
    "                                        plt.text(-x[-1]*0.06,-2.85, \"真实值：\"+str(y[-1]), ha='left', fontsize=12)\n",
    "                                        plt.text(-x[-1]*0.06, -3, \"预测值：\"+str(y2[-1]), ha='left', fontsize=12)\n",
    "                                        # plt.text(-x[-1]*0.06, -0.30, \"MSE:    \"+str(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:])), ha='left', fontsize=12)\n",
    "                                        \n",
    "                                        plt.text(-x[-1]*0.06, -3.15, \"MSE:    \"+str(\"{:.2e}\".format(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:]))), ha='left', fontsize=12)\n",
    "                                        # plt.savefig('./img(min)/'+colListAll[i]+'模型1-h64-testIndex='+str(testIndex)+'-epoch='+str(num_epochs)+'.jpg', format='jpg', dpi=200)\n",
    "                                        # print(plt.axis()[2])\n",
    "                                        plt.show()\n",
    "                                        print('真实值：',y[-1])\n",
    "                                        print('预测值：',y2[-1])\n",
    "                                        print('MSE：',mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:]))\n",
    "                                    \n",
    "                                    # 电池\n",
    "                                    realCellAll=pd.read_excel((os.path.join(args.root_path,\n",
    "                                                            '最小值(70)2019test.xlsx')))\n",
    "                                    # 这一列的全部真实值\n",
    "                                    realCellAll=realCellAll.iloc[:lenList[i]].values[:,i].reshape(-1, 1)\n",
    "                                    # 最终得到的realCell是与predict的shape一样的，可以用于计算mse，r平方之类\n",
    "                                    # for idx in range(lenList[i]-args.seq_len-args.pred_len+1):\n",
    "                                    #     for element in realCellAll[idx+args.seq_len : idx+args.seq_len+args.pred_len]:\n",
    "                                    #         realCell.append(element)\n",
    "                                    # mean_squared_error(realCell,predictCell)与上面计算的mseCell一样\n",
    "                                    realCell=y[-lenList[i]+args.seq_len:]\n",
    "                                    # print('mse新',mean_squared_error(realCell,predictCell))\n",
    "                                    # print('mse新xin',mean_squared_error(realCell,res_listnew2[100:]))\n",
    "                                    # print('mseCell',mseCell)\n",
    "                                    # 可以计算r平方\n",
    "                                    # print('r',r2_score(realCell,predictCell))\n",
    "                                    \n",
    "                                    excelHead.append(colListAll[i])\n",
    "                                    excelMse.append(\"{:.2e}\".format(mean_squared_error(y[-lenList[i]+args.seq_len:],y2[-lenList[i]+args.seq_len:])))\n",
    "                                    \n",
    "                                    # 暂时先不要R2\n",
    "                                    # excelR2.append(r2_score(realCell,predictCell))\n",
    "                            # 将DataFrame保存为Excel文件\n",
    "                            df.to_excel(excel_file, index=False)        \n",
    "                            # print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "                            # print('d_model=', args.d_model)\n",
    "                            # print('d_ff=', args.d_ff) \n",
    "                            # print('电池个数',dataAll.shape[1])\n",
    "                            # 是一个参数下所有电池的  \n",
    "                            # print('mseAll',mseAll/dataAll.shape[1])\n",
    "                            excelHead.append('总MSE')\n",
    "                            excelMse.append(\"{:.2e}\".format(mean_squared_error(np.array(YTruthAll).flatten(),np.array(YPredAll).flatten())))\n",
    "                            excelHead.append('总R2')\n",
    "                            excelMse.append(\"{:.2e}\".format(r2_score(np.array(YTruthAll).flatten(),np.array(YPredAll).flatten())))\n",
    "                            # 电池编号（第一行）未加入，就加一次\n",
    "                            if excelDataAll ==[]: excelDataAll.append(excelHead)\n",
    "                            excelDataAll.append(excelMse)\n",
    "                            # data = [\n",
    "                            #     excelHead,\n",
    "                            #     excelMse,\n",
    "                            #     # excelR2\n",
    "                            # ]\n",
    "\n",
    "                            # 创建数据框\n",
    "    # df = pd.DataFrame(excelDataAll)\n",
    "    # # 保存为 Excel 文件\n",
    "    # file_path = excelOutPath\n",
    "    # # 创建 Styler 对象并设置单元格样式\n",
    "    # styler = df.style.set_properties(**{'text-align': 'center'})\n",
    "    # # df.to_excel(file_path, index=False, header=False)\n",
    "    # styler.to_excel(file_path, index=False, header=False)\n",
    "    print('数据已保存为 Excel 文件.')\n",
    "\n",
    "except Exception as e:\n",
    "    print(traceback.print_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2556e3371ecfeda8696085f34e54091f59eadce9b2fe4f307bc2f4cd2d044a7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
